<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>wzwan</title>
        <link>https://wzwan-developer.github.io/</link>
        <description>Recent content on wzwan</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>wzwan</copyright><atom:link href="https://wzwan-developer.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Chapter 00: Adaptive Voxelization</title>
        <link>https://wzwan-developer.github.io/p/mlcc/00/</link>
        <pubDate>Mon, 16 Sep 2024 15:55:17 +0800</pubDate>
        
        <guid>https://wzwan-developer.github.io/p/mlcc/00/</guid>
        <description>&lt;img src="https://wzwan-developer.github.io/p/mlcc/00/lidar_voxel.png" alt="Featured image of post Chapter 00: Adaptive Voxelization" /&gt;&lt;h2 id=&#34;文章内容&#34;&gt;文章内容
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;          To find the correspondences among different LiDAR scans, we assume the initial base LiDAR trajectory $\mathcal{S}$, LiDAR extrinsic $\mathcal{E}_L$, and camera extrinsic $\mathcal{E}_C$ are available. The initial base LiDAR trajectory $\mathcal{S}$ could be obtained by an online LiDAR SLAM (e.g., [3]), and the initial extrinsic could be obtained from the CAD design or a rough Hand-Eye calibration [14].
Our previous work [5] extracts edge and plane feature points from each LiDAR scan and matches them to the nearby edge and plane points in the map by a $k$-nearest neighbor search ($k-NN$). This would repeatedly build a $k$-d tree of the global map at each iteration. In this paper, we use a more efficient voxel map proposed in [4] to create correspondences among all LiDAR scans.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;        为了找到不同雷达扫描之间的对应关系，我们假设初始的基准雷达轨迹$\mathcal{S}$、雷达外参$\mathcal{E}_L$、相机外参$\mathcal{E}_C$是可用的。初始的基准雷达轨迹$\mathcal{S}$可以通过实时雷达SLAM获得，而初始的外参可以通过CAD设计或者从粗略的手眼标定中获得。我们的前期工作，从每个雷达扫描中提取边缘和平面特征，并通过最邻域搜索，将他们匹配到地图中的临近边缘和平面。这会在每次迭代中重复构建全局地图的$k$-d树，在本文中，我们使用在文献4中提出的一种更为高效的体素地图来创建所有雷达扫描之间的对应关系。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;          The voxel map is built by cutting the point cloud (registered using the current $\mathcal{S}$ and $\mathcal{E}_L$) into small voxels such that all points in a voxel roughly lie on a plane (with some adjustable tolerance). The main problem of the fixed-resolution voxel map is that if the resolution is high, the segmentation would be too time-consuming, while if the resolution is too low, multiple small planes in the environments falling into the same voxel would not be segmented. To best adapt to the environment, we implement an adaptive voxelization process. More specifically, the entire map is first cut into voxels with a pre-set size (usually large, e.g., 4m). Then for each voxel, if the contained points from all LiDAR scans roughly form a plane (by checking the ratio between eigenvalues), it is treated as a planar voxel; otherwise, they will be divided into eight octants, where each will be examined again until the contained points roughly form a plane or the voxel size reaches the pre-set minimum lower bound. Moreover, the adaptive voxelization is performed directly on the LiDAR raw points, so no prior feature points extraction is needed as in [5].&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;        体素地图通过将点云（使用当前的 $\mathcal{S}$和 $\mathcal{E}_L$ 进行配准）切割成小的体素来构建，使得体素内的所有点大致位于同一平面上（具有一定的可调容差）。固定分辨率体素图的主要问题是，如果分辨率太高，分割将会非常耗时；而如果分辨率太低，环境中多个小平面落在同一个体素内时则无法进行分割。为了更好地适应环境，我们实现了自适应体素化过程。
具体来说，整个地图首先被切割成预设大小的体素（通常较大，例如4米）。然后对于每个体素，如果所有LiDAR扫描中包含的点大致形成一个平面（通过检查特征值之间的比率来判断），则将其视为平面体素；否则，这些体素将被分成八个八分之一体素（octants），每个都将再次进行检查，直到包含的点大致形成一个平面，或者体素尺寸达到预设的最小下限。此外，自适应体素化直接在LiDAR的原始点上执行，因此不需要像文献[5]那样预先提取特征点。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;          Fig. 3 shows a typical result of the adaptive voxelization process in a complicated campus environment. As can be seen, this process is able to segment planes of different sizes, including large planes on the ground, medium planes on the building walls, and tiny planes on tree crowns.
&lt;img src=&#34;https://wzwan-developer.github.io/p/mlcc/00/adaptive_voxelization.png&#34;
	width=&#34;2574&#34;
	height=&#34;930&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/mlcc/00/adaptive_voxelization_hu12395980834133490816.png 480w, https://wzwan-developer.github.io/p/mlcc/00/adaptive_voxelization_hu3118485833705387669.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;图3&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;276&#34;
		data-flex-basis=&#34;664px&#34;
	
&gt;
Fig. 3: A) LiDAR point cloud segmented with the adaptive voxelization. Points within the same voxel are colored identically. The detailed adaptive voxelization of points in the dashed white rectangle could be viewed in B) colored points and C) original points. The default size for the initial voxelization is 4m, and the minimum voxel size is 0.25m.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;图3展示了一个复杂校园环境中自适应体素化过程的典型结果。如图所示，该过程能够分割出不同大小的平面，包括地面上的大平面、建筑物墙面上的中等平面以及树冠上的小平面。
&lt;img src=&#34;https://wzwan-developer.github.io/p/mlcc/00/adaptive_voxelization.png&#34;
	width=&#34;2574&#34;
	height=&#34;930&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/mlcc/00/adaptive_voxelization_hu12395980834133490816.png 480w, https://wzwan-developer.github.io/p/mlcc/00/adaptive_voxelization_hu3118485833705387669.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;图3&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;276&#34;
		data-flex-basis=&#34;664px&#34;
	
&gt;
图3：(A) 使用自适应体素化分割的LiDAR点云。同一体素内的点被赋予相同的颜色。白色虚线矩形区域内的详细自适应体素化效果可以在 (B) 彩色点云和 (C) 原始点云中查看。初始体素化的默认大小为4米，而最小的体素大小为0.25米。&lt;/p&gt;
&lt;h2 id=&#34;相关理论&#34;&gt;相关理论
&lt;/h2&gt;&lt;p&gt;论文中关于自适应体素并未提及到重要信息，但是提到了参考文献4&lt;a class=&#34;link&#34; href=&#34;https://www.arxiv.org/pdf/2010.08215&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《BALM: Bundle Adjustment for Lidar Mapping》&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;自适应体素化&#34;&gt;自适应体素化
&lt;/h3&gt;&lt;p&gt;        我们在默认大小的3D空间中重复体素化，如果当前体素中的所有特征点都位于平面，则将当前体素与包含的特征点一起保存在内存中；否则，将当前体素分解为八个八分体，并继续检查每个八分体直到达到最小尺寸。在具体实现过程中有以下细节：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果一个体素内包含太多的特征点，则会导致文章&lt;a class=&#34;link&#34; href=&#34;https://wzwan-developer.github.io/p/mlcc/01/&#34; &gt;《Chapter 01: Multi-LiDAR Extrinsic Calibration》&lt;/a&gt;中推导过程章节中二阶闭式导数中的Hessian矩阵维度过高，在这种情况下，我们可以将点进行平均，以实现降采样但不降低映射一致性；&lt;/li&gt;
&lt;li&gt;同时，二阶闭式导数中的Hessian矩阵推导过程中提到$\lambda_m\ne\lambda_n$,因此当遇到$\lambda$的代数多重性大于1的体素需要跳过（忽略）；&lt;/li&gt;
&lt;li&gt;只需检查体素所包含的点，是否位于同一平面时允许更大的方差，则能自然地扩展到非平面特征（BLAM只提到了平面特征和边缘特征）；&lt;/li&gt;
&lt;li&gt;设置了两个条件来停止递归体素化：一个是树的最大深度，另一个是体素的最小点数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        其中，判断体素是否为平面的方法是计算体素内所有的点云的协方差矩阵，判断最大特征值与最小特征值的比值是否大于一定的阈值，如果大于则为平面：&lt;/p&gt;
&lt;p&gt;首先计算中心点$p_c$,即所有点的均值点,如下所示：
&lt;/p&gt;
$$
p_c=\frac{1}{N}\sum_{i=1}^{N}p_i
$$&lt;p&gt;
接着计算协方差矩阵：
&lt;/p&gt;
$$
\begin{align*}
C=\frac{1}{N}\sum_{i=1}^{N}\big(p_i - c\big)\big(p_i - c\big)^T\\
=\frac{1}{N}\sum_{i=1}^{N}\big(p_ip_i^T-p_ic^T-cp_i^T+cc^T\big)\\
=\frac{1}{N}\sum_{i=1}^{N}p_ip_i^T-\frac{1}{N}\sum_{i=1}^{N}p_ic^T
-c\big(\frac{1}{N}\sum_{i=1}^{N}p_i\big)^T+cc^T\\
=\frac{1}{N}\sum_{i=1}^{N}p_ip_i^T-cc^T-cc^T+cc^T\\
=\frac{1}{N}\sum_{i=1}^{N}p_ip_i^T-cc^T
\end{align*}
$$&lt;h3 id=&#34;八叉树数据结构&#34;&gt;八叉树数据结构
&lt;/h3&gt;&lt;p&gt;&lt;span style=&#34;color:red&#34;&gt;正在持续更新中！&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;代码详解&#34;&gt;代码详解
&lt;/h2&gt;&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;&lt;p&gt;[1]&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2109.06550&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《Targetless Extrinsic Calibration of Multiple Small FoV LiDARs and Cameras using Adaptive Voxelization》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2]&lt;a class=&#34;link&#34; href=&#34;https://www.arxiv.org/pdf/2010.08215&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《BALM: Bundle Adjustment for Lidar Mapping》&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Chapter 01: Multi-LiDAR Extrinsic Calibration</title>
        <link>https://wzwan-developer.github.io/p/mlcc/01/</link>
        <pubDate>Wed, 11 Sep 2024 09:05:20 +0800</pubDate>
        
        <guid>https://wzwan-developer.github.io/p/mlcc/01/</guid>
        <description>&lt;img src="https://wzwan-developer.github.io/p/mlcc/01/lidar_voxel.png" alt="Featured image of post Chapter 01: Multi-LiDAR Extrinsic Calibration" /&gt;&lt;h2 id=&#34;文章内容&#34;&gt;文章内容
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;            With adaptive voxelization, we can obtain a set
of voxels of different sizes. Each voxel contains points that are roughly on a plane and creates a planar constraint for
all LiDAR poses that  have points in this voxel. More specifically, considering the $l-th$ voxel consisting of a group of
points $\mathcal{P}_{l}={_{}^{G}P_{L_{i},t_{j}}}$ scanned by $L_{i} \in \mathcal{L}$ at times $t_{j} \in \mathcal{T}$.
We define a point cloud consistency  indicator $_{c_{l}}(_{L_{i}}^{G}T_{t_{j}})$ which forms a factor on $\mathcal{S}$ and $\mathcal{E}_{L}$ shown
in Fig. 4(a). Then, the base LiDAR trajectory and extrinsic are estimated by optimizing the factor graph. A natural choice   for the consistency
indicator $c_{l}(\cdot)$ would be the summed Euclidean distance between each $_{}^{G}P_{L_{i},t_{j}}$ the plane to be estimated (see Fig. 4(b)).
Taking account of all such indicators within the voxel map, we could formulate the problem as &lt;/p&gt;
$$\arg\min_{{\mathcal{S},\mathcal{E}_{L},{n}_{l},{q}_{l}}}\sum_{l}\underbrace{{\left(\frac{1}{N_{l}}\sum_{k=1}^{{N_{l}}}\left({n}_{l}^{T}\left(^{G}{p}_{k}-{q}_{l}\right)\right)^{2}\right)}}_{{l\mathrm{-th~factor}}}$$&lt;p&gt;， where $_{}^{G}p_{k}\in \mathcal{P}_{l}$, $N_{l}$ is the total number of points in $\mathcal{P}_{l}$, $n_{l}$ is the normal vector of the plane and $q_{l}$ is a point on this plane.
&lt;img src=&#34;https://wzwan-developer.github.io/p/mlcc/01/graph1.png&#34;
	width=&#34;1976&#34;
	height=&#34;830&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/mlcc/01/graph1_hu4057890427085875171.png 480w, https://wzwan-developer.github.io/p/mlcc/01/graph1_hu18239084144532588545.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Fig.4&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;238&#34;
		data-flex-basis=&#34;571px&#34;
	
&gt;
Fig.4 :(a) The $l-th$ factor item relating to $\mathcal{S}$ and $\mathcal{E}_{L}$ with $L_{i} \in \mathcal{L}$ and $t_{j} \in \mathcal{T}$ . (b) The distance from the point $_{}^{G}p_{k}$ to the plane $\pi$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;         通过自适应体素化，我们可以获得一组不同大小的体素。
每个体素包含大致在一个平面上的点，并为所有包含在此体素内的雷达姿态创建一个平面约束。
更具体地说，考虑由$L_{i} \in \mathcal{L}$在时刻$t_{j} \in \mathcal{T}$扫描的一组点组成的第$l$个体素。
我们定义了一个点云一致性指标$_{c_{l}}(_{L_{i}}^{G}T_{t_{j}})$ ，
它在图4(a)中形成了$\mathcal{S}$ 和 $\mathcal{E}_{L}$上的因子。然后，通过优化因子图来估计基准雷达的轨迹和外参。
对于一致性指标$c_{l}(\cdot)$的一个自然选择是计算每个$_{}^{G}P_{L_{i},t_{j}}$到平面的欧几里得距离之和（见图4(b)）。
考虑到体素图中所有这样的指标，我们可以将问题表述为
&lt;/p&gt;
$$\arg\min_{{\mathcal{S},\mathcal{E}_{L},{n}_{l},{q}_{l}}}\sum_{l}\underbrace{{\left(\frac{1}{N_{l}}\sum_{k=1}^{{N_{l}}}\left({n}_{l}^{T}\left(^{G}{p}_{k}-{q}_{l}\right)\right)^{2}\right)}}_{{l\mathrm{-th~factor}}}$$&lt;p&gt;
，其中 $_{}^{G}p_{k}\in \mathcal{P}_{l}$，$N_{l}$ 是 $\mathcal{P}_{l}$中所有点的总点数, $n_{l}$ 是平面的
法向量， $q_{l}$ 是平面中的一点。
&lt;img src=&#34;https://wzwan-developer.github.io/p/mlcc/01/graph1.png&#34;
	width=&#34;1976&#34;
	height=&#34;830&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/mlcc/01/graph1_hu4057890427085875171.png 480w, https://wzwan-developer.github.io/p/mlcc/01/graph1_hu18239084144532588545.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;图4&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;238&#34;
		data-flex-basis=&#34;571px&#34;
	
&gt;
Fig.4 :(a) 第$l$ 个因子项，涉及$\mathcal{S}$ 和 $\mathcal{E}_{L}$，其中  $L_{i} \in \mathcal{L}$
且 $t_{j} \in \mathcal{T}$ 。 (b)点 $_{}^{G}p_{k}$到平面$\pi$的距离.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;              It is noticed
that the optimization variables $(n_{l}, q_{l})$ in (2) could be analytically solved (see Appendix A
and the resultant cost function (3) is over the LiDAR pose $_{L_{i}}^{G}T_{t_{j}}$ (hence the base
LiDAR trajectory $\mathcal{S}$ and extrinsic $\mathcal{E}_{L}$) only, as follows
&lt;/p&gt;
$$ \arg\min_{\mathcal{S},\mathcal{E}_{L}}\sum_{l}^{}\lambda_{3}(A_{l}) $$&lt;p&gt;
where $\lambda_{3}(A_{l})$ denotes the minimal eigenvalue of matrix $A_{l}$ defined as
&lt;/p&gt;
$$ A_{l}=\frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \cdot_{}^{G}p_{k}^{T}-q_{l}^{\ast}\cdot {q_{l}^{\ast}}^{T}},q_{l}^{\ast} =\frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{_{}^{G}p_{k}}
$$&lt;p&gt;
. To allow efficient optimization in (3), we derive the closedform derivatives w.r.t the optimization
variable $x$ up to secondorder (the detailed derivation from (3) to (5) is elaborated in Appendix B):
&lt;/p&gt;
$$\lambda_3({x}\boxplus\delta{x})\approx\lambda_3({x})+{\bar{J}}\delta{x}+\frac12\delta{x}^T{\bar{H}}\delta{x}$$&lt;p&gt;
,where $\bar{J}$ is the Jacobian matrix, and $\bar{H}$  is the Hessian matrix.
The $\delta{x}$  is a small perturbation of the optimization variable $x$:
&lt;/p&gt;
$${x}=[\underbrace{\cdots_{L_{0}}^{G}{R}_{t_{j}}\quad L_{0}^{G}{t}_{t_{j}}\cdots}_{\mathcal{S}}\underbrace{\cdots_{L_{i}}^{L_{0}}{R}_{L_{i}}^{L_{0}}{t}\cdots}_{\mathcal{E}_{L}}]$$&lt;p&gt;
.Then the optimal $x^{\ast}$ could be determined by iteratively solving (6) with the LM method
and updating the $\delta{x}$ to $x$.
&lt;/p&gt;
$$(\bar{{H}}+\mu{I}) \delta{x}=-\bar{{J}}^T$$&lt;/blockquote&gt;
&lt;p&gt;         注意到优化变量$(n_{l}, q_{l})$在方程(2)中可以解析求解（详见附录A）,由此得到的损失函数(3)仅关于雷达姿态$_{L_{i}}^{G}T_{t_{j}}$(即基准雷达轨迹$\mathcal{S}$和外参$\mathcal{E}_{L}$),如下所示：
&lt;/p&gt;
$$ \arg\min_{\mathcal{S},\mathcal{E}_{L}}\sum_{l}^{}\lambda_{3}(A_{l}) $$&lt;p&gt;
其中$\lambda_{3}(A_{l})$表示矩阵 $A_{l}$的最小特征值， $A_{l}$定义为&lt;/p&gt;
$$ A_{l}=\frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \cdot_{}^{G}p_{k}^{T}-q_{l}^{\ast}\cdot {q_{l}^{\ast}}^{T}},q_{l}^{\ast} =\frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{_{}^{G}p_{k}}$$&lt;p&gt;
。为了使式(3)中的优化高效，我们推导了优化变量$x$的二阶闭式导数(从(3)到(5)的详细推导见附录B)：
&lt;/p&gt;
$$\lambda_3({x}\boxplus\delta{x})\approx\lambda_3({x})+{\bar{J}}\delta{x}+\frac12\delta{x}^T{\bar{H}}\delta{x}$$&lt;p&gt;
。其中$\bar{J}$是雅可比矩阵，$\bar{H}$是海森矩阵。$\delta{x}$是优化变量$x$的小扰动：
&lt;/p&gt;
$${x}=[\underbrace{\cdots_{L_{0}}^{G}{R}_{t_{j}}\quad L_{0}^{G}{t}_{t_{j}}\cdots}_{\mathcal{S}}\underbrace{\cdots_{L_{i}}^{L_{0}}{R}_{L_{i}}^{L_{0}}{t}\cdots}_{\mathcal{E}_{L}}]$$&lt;p&gt;
。然后，最优解$x^{\ast}$可以通过迭代求解公式(6)并使用LM的方法更新$\delta{x}$到$x$来确定。
&lt;/p&gt;
$$(\bar{{H}}+\mu{I}) \delta{x}=-{\bar{{J}}}^T$$&lt;h2 id=&#34;理论推导&#34;&gt;理论推导
&lt;/h2&gt;&lt;h3 id=&#34;损失函数的降维&#34;&gt;损失函数的降维
&lt;/h3&gt;&lt;h4 id=&#34;推导一balm论文的思路&#34;&gt;推导一：BALM论文的思路
&lt;/h4&gt;$$\arg\min_{{\mathcal{S},\mathcal{E}_{L},{n}_{l},{q}_{l}}}\sum_{l}\underbrace{{\left(\frac{1}{N_{l}}\sum_{k=1}^{{N_{l}}}\left({n}_{l}^{T}\left(^{G}{p}_{k}-{q}_{l}\right)\right)^{2}\right)}}_{{l\mathrm{-th~factor}}}$$&lt;p&gt;
观察上式可知，由于对于平面参数$\pi=(n_{l},q_{l})$的依赖，原始误差函数优化的维度很高。因为平面参数$(n_{l},q_{l})$对于不同的平面是有区别的。我们可以对它们进行优化，如下式所示：
&lt;/p&gt;
$$\arg\min_{{\mathcal{S},\mathcal{E}_{L}}}\sum_{l}{\left(\min_{n_{l},q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( n_{l}^{T}\left( {^{G}p_{k}-q_{l}}\right)\right)^{2}}} \right)} $$&lt;p&gt;
在$(n_{l},q_{l})$两个平面参数优化过程中可以优先优化$q_{l}$，再优化$n_{l}$，下式为优化$q_{l}$。
&lt;/p&gt;
$$\begin{align*}\arg\min_{n_{l},q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( n_{l}^{T}\left( {^{G}p_{k}-q_{l}}\right)\right)^{2}}} \\
= \arg\min_{n_{l}}\left( \min_{q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( n_{l}^{T}\left( {^{G}p_{k}-q_{l}}\right)\right)^{2}}}\right)\\
=\arg\min_{n_{l}}n_{l}^{T}\left( \min_{q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}}\right)^{2}}}\right)n_{l}
 \end{align*}$$&lt;p&gt;
继续简化关于$q_{l}$参数的优化
&lt;/p&gt;
$$\begin{align*}\arg\min_{q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}}\right)^{2}}}\\
 =\min_{q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}}\right)\left( {^{G}p_{k}-q_{l}}\right)^{T}}}\end{align*}$$&lt;p&gt;
需要求当上式最小化是$q_{l}$的最优解，我们需要找到上式梯度为0的$q_{l}$的值，因此我们对上式求关于$q_{l}$的导数，如下所示：
&lt;/p&gt;
$$\begin{align*}\frac{\partial}{\partial{q_{l}}} \left( {\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}}\right)\left( {^{G}p_{k}-q_{l}}\right)^{T}}}\right) \\
={\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}}  {-({^{G}p_{k}-q_{l})}^{T}}-\left( {^{G}p_{k}-q_{l}}\right)}}\\
= {\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}}  {-2({^{G}p_{k}-q_{l})}}}}\\
=-{\frac{2}{N_{l}}{\sum_{k=1}^{N_{l}}  {({^{G}p_{k}-q_{l})}}}}
\end{align*}$$&lt;p&gt;
令上式等于0：
&lt;/p&gt;
$$\begin{align*}-{\frac{2}{N_{l}}{\sum_{k=1}^{N_{l}}  {({^{G}p_{k}}-q_{l})}}}=0 \\
 \sum_{k=1}^{N_{l}}{({^{G}p_{k}-q_{l}})} =0\\
 \sum_{k=1}^{N_{l}}{^{G}p_{k}}-N_{l}q_{l}=0\\
 N_{l}q_{l}=\sum_{k=1}^{N_{l}}{^{G}p_{k}}\\
 q_{l}=\frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{^{G}p_{k}}
 \end{align*}$$&lt;p&gt;
由此可知，最优的$q_{l}$是所有$^{G}p_{k}$的均值$q_{l}^{\ast}$,接下来继续简化$n_{l}$
&lt;/p&gt;
$$\begin{align*}\arg\min_{n_{l}}n_{l}^{T}\left( \min_{q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}}\right)^{2}}}\right)n_{l}\\
=\arg\min_{n_{l}}n_{l}^{T}\left( {\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}^{\ast}}\right)^{2}}}\right)n_{l}\end{align*}$$&lt;p&gt;
其中，&lt;/p&gt;
$${\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}^{\ast}}\right)^{2}}}\\
\Leftrightarrow \frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \cdot_{}^{G}p_{k}^{T}-q_{l}^{\ast}\cdot {q_{l}^{\ast}}^{T}} $$&lt;p&gt;
需要注意的是上式中$q_{l}^{\ast} \cdot_{}^{G}p_{k}^{T}$与$_{}^{G}p_{k}\cdot{q_{l}^{\ast}}^{T}$两个交叉项在最小化过程中不会对优化结果产生影响，所以两式等价。
所以，带入&lt;/p&gt;
$$ A_{l}=\frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \cdot_{}^{G}p_{k}^{T}-q_{l}^{\ast}\cdot {q_{l}^{\ast}}^{T}},q_{l}^{\ast} =\frac{1}{N_{l}}\sum_{k=1}^{N_{l}}{_{}^{G}p_{k}}$$$$\begin{align*}\arg\min_{n_{l}}n_{l}^{T}\left( {\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}^{\ast}}\right)^{2}}}\right)n_{l}\\
=\arg\min_{n_{l}}n_{l}^{T}A_{l}n_{l}\end{align*}$$&lt;p&gt;
根据瑞利商定理，对矩阵$M$满足如下性质：
&lt;/p&gt;
$$\lambda_{min}(M)\le \frac{x^{T}Mx}{x^{T}x}\le\lambda_{max}(M),\forall{x}\ne0$$&lt;p&gt;
则关于误差函数，取得最小化，变量$(n_{l}, q_{l})$的优化为公式&lt;/p&gt;
$$\begin{align*}\
=\lambda_{min}(A_{l})\\arg\min_{n_{l}}n_{l}^{T}\left( \min_{q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( {^{G}p_{k}-q_{l}}\right)^{2}}}\right)n_{l}\\
=\lambda_{3}(A_{l})\end{align*}$$&lt;p&gt;
将其带入&lt;/p&gt;
$$\begin{align*}\arg\min_{{\mathcal{S},\mathcal{E}_{L}}}\sum_{l}{\left(\min_{n_{l},q_{l}}{\frac{1}{N_{l}}{\sum_{k=1}^{N_{l}} \left( n_{l}^{T}\left( {^{G}p_{k}-q_{l}}\right)\right)^{2}}} \right)}\\
=\arg\min_{{\mathcal{S},\mathcal{E}_{L}}}\sum_{l}{\lambda_{3}(A_{l})}\end{align*}$$&lt;h4 id=&#34;推导二该论文中的推导思路&#34;&gt;推导二：该论文中的推导思路
&lt;/h4&gt;&lt;p&gt;&lt;span style=&#34;color:red;&#34;&gt;后续补充！&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;二阶闭式导数的推导&#34;&gt;二阶闭式导数的推导
&lt;/h3&gt;&lt;p&gt;首先引入BALM中两个定理，如下所示:&lt;/p&gt;
&lt;h4 id=&#34;定理1&#34;&gt;定理1
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;已知：&lt;/p&gt;
$${A}=\frac1N\sum_{i=1}^N\left({p}_i-\bar{{p}}\right)\left({p}_i-\bar{{p}}\right)^T,\bar{{p}}=\frac{1}{N}\sum_{i=1}^{N}{p}_{i}$$&lt;p&gt;
对于一组点$p_{i}\left(i=1,\dots,\right)$和定义的协方差矩阵$A$,假设$A$具有对应于特征向量的$u_{k}\left(k=1,2,3\right)$,则有&lt;/p&gt;
$$\frac{\partial\lambda_k}{\partial{p}_i}=\frac2N({p}_i-\bar{{p}})^T{u}_k{u}_k^T$$&lt;p&gt;其中,$\bar{p}$是$N$个点的均值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;证明如下&lt;/strong&gt;：假设点$p_i= [x_{i} \quad y_{i} \quad z_{i}]^{T}$以及对应的特征向量矩阵$U={[u_{1} \quad u_{2} \quad u_{3} ]}^{T}$。进一步定义$p$是$p_{i}$的一个元素，$p$是$x_{i},y_{i},z_{i}$中其中一个。协方差矩阵$A$可以分解为
$\Lambda=U^{T}AU$,其中:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Lambda$是对角矩阵，其对角线元素是特征值,
$\lambda_{1},\lambda_{2},\lambda_{3}$。&lt;/li&gt;
&lt;li&gt;$U$是一个正交矩阵，其列是$A$的特征向量$u_{1},u_{2},u_{3}$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对$\Lambda$求导可得下式：
&lt;/p&gt;
$$
\frac{\partial{}\Lambda}{\partial{p}}=\left( \frac{\partial{U}}{\partial{p}}\right)^{T}AU+U^{T}\left(\frac{\partial{A}}{\partial{p}}\right)U+U^{T}A\left(\frac{\partial{U}}{\partial{p}}\right)\tag{式1}
$$&lt;p&gt;
又因为$\Lambda=U^{T}AU$,可以推导得到&lt;/p&gt;
$$U^{T}A=\Lambda{}U^{T},AU=U\Lambda\tag{式2}$$&lt;p&gt;,将式1带入式2，可得：
&lt;/p&gt;
$$
\frac{\partial{}\Lambda}{\partial{p}}=\left( \frac{\partial{U}}{\partial{p}}\right)^{T}U\Lambda+U^{T}\left(\frac{\partial{A}}{\partial{p}}\right)U+\Lambda{}U^{T}\left(\frac{\partial{U}}{\partial{p}}\right)\tag{式3}
$$&lt;p&gt;
又因为：
&lt;/p&gt;
$$
U^{T}U=I\\
\Longrightarrow {U^{T}\frac{\partial{U}}{\partial{p}}+\left(\frac{\partial{U}}{\partial{p}}\right)^{T}U=0}\tag{式4}
$$&lt;p&gt;
由此可知，$U^{T}\frac{\partial{U}}{\partial{p}}$是一个&lt;a class=&#34;link&#34; href=&#34;https://baike.baidu.com/item/%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5/9063240&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;反对称矩阵&lt;/a&gt;，其对角线元素和0。
&lt;img src=&#34;https://wzwan-developer.github.io/p/mlcc/01/skew-symmetric-matrix.png&#34;
	width=&#34;1640&#34;
	height=&#34;268&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/mlcc/01/skew-symmetric-matrix_hu12682485345853843236.png 480w, https://wzwan-developer.github.io/p/mlcc/01/skew-symmetric-matrix_hu16826235980269994892.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;反对称矩阵的定义&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;611&#34;
		data-flex-basis=&#34;1468px&#34;
	
&gt;
因此可得:
&lt;/p&gt;
$$
\left( \frac{\partial{U}}{\partial{p}}\right)^{T}U\Lambda+\Lambda{}U^{T}\left(\frac{\partial{U}}{\partial{p}}\right)=0\tag{式5}
$$&lt;p&gt;
将式5带入式3中，可得：
&lt;/p&gt;
$$
\frac{\partial{}\Lambda}{\partial{p}}=U^{T}\left(\frac{\partial{A}}{\partial{p}}\right)U\tag{式6}
$$&lt;p&gt;
又因为$\lambda_{k}={u_{k}}^{T}Au_{k}$,代入式6可得：
&lt;/p&gt;
$$
\frac{\partial{}\lambda_{k}}{\partial{p}}={u_{k}}^{T}\left(\frac{\partial{A}}{\partial{p}}\right)u_{k}=\frac{\partial{{u_{k}}^{T}Au_{k}}}{\partial{p}}\tag{式7}
$$&lt;p&gt;
此时将标量$p$换回为向量$p_{i}$,得到下式
&lt;/p&gt;
$$
\frac{\partial{}\lambda_{k}}{\partial{p_{i}}}=\begin{bmatrix} 
\frac{\partial{{u_{k}}^{T}Au_{k}}}{\partial{x_{i}}}&amp;
\frac{\partial{{u_{k}}^{T}Au_{k}}}{\partial{y_{i}}}&amp;
\frac{\partial{{u_{k}}^{T}Au_{k}}}{\partial{z_{i}}}
\end{bmatrix}=\frac{\partial{{u_{k}}^{T}Au_{k}}}{\partial{p_{i}}}\tag{式8}
$$&lt;p&gt;
带入矩阵$A$和$\bar{p}$的定义可得：
&lt;/p&gt;
$$
\begin{align}
\frac{\partial{}\lambda_{k}}{\partial{p_{j}}}=\frac1N\sum_{i=1}^N{\frac{\partial{{u_{k}}^{T}\left({p}_j-\bar{p}\right)\left(p_j-\bar{p}\right)^Tu_{k}}}{\partial{p_{i}}}}\\
=\frac1N\sum_{j=1}^N{\frac{\partial{\left({p}_j-\bar{p}\right)^{T}{u_{k}}{u_{k}}^{T}\left(p_j-\bar{p}\right)}}{\partial{p_{i}}}}\\
=\frac1N\sum_{j=1}^N{\frac{\partial\left(\left({u_{k}}^{T}\left(p_j-\bar{p}\right)\right)^{T}\left({u_{k}}^{T}\left(p_j-\bar{p}\right)\right)\right)}{\partial{p_{i}}}}\\
=\frac1N\sum_{j=1}^N{2{\left(p_j-\bar{p}\right)^{T}u_{k}}\frac{\partial{u_{k}}^{T}\left(p_j-\bar{p}\right)}{\partial{p_{i}}}}\\
=\frac2N\sum_{j=1}^N{{\left(p_j-\bar{p}\right)^{T}u_{k}}\frac{\partial{u_{k}}^{T}\left(p_j-\bar{p}\right)}{\partial{p_{i}}}}\\
=\frac2N\sum_{j=1}^N{{\left(p_j-\bar{p}\right)^{T}u_{k}}\frac{\partial{u_{k}}^{T}\left(p_j-\left(\frac{1}{N}\sum_{i=1}^{N}p_{i}\right)\right)}{\partial{p_{i}}}}\\
=\frac2N{{\left(p_i-\bar{p}\right)^{T}u_{k}}{u_{k}}^{T}\left(I-\frac{1}{N}I\right)}+\\\frac2N\sum_{j=1,j\ne{i}}^N\left(p_j-\bar{p}\right)^{T}u_{k}{u_{k}}^{T}\left(-\frac{1}{N}I\right)\\
=\frac2N{{\left(p_i-\bar{p}\right)^{T}u_{k}}{u_{k}}^{T}\left(I-\frac{1}{N}I\right)}+\\\frac2Nu_{k}{u_{k}}^{T}\left(-\frac{1}{N}I\right)\sum_{j=1,j\ne{i}}^N\left(p_j-\bar{p}\right)^{T}\\
=\frac2N{{\left(p_i-\bar{p}\right)^{T}u_{k}}{u_{k}}^{T}\left(I-\frac{1}{N}I\right)}+\\\frac2Nu_{k}{u_{k}}^{T}\left(-\frac{1}{N}I\right)\left(\left(\sum_{j=1}^{N}(p_{j}-\bar{p})^{T}\right)-\left(p_i-\bar{p}\right)^{T}\right)\\
=\frac2N{{\left(p_i-\bar{p}\right)^{T}u_{k}}{u_{k}}^{T}\left(I-\frac{1}{N}I\right)}+\\\frac2Nu_{k}{u_{k}}^{T}\left(-\frac{1}{N}I\right)\left(0-\left(p_i-\bar{p}\right)^{T}\right)\\
=\frac2N{{\left(p_i-\bar{p}\right)^{T}u_{k}}{u_{k}}^{T}}
\end{align}\tag{式9}
$$&lt;p&gt;
其中涉及到以下公式：
&lt;/p&gt;
$$
\frac{\partial{p}_j}{\partial{p}_i}={I},(i=j)\quad\frac{\partial{p}_j}{\partial{p}_i}={0},(i\neq j)
\tag{式10}
$$&lt;h4 id=&#34;定理2&#34;&gt;定理2
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;已知：&lt;/p&gt;
$${A}=\frac1N\sum_{i=1}^N\left({p}_i-\bar{{p}}\right)\left({p}_i-\bar{{p}}\right)^T,\bar{{p}}=\frac{1}{N}\sum_{i=1}^{N}{p}_{i}$$&lt;p&gt;
对于一组点$p_{i}\left(i=1,\dots,\right)$和定义的协方差矩阵$A$,假设$A$具有对应于特征向量的$u_{k}\left(k=1,2,3\right)$,则有&lt;/p&gt;
$$\begin{aligned}\frac{\partial^{2}\lambda_{k}}{\partial{p}_{j}\partial{p}_{i}}=\begin{cases}\frac{2}{N}\biggl(\frac{N-1}{N}{u}_{k}{u}_{k}^{T}+{u}_{k}({p}_{i}-\bar{{p}})^{T}{U}{F}_{k}^{{p}_{j}}\\\\+{U}{F}_{k}^{{p}_{j}}\biggl({u}_{k}^{T}({p}_{i}-\bar{{p}})\biggr)\biggr),\quad i=j\\\\\frac{2}{N}\biggl(-\frac{1}{N}{u}_{k}{u}_{k}^{T}+{u}_{k}({p}_{i}-\bar{{p}})^{T}{U}{F}_{k}^{{p}_{j}}\\\\+{U}{F}_{k}^{{p}_{j}}\biggl({u}_{k}^{T}({p}_{i}-\bar{{p}})\biggr)\biggr),\quad i\neq j\end{cases}\end{aligned}$$&lt;p&gt; &lt;/p&gt;
$${F}_{k}^{{P}_{j}}=\begin{bmatrix}{F}_{1,k}^{{P}_{j}}\\{F}_{2,k}^{{P}_{j}}\\{F}_{3,k}^{{P}_{j}}\end{bmatrix}\in\mathbb{R}^{3\times3},\quad{U}=\begin{bmatrix}{u}_{1}&amp;{u}_{2}&amp;{u}_{3}\end{bmatrix}$$&lt;p&gt; &lt;/p&gt;
$$\left.{F}_{m,n}^{{P}_{j}}=\left\{\begin{matrix}\frac{({p}_{j}-\bar{{p}})^{T}}{N(\lambda_{n}-\lambda_{m})}({u}_{m}{u}_{n}^{T}+{u}_{n}{u}_{m}^{T}),m\neq n\\{0}_{1\times3}&amp;,m=n\end{matrix}\right.\right.$$&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;证明如下&lt;/strong&gt;：
已知协方差矩阵可被分解，且设$q$是点$p_{i}$的一个标量$x_{i},y_{i},z_{i}$之一，如下所示：
&lt;/p&gt;
$${A}={U}{\Lambda}{U}^{T} \tag{式1}$$&lt;p&gt;
首先对其求关于$q$的导数：
&lt;/p&gt;
$$\frac{\partial{A}}{\partial q}=\frac{\partial}{\partial q}\left({U}{\Lambda}{U}^{T}\right)\tag{式2}$$&lt;p&gt;
根据链式法则，右侧可以写为：
&lt;/p&gt;
$${\frac{\partial{A}}{\partial q}}={\frac{\partial{U}}{\partial q}}{\Lambda}{U}^{T}+{U}{\frac{\partial{\Lambda}}{\partial q}}{U}^{T}+{U}{\Lambda}{\frac{\partial{U}^{T}}{\partial q}} $$&lt;p&gt;
由于$\frac{\partial{U}^{T}}{\partial{q}}=\left({\frac{\partial{U}}{\partial q}}\right)^{T}$,因此式2可以变为
&lt;/p&gt;
$$\begin{align}
\frac{\partial{A}}{\partial q}=\frac{\partial{U}}{\partial q}{\Lambda}{U}^T+{U}\frac{\partial{\Lambda}}{\partial q}{U}^T+{U}{\Lambda}\left(\frac{\partial{U}}{\partial q}\right)^T\\
\Longrightarrow {U}^{T}{\frac{\partial{A}}{\partial q}}{U}={U}^{T}{\frac{\partial{U}}{\partial q}}{\Lambda}+{\frac{\partial{\Lambda}}{\partial q}}+{\Lambda}\left({\frac{\partial{U}}{\partial q}}\right)^{T}{U} 
\end{align}\tag{式3}$$&lt;p&gt;
设$C^{q}=U^{T}\frac{\partial{U}}{\partial q} $,因为$C^{q}$是反对称矩阵(由定理1的证明可知),所以有以下$C^{q}+{C^{q}}^{T}=0$,即${C^{q}}^{T}=-C^{q}$。代入式3可得：
&lt;/p&gt;
$$
{U}^{T}{\frac{\partial{A}}{\partial q}}{U}={C}^{q}{\Lambda}+{\frac{\partial{\Lambda}}{\partial q}}-{\Lambda}{C}^{q}
\tag{式4}$$&lt;p&gt;
取$C^{q}$的m行，n列可得：
&lt;/p&gt;
$$
\begin{align}
\left({U}^T\frac{\partial{A}}{\partial q}{U}\right)_{m,n}=\left(\frac{\partial\boldsymbol{\Lambda}}{\partial q}\right)_{m,n}-\left({\Lambda}{C}^q-{C}^q{\Lambda}\right)_{m,n}\\
\Longrightarrow 
\left(\frac{\partial\boldsymbol{\Lambda}}{\partial q}\right)_{m,n}=\left({U}^T\frac{\partial{A}}{\partial q}{U}\right)_{m,n}+\left({\Lambda}{C}^q-{C}^q{\Lambda}\right)_{m,n}\\
\Longrightarrow 
0=\left({U}^T\frac{\partial{A}}{\partial q}{U}\right)_{m,n}+\left({\Lambda}{C}^q-{C}^q{\Lambda}\right)_{m,n}\\
\Longrightarrow 
0=u_{m}^{T}{\frac{\partial{A}}{\partial{q}}}u_{n}+\lambda_{m}C_{m,n}^{q}-C_{m,n}^{q}\lambda_{n}\\
\Longrightarrow 
C_{m,n}^{q}\left(\lambda_{m}-\lambda_{n}\right)=-u_{m}^{T}{\frac{\partial{A}}{\partial{q}}}u_{n}\\
\Longrightarrow 
{C}_{m,n}^q=\frac{{u}_m^T\frac{\partial{A}}{\partial q}{u}_n}{\lambda_n-\lambda_m}&amp;,(\lambda_{m}\ne\lambda_{n})
\end{align}
\tag{式5}$$&lt;p&gt;
取$C^{q}$的m行，m列,由于它是反对称矩阵，所以它的对角线元素为0，即：
&lt;/p&gt;
$$\begin{align}
{C}_{m,m}^q={u}_m^T\frac{\partial{u}_m}{\partial q}\\
\Longrightarrow 
{C}_{m,m}^q=0&amp;,(m=n)
\end{align}\tag{式6}$$&lt;p&gt;
接下来求解$u_{k}$对$p_{j}$的三个分量的微积分：
&lt;/p&gt;
$$
\begin{align}
\frac{\partial u_{k}}{\partial{q}}=\frac{\partial Ue_{k}}{\partial q}
=UU^{T}\frac{\partial U}{\partial q}e_{k}
=UC^{q}e_{k}
\end{align}
\tag{式7}
$$&lt;p&gt;
其中$e_{k}$是3x1的向量，其中第k个元素是1，其它元素是0，这意味着：
&lt;/p&gt;
$$
C^{q}e_{k}=\begin{bmatrix}
 C_{1,k}^{q}\\
 C_{2,k}^{q}\\
C_{3,k}^{q}
\end{bmatrix}
\tag{式8}$$&lt;p&gt;
将$q$替换为$p_{j}$,并将式8代入可得：
&lt;/p&gt;
$$
\begin{align}
\begin{aligned}
\frac{\partial{u}_k}{\partial{p}_j}&amp; =\begin{bmatrix}\frac{\partial{U}{e}_k}{\partial x_j}&amp;\frac{\partial{U}{e}_k}{\partial y_j}&amp;\frac{\partial{U}{e}_k}{\partial z_j}\end{bmatrix} \\
&amp;=\begin{bmatrix}{U}{C}^{x_j}{e}_k&amp;{U}{C}^{y_j}{e}_k&amp;{U}{C}^{z_j}{e}_k\end{bmatrix} \\
&amp;={U}\big[{C}^{x_j}{e}_k\quad{C}^{y_j}{e}_k\quad{C}^{z_j}{e}_k\big] \\
&amp;={U}\begin{bmatrix}{C}_{1,k}^{x_j}&amp;{C}_{1,k}^{y_j}&amp;{C}_{1,k}^{z_j}\\{C}_{2,k}^{x_j}&amp;{C}_{2,k}^{y_j}&amp;{C}_{2,k}^{z_j}\\{C}_{3,k}^{x_j}&amp;{C}_{3,k}^{y_j}&amp;{C}_{3,k}^{z_j}\end{bmatrix}
\end{aligned}
\end{align}
\tag{式9}
$$&lt;p&gt;
结合式9和式5、6可有如下定义：
&lt;/p&gt;
$$
\begin{align*}
{F}_{m,n}^{{p}_{j}}=
\begin{bmatrix}{C}_{m,n}^{x_{j}}&amp;{C}_{m,n}^{y_{j}}&amp;{C}_{m,n}^{z_{j}}\end{bmatrix}\in\mathbb{R}^{1\times3},\quad m,n\in\{1,2,3\}.\\
=\begin{cases}
 \frac{{u}_m^T\frac{\partial{A}}{\partial {p_{j}}}{u}_n}{\lambda_n-\lambda_m} , \quad m\ne n \\
0,\quad m=n
\end{cases}
\end{align*}
\tag{式10}$$&lt;p&gt;将式10带入式9中可得：
&lt;/p&gt;
$$
\frac{\partial{u_{k}}}{\partial{p_{j}}}=
U\begin{bmatrix}
F_{1,k}^{p_{j}}\\
F_{2,k}^{p_{j}}\\
F_{3,k}^{p_{j}}
\end{bmatrix}
=UF_{k}^{p_{j}}\tag{式11}$$&lt;p&gt;
接下来对式10做以下化简，首先考虑$m\ne n$的情况，过程如下所示：
&lt;/p&gt;
$$
\begin{align*}
\frac{u_{m}^{T} \frac{\partial A }{\partial p_{j}} u_{n}}{\lambda_n -\lambda_m}\\
=\frac{1}{\lambda_n -\lambda_m}\cdot u_{m}^{T} \frac{\partial A }{\partial p_{j}} u_{n}\\
=\frac{1}{\lambda_n -\lambda_m}\cdot u_{m}^{T} \frac{\partial {\left({A}=\frac1N\sum_{i=1}^N\left({p}_i-\bar{{p}}\right)\left({p}_i-\bar{{p}}\right)^T\right)} }{\partial p_{j}} u_{n}\\
=\frac{1}{\lambda_n -\lambda_m}\cdot\left(\frac{1}{N}\sum_{i=1}^{N}\frac{u_{m}^{T}\left(p_{i}-\bar{p}\right)\left(p_{i}-\bar{p}\right)^{T}u_{n}}{\partial{p_j}}\right)\\
=\frac{1}{\lambda_n -\lambda_m}
\cdot\frac{1}{N}\sum_{i=1}^{N}
\left(\frac{u_{m}^{T}\left(p_{i}-\bar{p}\right)\left(p_{i}-\bar{p}\right)^{T}u_{n}}{\partial{\left(p_{i}-\bar{p}\right)}}\cdot\frac{\partial{\left(p_{i}-\bar{p}\right)}}{\partial{p_j}}\right)\\
=\frac{1}{\lambda_n -\lambda_m}
\cdot\frac{1}{N}\sum_{i=1}^{N}
\left(\left(p_{i}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\cdot\frac{\partial{\left(p_{i}-\bar{p}\right)}}{\partial{p_j}}\right)\\
=\frac{1}{\lambda_n -\lambda_m}\\
\cdot\frac{1}{N}\sum_{i=1}^{N}
\left(\left(p_{i}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\cdot
\frac{\partial{\left(p_{i}-\left(\frac{1}{N}\sum_{i=1}^{N}{p}_{i}\right)\right)}}{\partial{p_j}}\right)\\
=\frac{1}{\lambda_n -\lambda_m}\\
\cdot\frac{1}{N}\sum_{i=1}^{N}
\left(\left(p_{i}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\cdot
\frac{\partial{\left(p_{i}-\left(\frac{1}{N}\sum_{i=1}^{N}{p}_{i}\right)\right)}}{\partial{p_j}}\right)\\
=\frac{1}{\lambda_n -\lambda_m}
\frac{1}{N}\left(p_{j}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)
\cdot
\left(I-\frac{1}{N}I\right)\\
+\frac{1}{N}\sum_{i=1,i\ne{j}}^{N}{\left(\left(p_{i}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\cdot\left(-\frac{1}{N}I\right)\right)}\\
=\frac{1}{\lambda_n -\lambda_m}
\frac{1}{N}\left(p_{j}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)
\cdot
\left(I-\frac{1}{N}I\right)\\
+\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\left(-\frac{1}{N}I\right)
\frac{1}{N}\sum_{i=1,i\ne{j}}^{N}\left(p_{i}-\bar{p}\right)^{T}\\
=\frac{1}{\lambda_n -\lambda_m}
\frac{1}{N}\left(p_{j}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)
\cdot\left(I-\frac{1}{N}I\right)\\
+\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\left(-\frac{1}{N}I\right)
\left(\left(\sum_{i=1}^{N}(p_{i}-\bar{p})^{T}\right)-\left(p_j-\bar{p}\right)^{T}\right)\\
=\frac{1}{\lambda_n -\lambda_m}
\frac{1}{N}\left(p_{j}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)
\cdot\left(I-\frac{1}{N}I\right)\\
+\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\left(-\frac{1}{N}I\right)
\left(0-\left(p_j-\bar{p}\right)^{T}\right)\\
=\frac{1}{\lambda_n -\lambda_m}
\frac{1}{N}\left(p_{j}-\bar{p}\right)^{T}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)\\
=\frac{\left(p_{j}-\bar{p}\right)^{T}}{\left(\lambda_n -\lambda_m\right)N}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right)
\end{align*}
\tag{式12}$$&lt;p&gt;
其中涉及到以下公式：
&lt;/p&gt;
$$
\frac{\partial{p}_j}{\partial{p}_i}={I},(i=j)\quad\frac{\partial{p}_j}{\partial{p}_i}={0},(i\neq j)
\tag{式13}$$$$
\frac{\partial {a}^\top{x}{x}^\top{b}}{\partial {x}}={x}^\top\left({a}{b}^\top+{b}{a}^\top\right)
\tag{式14}$$&lt;p&gt;
结合$m=n$的情况，${F}_{m,n}^{{p}_{j}}$的简化结果如下所示：
&lt;/p&gt;
$$
F_{m,n}^{p_{j}}=
\begin{cases}
 \frac{\left(p_{j}-\bar{p}\right)^{T}}{\left(\lambda_n -\lambda_m\right)N}\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\right),\quad m\ne n\\
0,\quad m=n
\end{cases}
\tag{式15}$$&lt;p&gt;
此时，开始求解二阶导数：
&lt;/p&gt;
$$
\begin{align*}
\frac{\partial}{\partial{p_{j}}}\left(\frac{\partial{\lambda_k}}{\partial{p_{i}}}\right)
=\frac{\partial{\frac2N\left({{\left(p_i-\bar{p}\right)^{T}u_{k}}{u_{k}}^{T}}\right)^{T}}}{\partial{p_{j}}}\\
=\frac{2}{N}\cdot\frac{\partial{u_{k}{u_{k}}^{T}\left(p_i-\bar{p}\right)}}{\partial{p_{j}}}\\
=\frac{2}{N}\cdot\left({\frac{\partial {u_{k}}}{\partial{p_j}}u_{k}^{T}\left(p_i-\bar{p}\right)}+u_{k}\frac{\partial{u_{k}^{T}\left(p_i-\bar{p}\right)}}{p_j}\right)\\
=\frac{2}{N}\cdot\left(\frac{\partial {u_{k}}}{\partial{p_j}}u_{k}^{T}\left(p_i-\bar{p}\right)
+u_{k}u_{k}^{T}\frac{\partial{\left(p_i-\bar{p}\right)}}{p_j}
+u_{k}\left(p_i-\bar{p}\right)^{T}\frac{\partial{u_k}}{p_j}\right)\\
=\frac{2}{N}\cdot\left(UF_{k}^{p_j}u_{k}^{T}\left(p_i-\bar{p}\right)
+u_{k}u_{k}^{T}\frac{\partial{\left(p_i-\bar{p}\right)}}{p_j}
+u_{k}\left(p_i-\bar{p}\right)^{T}UF_{k}^{p_j}
\right)\\
=\begin{cases}
\frac{2}{N}\cdot\left(UF_{k}^{p_j}u_{k}^{T}\left(p_i-\bar{p}\right)
+u_{k}u_{k}^{T}\frac{N-1}{N}I
+u_{k}\left(p_i-\bar{p}\right)^{T}UF_{k}^{p_j}
\right),\quad i=j \\
\frac{2}{N}\cdot\left(UF_{k}^{p_j}u_{k}^{T}\left(p_i-\bar{p}\right)
+u_{k}u_{k}^{T}\frac{-1}{N}I
+u_{k}\left(p_i-\bar{p}\right)^{T}UF_{k}^{p_j}
\right),\quad i \ne j
\end{cases}
\end{align*}
\tag{式16}
$$&lt;p&gt;
其中同样涉及到式13。&lt;/p&gt;
&lt;h4 id=&#34;推导过程&#34;&gt;推导过程
&lt;/h4&gt;&lt;p&gt;回顾代价函数为&lt;/p&gt;
$$\arg\min_{\mathcal{S},\mathcal{E}_{L}}\sum_{l}^{}\lambda_{3}(A_{l})\tag{式1}$$&lt;p&gt;
，优化问题是非线性的，通过迭代求解，每次迭代中，代价函数被二阶近似，具体的说，我们将$\lambda_3$视为包含所有点${^G}p$的函数，其中
$^{G}p$是一个列向量，每个点$^{G}p_{k}\in\mathcal{P}_{l}$，即：
&lt;/p&gt;
$$
^{G}p=\begin{bmatrix}{^{G}p_{1}^{T}} \quad {^{G}p_{2}^{T}} \quad \cdots \quad {^{G}p_{N_{l}}^{T}} \end{bmatrix}\in\mathbb{R} ^{3N_{l}}
\tag{式2}
$$&lt;p&gt;
。$\lambda{(^Gp)}$可被近似为：
&lt;/p&gt;
$$
\lambda_{3}\left(^{G}{p}+\delta^{G}{p}\right)\approx\lambda_{3}\left(^{G}{p}\right)+{J}\cdot\delta^{G}{p}+\frac{1}{2} \delta^{G}{p}^{T}\cdot{H}\cdot\delta^{G}{p}
\tag{式3}
$$&lt;p&gt;假设第$k$个点$^Gp_{k}$在时间$t_j$由雷达$L_i$扫描，则有：
&lt;/p&gt;
$$
\begin{align*}
^Gp_k={^{G}_{L_i}T}_{t_j}p_k={^{G}_{L_0}T}_{t_j}\cdot {^{L_{0}}_{L_i}T}\cdot p_{k}\\
={^{G}_{L_0}R_{t_j}}\left({^{L_0}_{L_i}R\cdot {p_k}+{^{L_0}_{L_i}t}}\right)+{^G_{L_i}t_{t_j}}
\end{align*}
\tag{式4}
$$&lt;p&gt;
表明$^Gp_k$依赖于$\mathcal{S}$和$\mathcal{E}_L$。为了扰动$^Gp_k$,我们在位姿$T$的进行扰动，
记为$\delta{T}=\begin{bmatrix}\phi{^T}\quad\delta{t}^T \end{bmatrix}^T\in\mathbb{R}^6$，
于在流形上的扰动可以参考论文&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1812.01537&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《A micro Lie theory for state estimation in robotics》&lt;/a&gt;。
&lt;/p&gt;
$$
T=(R,t)\quad ,T \boxplus\delta{T}=\left(R\exp(\phi^{\wedge} ),t+\delta{t}\right)
\tag{式5}
$$&lt;p&gt;
。将上式带入到代价函数式1中，可得：
&lt;/p&gt;
$$
\begin{align*}
{}^{G}{p}_{k}+\delta^{G}{p}_{k}=
{}_{L_{0}}^{G}R_{t_{j}}\exp\big({}_{L_{0}}^{G}\phi_{t_{j}}^{\wedge}\big)
\bigg({}_{L_{i}}^{L_{0}}R\exp\big({}_{L_{i}}^{L_{0}}\phi^{\wedge}\big)p_{k}
+{}_{L_{i}}^{L_{0}}{t}+\delta_{L_{i}}^{L_{0}}{t}\bigg)\\
+{}_{L_{0}}^{G}{t}_{t_{j}}
+\delta_{L_{0}}^{G}{t}_{t_{j}}\\
={}_{L_{0}}^{G}R_{t_{j}}\big(I+{}_{L_{0}}^{G}\phi_{t_{j}}^{\wedge}\big)
\bigg({}_{L_{i}}^{L_{0}}R\big(I+{}_{L_{i}}^{L_{0}}\phi^{\wedge}\big)p_{k}
+{}_{L_{i}}^{L_{0}}{t}+\delta_{L_{i}}^{L_{0}}{t}\bigg)\\
+{}_{L_{0}}^{G}{t}_{t_{j}}+\delta_{L_{0}}^{G}{t}_{t_{j}}\\
={}_{L_{0}}^{G}{R}_{t_{j}}\big(I+{}_{L_{0}}^{G}\phi_{t_{j}}^{\wedge}\big)
\bigg({}_{L_{i}}^{L_{0}}Rp_{k}+{}_{L_{i}}^{L_{0}}R{}_{L_{i}}^{L_{0}}\phi^{\wedge}p_{k}
+{}_{L_{i}}^{L_{0}}{t}+\delta_{L_{i}}^{L_{0}}{t}\bigg)\\
+{}_{L_{0}}^{G}{t}_{t_{j}}+\delta_{L_{0}}^{G}{t}_{t_{j}}\\
\approx{}_{L_{0}}^{G}R_{t_{j}}\big({}_{L_{i}}^{L_{0}}R\cdot{p_{k}}+{}_{L_{0}}^{G}{t}_{t_{j}}\big)
+{}_{L_{0}}^{G}R_{t_{j}}\big({}_{L_{i}}^{L_{0}}R{}_{L_{i}}^{L_{0}}\phi^{\wedge}p_{k}
+\delta_{L_{i}}^{L_{0}}{t}\big)\\
+{}_{L_{0}}^{G}R_{t_{j}}{}_{L_{0}}^{G}\phi_{t_{j}}^{\wedge}
\bigg({}_{L_{i}}^{L_{0}}Rp_{k}+{}_{L_{i}}^{L_{0}}{t}\bigg)\\
+{}_{L_{0}}^{G}{t}_{t_{j}}+\delta_{L_{0}}^{G}{t}_{t_{j}}\\
\approx{}_{L_{0}}^{G}R_{t_{j}}\big({}_{L_{i}}^{L_{0}}R\cdot{p_{k}}
+{}_{L_{0}}^{G}{t}_{t_{j}}\big)+{}_{L_{0}}^{G}{t}_{t_{j}}
+{}_{L_{0}}^{G}R_{t_{j}}\big(I\cdot{}_{L_{i}}^{L_{0}}\phi^{\wedge}p_{k}
+\delta_{L_{i}}^{L_{0}}{t}\big)\\
+{}_{L_{0}}^{G}R_{t_{j}}{}_{L_{0}}^{G}\phi_{t_{j}}^{\wedge}
\bigg({}_{L_{i}}^{L_{0}}Rp_{k}
+{}_{L_{i}}^{L_{0}}{t}\bigg)+\delta_{L_{0}}^{G}{t}_{t_{j}}\\
\approx{}_{L_{0}}^{G}R_{t_{j}}\big({}_{L_{i}}^{L_{0}}R\cdot{p_{k}}
+{}_{L_{0}}^{G}{t}_{t_{j}}\big)+{}_{L_{0}}^{G}{t}_{t_{j}}\\
+{}_{L_0}^GR_{t_j}\left(p_k\right)^{\wedge}\cdot_{L_i}^{L_0}\phi+_{L_0}^GR_{t_j}\delta_{L_i}^{L_0}t
+{}_{L_{0}}^{G}R_{t_{j}}
\bigg({}_{L_{i}}^{L_{0}}Rp_{k}
+{}_{L_{i}}^{L_{0}}{t}\bigg)^{\wedge}{}_{L_{0}}^{G}\phi_{t_{j}}+\delta_{L_{0}}^{G}{t}_{t_{j}}
\end{align*}
\tag{式6}
$$&lt;p&gt;
然后，结合式4和式6可得$\delta{^Gp_k}$，如下所示：
&lt;/p&gt;
$$
\begin{align*}
\delta^{G}{p}_{k}\approx{}_{L_{0}}^{G}R_{t_{j}}
\big({}_{L_{i}}^{L_{0}}{R}{p}_{k}+{}_{L_{i}}^{L_{0}}{t}\big)^{\wedge}{}_{L_{0}}^{G}\phi_{t_{j}}
+\delta_{L_{0}}^{G}{t}_{t_{j}}+\\{}_{L_{0}}^{G}R_{t_{j}}\big({p}_{k}\big)^{\wedge}{}_{L_{i}}^{L_{0}}\phi
+{}_{L_{0}}^{G}{R}_{t_{j}}\delta_{L_{i}}^{L_{0}}{t}\\
=D\cdot \delta x ,
\end{align*}
\tag{式7}
$$&lt;p&gt;
其中$\delta{x}=\begin{bmatrix}\cdots \quad {^G_{L_0}\phi_{t_j}^{T}\quad\delta_{L_0}^{G}t_{t_j}^T}\cdots{^{L_{0}}_{L_i}\phi^{T}\quad\delta_{L_i}^{L_0}t^T} \cdots\end{bmatrix}^{T}
\ne\mathbb{R}^{6\left(m+n-2\right)}$是优化变量$x=\begin{bmatrix}\cdots{_{L_0}^GR_{t_j} }\quad{_{L_0}^{G}t_{t_j}}\cdots{_{L_0}^{L_i}R}\quad{_{L_0}^{L_i}t}\cdots\end{bmatrix}$的微小扰动。&lt;/p&gt;
&lt;p&gt;并且
&lt;/p&gt;
$$\begin{align*}
D =\begin{bmatrix}\vdots&amp;\vdots\\\cdots {D}_{k,p}^{\mathcal{S}}&amp;\cdots {D}_{k,q}^{\varepsilon_{L}}&amp;\cdots\\\vdots&amp;\vdots\end{bmatrix}\in\mathbb{R}^{3N_{l}\times6(m+n-2)} \\
\mathrm{D}_{k,p}^{\mathcal{S}}
\begin{cases}
\begin{bmatrix}{-{}_{L_{0}}^{G}{R}_{t_{j}}}\left({}_{L_{i}}^{L_{0}}{R}{p}_{k}+{}_{L_{i}}^{L_{0}}{t}\right)^{\wedge}&amp;{I}\end{bmatrix},\quad{\mathrm{if} p=j}\\
{0}_{3\times6},\quad {else}
\end{cases}\\
\mathrm{D}_{k,q}^{\mathcal{E}_{L}} 
\begin{cases}
\begin{bmatrix}{-{}_{L_{0}}^{G}{R}_{t_{j}}}{}_{L_{i}}^{L_{0}}{R}({p}_{k})^{\wedge}&amp;{}_{L_{0}}^{G}{R}_{t_{j}}\end{bmatrix},\quad{\mathrm{if~}q=i}\\
{0}_{3\times6},\quad {else}
\end{cases}
\end{align*}
$$&lt;p&gt;
&lt;em&gt;&lt;span style=&#34;color:red&#34;&gt;注意：&lt;/span&gt;&lt;/em&gt; 论文中的结果与推导有差异，下面是论文给的结果，&lt;span style=&#34;color:blue;&#34;&gt;待排查！&lt;/span&gt;
&lt;/p&gt;
$$\delta^{G}{p}_{k}\approx{}_{L_{0}}^{G}R_{t_{j}}
\big({}_{L_{i}}^{L_{0}}{R}{p}_{k}+{}_{L_{i}}^{L_{0}}{t}\big)^{\wedge}{}_{L_{0}}^{G}\phi_{t_{j}}
+\delta_{L_{0}}^{G}{t}_{t_{j}}+\\{}_{L_{\color{red}i}}^{G}R_{t_{j}}\big({p}_{k}\big)^{\wedge}{}_{L_{i}}^{L_{0}}\phi
+{}_{L_{0}}^{G}{R}_{t_{j}}\delta_{L_{i}}^{L_{0}}{t}$$&lt;p&gt;上面用到一些近似化：
&lt;/p&gt;
$$
\exp(\phi^{\wedge})\approx I+\phi^{\wedge}\tag{式8}
$$&lt;p&gt;
结合式3到式7有以下结论：
&lt;/p&gt;
$$
\begin{align*}
\begin{gathered}
\lambda_{3}({x}\boxplus\delta{x}) \approx\lambda_{3}({x})+{JD}\delta{x}+\frac{1}{2}
\delta{x}^{T}{D}^{T}{HD}\delta{x} \\
=\lambda_{3}({x})+{\bar{J}}\delta{x}+\frac{1}{2}\delta{x}^{T}{\bar{H}}\delta{x}. 
\end{gathered}
\end{align*}
\tag{式9}
$$&lt;p&gt;
根据定理1和定理2的结论可知：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$J$为雅可比矩阵，其中第$i$个元素按照定理1计算；&lt;/li&gt;
&lt;li&gt;$H$为Hessian矩阵，其中第$i$行，第$j$列元素按照定理2计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;并可得且LM算法的增量公式为$\left(\bar{H}(^{G}p+\mu I)\right)\delta{^Gp^{\ast}}=-\bar{J}(^Gp)^T$。&lt;/p&gt;
&lt;h2 id=&#34;代码详解&#34;&gt;代码详解
&lt;/h2&gt;&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;&lt;p&gt;[1]&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2109.06550&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《Targetless Extrinsic Calibration of Multiple Small FoV LiDARs and Cameras using Adaptive Voxelization》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2]&lt;a class=&#34;link&#34; href=&#34;https://www.arxiv.org/pdf/2010.08215&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《BALM: Bundle Adjustment for Lidar Mapping》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3]&lt;a class=&#34;link&#34; href=&#34;http://epsilonjohn.club/2020/11/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/BALM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《BALM论文阅读》——epsilonjohn的博客文章&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4]&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1812.01537&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《A micro Lie theory for state estimation in robotics》&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>如何理解概率论中的“矩”</title>
        <link>https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/</link>
        <pubDate>Mon, 09 Sep 2024 11:12:48 +0800</pubDate>
        
        <guid>https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/</guid>
        <description>&lt;img src="https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/gaussian-normal-distribution-graph.png" alt="Featured image of post 如何理解概率论中的“矩”" /&gt;&lt;h2 id=&#34;概率论中的矩&#34;&gt;概率论中的“矩”
&lt;/h2&gt;&lt;h3 id=&#34;彩票的问题&#34;&gt;彩票的问题
&lt;/h3&gt;&lt;p&gt;假设福利彩票，每一注两元钱，且中奖的概率分布如下：
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph1.png&#34;
	width=&#34;359&#34;
	height=&#34;402&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph1_hu7074458194076008173.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph1_hu11398514835930632876.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;概率分布图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;89&#34;
		data-flex-basis=&#34;214px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;其中，概率的“称”如下所示：
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph2.png&#34;
	width=&#34;613&#34;
	height=&#34;402&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph2_hu1581581583894811490.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph2_hu3775081096410037377.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;概率的称&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;365px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;此时我们称量一下中奖500万元：
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph3.png&#34;
	width=&#34;613&#34;
	height=&#34;402&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph3_hu9993873231620659325.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph3_hu8003149627366197390.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;500万元&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;365px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;上述结果表明：不确定的500万元等价于确定的0.5元。此时将所有的中奖概率刻画上去：
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph4.png&#34;
	width=&#34;613&#34;
	height=&#34;402&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph4_hu8029704338762354472.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph4_hu18134410058688724433.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;365px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;上述结果等于&lt;/p&gt;
$$1.5 = 5\times 10\% + 100\times0.5\% + 5000000\times0.000001\% $$&lt;p&gt;
结果表明一张彩票成本两元，但是期望获得的收益为1.5元，每买一张都会亏损0.5元。&lt;/p&gt;
&lt;h2 id=&#34;矩&#34;&gt;“矩”
&lt;/h2&gt;&lt;h3 id=&#34;一阶矩&#34;&gt;一阶矩
&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;上述我们计算的就是概率的一阶矩，也就是期望（expectation/mean）。
&lt;/code&gt;&lt;/pre&gt;
$$
E[X]=\sum p_{i}x_{i}
$$&lt;p&gt;含义如下：
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph5.png&#34;
	width=&#34;572&#34;
	height=&#34;402&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph5_hu18168430126999916666.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/graph5_hu8960376600484578208.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;”期望含义“&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;341px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;二阶矩&#34;&gt;二阶矩
&lt;/h3&gt;&lt;p&gt;二阶矩是广为认知的协方差矩阵$\Sigma$
&lt;/p&gt;
$$
    \Sigma=E[(X-\mu)^{2}]=\sum_{i}p_{i}(x_{i}-\mu)^{2}
$$&lt;h3 id=&#34;高阶矩&#34;&gt;高阶矩
&lt;/h3&gt;&lt;p&gt;三阶矩称为偏度，四阶矩称为峰度。各有用途但是共同的特点为称量之后才能使用。&lt;/p&gt;
&lt;h2 id=&#34;参考链接&#34;&gt;参考链接
&lt;/h2&gt;&lt;p&gt;[1]&lt;a class=&#34;link&#34; href=&#34;https://matongxue.blog.csdn.net/article/details/109766892&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;如何理解概率论中的“矩”？&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>舒尔补</title>
        <link>https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_02/</link>
        <pubDate>Mon, 02 Sep 2024 23:51:06 +0800</pubDate>
        
        <guid>https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_02/</guid>
        <description>&lt;img src="https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_02/gaussian-normal-distribution-graph.png" alt="Featured image of post 舒尔补" /&gt;&lt;h2 id=&#34;舒尔补定义&#34;&gt;舒尔补定义
&lt;/h2&gt;&lt;p&gt;给定任意的矩阵块 $M$ ，如下所示：&lt;/p&gt;
$$M=\begin{bmatrix} A &amp; B\\  C &amp;D\\ \end{bmatrix}$$&lt;ul&gt;
&lt;li&gt;如果，矩阵块 $D$ 是可逆的，则 $A − B D^{-1}  C$称之为 $D$ 关于 $M$的舒尔补。&lt;/li&gt;
&lt;li&gt;如果，矩阵块 $A$ 是可逆的，则 $D − CA^{-1}  B$称之为 $A$ 关于 $M$的舒尔补。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;舒尔补的定理推导&#34;&gt;舒尔补的定理推导
&lt;/h2&gt;&lt;p&gt;将$M$矩阵分别变成上三角或者下三角：
&lt;/p&gt;
$$\begin{bmatrix}I &amp; 0\\ -CA^{-1} &amp;I\\\end{bmatrix}
\begin{bmatrix}A &amp; B\\ C &amp; D\end{bmatrix}=\begin{bmatrix}A &amp; B\\ 0 &amp; \Delta _{A}\end{bmatrix}$$$$\begin{bmatrix}A &amp; B\\ C&amp;D\end{bmatrix}
\begin{bmatrix}I &amp; -A^{-1}B\\  0&amp;I\\\end{bmatrix}=
\begin{bmatrix}A &amp; 0\\ C &amp; \Delta _{A}\end{bmatrix}$$&lt;p&gt;其中${\Delta _{A} =D-CA^{-1}B }$。联合起来，将${M}$变形为对角形：
&lt;/p&gt;
$$\begin{bmatrix}I &amp; 0\\ -CA^{-1} &amp;I\\\end{bmatrix}
\begin{bmatrix}A &amp; B\\ C &amp; D\end{bmatrix}
\begin{bmatrix}I &amp; -A^{-1}B\\  0&amp;I\\\end{bmatrix}=
\begin{bmatrix}A &amp; 0\\ 0 &amp; \Delta _{A}\end{bmatrix}
$$&lt;p&gt;
反过来亦可从对角矩阵恢复${M}$:
&lt;/p&gt;
$$\begin{bmatrix}I &amp; 0\\ CA^{-1} &amp;I\\\end{bmatrix}
\begin{bmatrix}A &amp; 0\\ 0&amp; \Delta _{A}\end{bmatrix}
\begin{bmatrix}I &amp; A^{-1}B\\  0&amp;I\\\end{bmatrix}=
\begin{bmatrix}A &amp; B\\ C &amp; D\ \end{bmatrix}
$$&lt;h2 id=&#34;用途&#34;&gt;用途
&lt;/h2&gt;&lt;h3 id=&#34;快速求矩阵的逆&#34;&gt;快速求矩阵的逆
&lt;/h3&gt;&lt;p&gt;矩阵${M}$可以改写为：
&lt;/p&gt;
$$M=\begin{bmatrix}A &amp; B\\ C&amp;D\end{bmatrix}=\begin{bmatrix}I &amp; 0\\ CA^{-1} &amp;I\\\end{bmatrix}
\begin{bmatrix}A &amp; 0\\ 0&amp; \Delta _{A}\end{bmatrix}
\begin{bmatrix}I &amp; A^{-1}B\\  0&amp;I\\\end{bmatrix}$$$$M^{-1}=\begin{bmatrix}A &amp; B\\ C&amp;D\end{bmatrix}^{-1}=\begin{bmatrix}I &amp; 0\\ CA^{-1} &amp;I\\\end{bmatrix}^{-1}\begin{bmatrix}A^{-1} &amp; 0\\ 0&amp; \Delta _{A}^{-1}\end{bmatrix}\begin{bmatrix}I &amp; A^{-1}B\\  0&amp;I\\\end{bmatrix}^{-1}\\  =\begin{bmatrix}I &amp; 0\\ -CA^{-1} &amp;I\\\end{bmatrix}\begin{bmatrix}A^{-1} &amp; 0\\ 0&amp; \Delta _{A}^{-1}\end{bmatrix}\begin{bmatrix}I &amp; -A^{-1}B\\  0&amp;I\\\end{bmatrix}\\=\begin{bmatrix}A^{-1}+A^{-1}B{\Delta _A}^{-1}CA^{-1}&amp;-A^{-1}B{\Delta _A}^{-1}\\-{\Delta _A}^{-1}CA^{-1}&amp;{\Delta _A}^{-1} \end{bmatrix}
$$&lt;h3 id=&#34;舒尔补在信息矩阵求解中的使用&#34;&gt;舒尔补在信息矩阵求解中的使用
&lt;/h3&gt;&lt;p&gt;协方差矩阵&lt;/p&gt;
$$\sum=\begin{bmatrix}A &amp; C^{T}\\C&amp;D\end{bmatrix}$$&lt;p&gt;,
则信息矩阵&lt;/p&gt;
$$\sum^{-1}=\begin{bmatrix}A&amp;C^{T}\\C&amp;D\end{bmatrix}^{-1}\\=\begin{bmatrix}A^{-1}+A^{-1}C^{T}{\Delta _A}^{-1}CA^{-1}&amp;-A^{-1}C^{T}{\Delta _A}^{-1}\\-{\Delta _A}^{-1}CA^{-1}&amp;{\Delta _A}^{-1} \end{bmatrix}\\\stackrel{\triangle}{=}\begin{bmatrix}\Lambda_{aa}&amp;\Lambda _{ab}\\\Lambda _{ba}&amp;\Lambda _{bb} \end{bmatrix}$$&lt;p&gt;
其中，由上式可推导得$A^{-1}=\Lambda _{aa}-\Lambda _{ab}\Lambda _{bb}^{-1}\Lambda _{ba}$, 以及$D^{-1}=\Lambda _{bb}-\Lambda _{ba}\Lambda _{aa}^{-1}\Lambda _{ab}$，它们即为下次优化会使用的先验信息矩阵（边际概率的信息矩阵）。&lt;/p&gt;
&lt;h3 id=&#34;通过舒尔补分解多元高斯分布&#34;&gt;通过舒尔补分解多元高斯分布
&lt;/h3&gt;&lt;p&gt;假设多元变量$M$服从高斯分布，且由两部分组成：&lt;/p&gt;
$$ x=\begin{bmatrix}a\\b\end{bmatrix} $$&lt;p&gt;,变量构成的协方差矩阵等于&lt;/p&gt;
$$\sum=\begin{bmatrix} A &amp; C^{T} \\C&amp;D \end{bmatrix}$$&lt;p&gt;,其中$A=cov(a,a)$,$C=cov(a,b)$,$D=cov(b,b)$。
则$x$的概率分布为：
&lt;/p&gt;
$$P(a,b)=P(a)P(b|a)\propto exp(-\frac{1}{2} \begin{bmatrix}a\\b\end{bmatrix}^{T}\begin{bmatrix}A&amp;C^{T}\\C&amp;D\end{bmatrix}^{-1}\begin{bmatrix}a&amp;b\end{bmatrix})$$&lt;p&gt;。使用上一节内容将矩阵转化为对角矩阵
&lt;/p&gt;
$$ \begin{align}
P(a,b) \\ 
\propto  exp\left (  -\frac{1}{2}\begin{bmatrix}a\\b\end{bmatrix}^{T}\begin{bmatrix}A&amp;C^{T}\\C&amp;D\end{bmatrix}^{-1}\begin{bmatrix}a&amp;b\end{bmatrix}\right) \\
  \propto exp \left( -\frac{1}{2}\begin{bmatrix}a\\b\end{bmatrix}^{T}\begin{bmatrix}I &amp; 0\\ -CA^{-1} &amp;I\\\end{bmatrix}\begin{bmatrix}A^{-1} &amp; 0\\ 0&amp; \Delta _{A}^{-1}\end{bmatrix}\begin{bmatrix}I &amp; -A^{-1}B\\  0&amp;I\\\end{bmatrix}\begin{bmatrix}a&amp;b\end{bmatrix})\right )\\
  \propto exp\left( -\frac{1}{2}\begin{bmatrix}a^{T}&amp;(b-CA^{-1}a)^{T}\end{bmatrix}\begin{bmatrix}A^{-1}&amp;0\\0&amp;{\Delta _A^{-1}}\end{bmatrix}\begin{bmatrix}a\\b-CA^{-1}a\end{bmatrix}\right)\\
  \propto exp \left( -\frac{1}{2}(a^TA^{-1}a)+(b-CA^{-1}a)^{T} \Delta _A^{-1}(b-CA^{-1}a) \right)\\
  \propto exp \left( -\frac{1}{2}a^{T}A^{-1}a\right)exp \left ( -\frac{1}{2}(b-CA^{-1}a)^{T}\Delta _A^{-1}(b-CA^{-1}a)\right)\\
  \propto P(a)P(b|a)
  \\\end{align}$$&lt;p&gt;
在《机器人学中的状态估计》2.2.3章节&amp;quot;联合概率密度函数，分解与推断&amp;quot;可见相似内容,其实就是高斯推断，套用相关模型$P(a)$是观测（边际概率），$P(b|a)$是后验概率，$P(a|b)$是传感器模型。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>边缘化</title>
        <link>https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/</link>
        <pubDate>Mon, 02 Sep 2024 00:00:00 +0000</pubDate>
        
        <guid>https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/</guid>
        <description>&lt;img src="https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/gaussian-normal-distribution-graph.png" alt="Featured image of post 边缘化" /&gt;&lt;h2 id=&#34;从优化角度理解边缘化&#34;&gt;从优化角度理解边缘化
&lt;/h2&gt;&lt;h3 id=&#34;模型&#34;&gt;模型
&lt;/h3&gt;&lt;p&gt;优化问题具有如下通用形式：
$ HX=b $
并且可以拆解成如下的形式：
&lt;/p&gt;
$$\begin{bmatrix}H_{mm}&amp;H_{mr}\\H_{rm}&amp;H_{rr}\end{bmatrix}\begin{bmatrix}X_m\\X_r\end{bmatrix}=\begin{bmatrix}b_m\\b_r\end{bmatrix} $$&lt;p&gt;
拆解的目的是通过边缘化将$X_m$从状态量里删除掉，但是要保留它的约束。在划窗模式里，这个$X_m$为要边缘化掉的量。&lt;/p&gt;
&lt;h3 id=&#34;过程&#34;&gt;过程
&lt;/h3&gt;&lt;p&gt;对$H$矩阵利用&lt;a class=&#34;link&#34; href=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_02/&#34; &gt;舒尔补&lt;/a&gt; 进行三角化，如下所示：
&lt;/p&gt;
$$\begin{bmatrix}I&amp;0\\-H_{rm}H_{mm}^{-1}&amp;I\end{bmatrix}\begin{bmatrix}H_{mm}&amp;H_{mr}\\H_{rm}&amp;H_{rr}\end{bmatrix}\begin{bmatrix}X_m\\X_r\end{bmatrix}=\begin{bmatrix}I&amp;0\\-H_{rm}H_{mm}^{-1}&amp;I\end{bmatrix}\begin{bmatrix}b_m\\b_r\end{bmatrix}$$&lt;p&gt;
化简可得：
&lt;/p&gt;
$$\begin{bmatrix}H_{mm}&amp;H_{mr}\\0&amp;H_{rr}-H_{rm}H_{mm}^{-1}H_{mr}\end{bmatrix}\begin{bmatrix}X_m\\X_r\end{bmatrix}=\begin{bmatrix}b_m\\b_r-H_{rm}H_{mm}^{-1}b_m\end{bmatrix}$$&lt;p&gt;
由上式可得：
&lt;/p&gt;
$$(H_{rr}-H_{rm}H_{mm}^{-1}H_{mr})X_r=b_r-H_{rm}H_{mm}^{-1}b_{m}$$&lt;p&gt;
意义：此时可以不依赖$X_m$求解出$X_r$,若我们只关心$X_r$的值，则可以把$X_m$从模型中删除。&lt;/p&gt;
&lt;h2 id=&#34;从滤波角度理解边缘化&#34;&gt;从滤波角度理解边缘化
&lt;/h2&gt;&lt;h3 id=&#34;模型-1&#34;&gt;模型
&lt;/h3&gt;&lt;p&gt;运动模型和观测模型定义（可见《机器人学中的状态估计》3.3.1 ”问题定义“章节）
如下：
&lt;/p&gt;
$$\begin{align}
x_k=A_{k-1}x_{k-1}+v_k+w_k,&amp;k=1...K\\
y_k=C_kx_k+n_k,&amp;k=0...K
\end{align}$$&lt;h3 id=&#34;map估计角度&#34;&gt;MAP估计角度
&lt;/h3&gt;&lt;p&gt;优化目标函数定义（详情参考《机器人学中的状态估计》3.1.2 &amp;ldquo;最大后验估计&amp;rdquo; 章节）如下：
&lt;/p&gt;
$$\hat{x}=arg\underset{x}{min} J(x)$$&lt;p&gt;
其中$J(x)=\sum_{k=0}^{K}(J_{v,k}(x)+J_{y,k}(x)$,$J_{v,k}(x))$见式(3.9.a),$J_{y,k}(x)$见式(3.9.b)。
再次对形式进行以下提升，将所有时刻的状态整理为向量x,并把所有时刻已知数据整理为z。对问题进行一定的简化，可得
$J(x)=\frac{1}{2}\left(z-Hx \right)^{T}W^{-1}(z-Hx)$（式3.14）
对其进行求解最小值，可求解它的一阶导数，并使一阶导为0；
&lt;/p&gt;
$${\frac{\partial J(x)}{\partial x^{T}}}|_x=-H^{T}W^{-1}(z-H\hat{x})=0 \Rightarrow (H^{T}W^{-1}H)\hat{x}=H^{T}W^{-1}z$$&lt;p&gt;
&lt;em&gt;注：此时形式以及是接近优化角度的$HX=b$。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;滤波角度&#34;&gt;滤波角度
&lt;/h3&gt;&lt;p&gt;由于马尔可夫性，当前时刻仅与前一时刻有关，由此再次参考 3.3.2章节 &amp;ldquo;通过MAP推导卡尔曼滤波&amp;rdquo;，
假设已经有了k-1时刻的后验估计&lt;/p&gt;
$$ \{ \hat {x}_{k-1} ,\hat{P}_{k-1}\}$$&lt;p&gt;,目标是计算&lt;/p&gt;
$$ \{ \hat {x}_{k} ,\hat{P}_{k}\}$$&lt;p&gt;，我们使用k-1时刻的后验估计加上k时刻的$v_k$,$y_k$来估计&lt;/p&gt;
$$ \{ \hat {x}_{k} ,\hat{P}_{k}\}$$&lt;p&gt;。
为了推导该过程，定义
&lt;/p&gt;
$$ z=\begin{bmatrix}\hat{x}_{k-1}\\v_k\\y_k\end{bmatrix},H=\begin{bmatrix}I&amp;&amp;\\-A_{k-1}&amp;I\\&amp;&amp;C_{k}\end{bmatrix},W=\begin{bmatrix}\hat {P}_{k-1}&amp;&amp;\\&amp;Q_k&amp;\\&amp;&amp;R_k\end{bmatrix}$$&lt;p&gt;
则模型的解为&lt;/p&gt;
$$(H_{k}^{T}W_{k}^{-1}H_{k})\hat{x}=H_{k}^{T}W_{k}^{-1}z_k$$&lt;p&gt;，
其中&lt;/p&gt;
$$\hat{x}=\begin{bmatrix}\hat{x&#39;}_{k-1}\\\hat{x}_k\end{bmatrix}$$&lt;p&gt;
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image00.png&#34;
	width=&#34;714&#34;
	height=&#34;352&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image00_hu2802948725242621933.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image00_hu16496475951586850660.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;202&#34;
		data-flex-basis=&#34;486px&#34;
	
&gt;
借助本文第一节，目标为从$x$变量中删除$\hat{x&#39;}_{k-1}$，执行舒尔补可得
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image01.png&#34;
	width=&#34;707&#34;
	height=&#34;463&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image01_hu12842677403844977782.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image01_hu10364658897043807725.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;366px&#34;
	
&gt;
&lt;img src=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image02.png&#34;
	width=&#34;1371&#34;
	height=&#34;694&#34;
	srcset=&#34;https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image02_hu7680983322299133859.png 480w, https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/image02_hu10029282904931644770.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;197&#34;
		data-flex-basis=&#34;474px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>归档</title>
        <link>https://wzwan-developer.github.io/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>https://wzwan-developer.github.io/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>搜索</title>
        <link>https://wzwan-developer.github.io/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://wzwan-developer.github.io/search/</guid>
        <description></description>
        </item>
        <item>
        <title>友情链接</title>
        <link>https://wzwan-developer.github.io/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://wzwan-developer.github.io/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
