[{"content":"理论内容 K-d树最早由Bentley Jon Louis提出,是二分树的高维度版本。 K-d 树也是二叉树的一种,任意一个 K-d 树的节点由左右两侧组成。在二分树里,可以用单个维度的信息来区分左右,但在 K-d 树里,由于要分割高维数据,会用超平面(Hyperplane)来区分左右侧(不过,对于三维点,实际上的超平面就是普通的二维平面)。在如何分割方面,则存在一些方法上的差异。下文介绍的是沿轴超平面分割(Axis-aligned Splitting Plane)。只需要沿着所有维度中任意一个轴将点云分开即可,实现起来十分简单。\n我们可以对一个任意维度的点云建立 K-d 树,称为 K-d树的构建过程,或者叫建树。随后, 可以对空间中任意一点进行k近邻查找,称为查找过程。根据查找方法的不同,K-d树也分按范围查找(Search by Range)和按 k 最近邻查找(Search by k Nearest Neighbours),二者的具体实现方法大同小异。在K-d树中,以树状结构来表达点云的结构关系,规定:\n每个点云有左右两个分枝； 叶子节点表示原始点云中的点。当然在实际存储时，可以存储点的索引而非点云本身，这样可以节省空间。 非叶子节点存储一个分割轴和分割阈值，来表达如何分割左分枝和右分枝。例如，x=1可以存储为按第一个轴，阈值为1的方式来分割。规定左侧分枝取小于号，右侧分枝取大于等于号。 按照上述约定,就可以实现 K-d树的构建算法和查找算法。下面简单描述其算法步骤,然后给出实现和结果。由于 K-d 树在数据结构上还是一种树,所以大部分算法都可以用递归的形式很简洁地实现。\nK-d树的构建 在K-d树的构建过程中,主要考虑如何对给定点云进行分割。不同分割方法的策略不同。传统的做法,或是以固定顺序来交替坐标轴1099,或是计算当前点云在各轴上的分散程度,取分散程度最大的轴作为分割轴。这里介绍后一种方法\nK-d树的构建步骤如下:\n输入:点云数据 $X={x_1,\\cdots,x_n}$,其中$x_i\\in\\mathbb{R}^{k}$。 考虑将子集$X_n\\subset X$插人节点$n$。 如果$X_n$为空,则退出。 如果$X_n$只有一个点,则记为叶子节点,退出。 计算$X_n$在各轴的方差,挑选分布最大的一个轴,记为j;取平均数$m_j = X_n[j]$作为分割阈值。 遍历 $x\\in{X_n}$,对于$x[j]","date":"2024-10-22T20:39:43+08:00","image":"https://wzwan-developer.github.io/p/nearestneighborproblem/01/title_hu18002144391777994966.png","permalink":"https://wzwan-developer.github.io/p/nearestneighborproblem/01/","title":"K-d树"},{"content":"理论内容 暴力最近邻法(Brute-force Nearest Neighbour Search,BF 最近邻搜索)是最简单直观的最近邻计算方法,无须任何辅助的数据结构。 如果我们搜索一个点的最近邻,不妨称为暴力最近邻搜索;如果搜索k个最近邻,不妨称为暴力k近邻搜索。整体而言,这是一种简单粗暴的思路。\n暴力最近邻搜索 给定点云$\\mathcal{X}$和待查找点$x_m$,计算$x_m$与$\\mathcal{X}中每个点的距离,并给出最小距离。 同理,可以类似地给出暴力k近邻的搜索方法:\n暴力k近邻（BF kNN）\n对给定点云$\\mathcal{X}$和查找点$x_m$,计算$x_m$对所有$\\mathcal{X}$点的距离。 对第1步的结果排序。 选择$k$个最近的点。 对所有$x_m$重复步骤1~3。 代码实践 暴力最近邻 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 // 单线程 /** * @brief Brute-force Nearest Neighbour * @param cloud 点云 * @param point 待查找点 * @return 找到的最近点索引 */ int bfnn_point(CloudPtr cloud, const Vec3f\u0026amp; point) { return std::min_element(cloud-\u0026gt;points.begin(), cloud-\u0026gt;points.end(), [\u0026amp;point](const PointType\u0026amp; pt1, const PointType\u0026amp; pt2) -\u0026gt; bool { return (pt1.getVector3fMap() - point).squaredNorm() \u0026lt; (pt2.getVector3fMap() - point).squaredNorm(); }) -cloud-\u0026gt;points.begin(); } /** * @brief 对点云进行BF最近邻 * @param cloud1 目标点云 * @param cloud2 被查找点云 * @param matches 两个点云内的匹配关系 * @return */ void bfnn_cloud(CloudPtr cloud1, CloudPtr cloud2, std::vector\u0026lt;std::pair\u0026lt;size_t, size_t\u0026gt;\u0026gt;\u0026amp; matches) { // 单线程版本 std::vector\u0026lt;size_t\u0026gt; index(cloud2-\u0026gt;size()); std::for_each(index.begin(), index.end(), [idx = 0](size_t\u0026amp; i) mutable { i = idx++; }); matches.resize(index.size()); //参数std::execution::seq表示使用单线程,顺序化的方式执行 std::for_each(std::execution::seq, index.begin(), index.end(), [\u0026amp;](auto idx) { matches[idx].second = idx; matches[idx].first = bfnn_point(cloud1, ToVec3f(cloud2-\u0026gt;points[idx])); }); } //多线程 void bfnn_cloud_mt(CloudPtr cloud1, CloudPtr cloud2, std::vector\u0026lt;std::pair\u0026lt;size_t, size_t\u0026gt;\u0026gt;\u0026amp; matches) { // 先生成索引 std::vector\u0026lt;size_t\u0026gt; index(cloud2-\u0026gt;size()); std::for_each(index.begin(), index.end(), [idx = 0](size_t\u0026amp; i) mutable { i = idx++; }); // 并行化for_each matches.resize(index.size()); std::for_each(std::execution::par_unseq, index.begin(), index.end(), [\u0026amp;](auto idx) { matches[idx].second = idx; matches[idx].first = bfnn_point(cloud1, ToVec3f(cloud2-\u0026gt;points[idx])); }); } 参考文献 [1]《自动驾驶与机器人中的 SLAM技术:从理论到实践》\n[2]《slam_in_autonomous_driving》——高翔老师的开源仓库\n","date":"2024-10-22T20:29:04+08:00","image":"https://wzwan-developer.github.io/p/nearestneighborproblem/00/title_hu14477640576711799521.png","permalink":"https://wzwan-developer.github.io/p/nearestneighborproblem/00/","title":"暴力最近邻法"},{"content":"文章内容 With the LiDAR extrinsic parameter $\\mathcal{E}_L$ and pose trajectory $\\mathcal{S}$ computed above, we obtain a dense global point cloud by transforming all LiDAR points to the base LiDAR frame. Then, the extrinsic $\\mathcal{E}_C$ is optimized by minimizing the summed distance between the back-projected LiDAR edge feature points and the image edge feature points. Two types of LiDAR edge points could be extracted from the point cloud. One is the depth-discontinuous edge between the foreground and background objects, and the other is the depth-continuous edge between two neighboring non-parallel planes. As explained in our previous work [28], depth-discontinuous edges suffer from foreground inflation and bleeding points phenomenon; we hence use depth-continuous edges to match the point cloud and images.\n利用上述计算得到的激光雷达外参参数 $\\mathcal{E}_L$ 和位姿轨迹 $\\mathcal{S}$，我们将所有激光雷达点转换到基准激光雷达坐标系中，从而获得一个密集的全局点云。接着，通过最小化反向投影的激光雷达边缘特征点与图像边缘特征点之间的累积距离来优化相机外参 $\\mathcal{E}_C$。可以从点云中提取两种类型的激光雷达边缘点。一种是前景和背景物体之间的深度不连续边缘；另一种是非平行邻近平面之间的深度连续边缘。正如我们先前的工作 [28] 中所解释的那样，深度不连续边缘容易出现前景膨胀和漂移点现象；因此，我们使用深度连续边缘来进行点云与图像的匹配。\nIn [28], the LiDAR point cloud is segmented into voxels with uniform sizes, and the planes inside each voxel are estimated by the RANSAC algorithm. In contrast, our method uses the same adaptive voxel map obtained in Sec. III-B. We calculate the angle between their containing plane normals for every two adjacent voxels. If this angle exceeds a threshold, the intersection line of these two planes is extracted as the depthcontinuous edge, as shown in Fig. 5. We choose to implement the Canny algorithm for image edge features to detect and extract.\n在文献[28]中，LiDAR点云被分割成大小均匀的体素，然后通过RANSAC算法估计每个体素内的平面。相比之下，我们的方法使用了在第III-B节中获得的自适应体素地图。我们计算每两个相邻体素中包含平面法线之间的夹角。如果该夹角超过某一阈值，则提取这两个平面的交线作为深度连续边缘，如图5所示。我们选择使用Canny算法来检测并提取图像中的边缘特征。\n$${}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}=\\mathbf{f}\\left(\\boldsymbol{\\pi}\\left({{}^{C_l}_{L_{0}}}\\mathbf{T}\\left({}^{G}_{L_0}\\mathbf{T}_{t_{j}}\\right)^{-1}{}^{G}\\mathbf{p}_{i}\\\\\\right)\\right)\\tag{7}$$$$ \\mathbf{A}_{i,l,j}=\\sum_{k=1}^\\kappa(\\mathbf{q}_k-\\mathbf{q}_{i,l,j})(\\mathbf{q}_k-\\mathbf{q}_{i,l,j})^T,\\mathbf{q}_{i,l,j}=\\frac1\\kappa\\sum_{k=1}^\\kappa\\mathbf{q}_k\\tag{8}$$$$\\mathbf{r}_{i,l,j}=\\mathbf{n}_{i,l,j}^{T}\\left({}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}-\\mathbf{q}_{i,l,j}\\right).\\tag{9}$$$$\\mathcal{E}_{C}^{*}=\\arg\\min_{\\mathcal{E}_{C}}\\sum_{i}\\sum_{\\mathbf{I}_{l,j}\\in\\mathcal{I}_{i}}\\left(\\mathbf{n}_{i,l,j}^{T}\\left({}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}-\\mathbf{q}_{i,l,j}\\right)\\right)\\tag{10}$$.\n$$ {}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}=\\mathbf{f}\\left(\\boldsymbol{\\pi}\\left({{}^{C_l}_{L_{0}}}\\mathbf{T}\\left({}^{G}_{L_0}\\mathbf{T}_{t_{j}}\\right)^{-1}{}^{G}\\mathbf{p}_{i}\\\\\\right)\\right)\\tag{7} $$$$ \\mathbf{A}_{i,l,j}=\\sum_{k=1}^\\kappa(\\mathbf{q}_k-\\mathbf{q}_{i,l,j})(\\mathbf{q}_k-\\mathbf{q}_{i,l,j})^T,\\mathbf{q}_{i,l,j}=\\frac1\\kappa\\sum_{k=1}^\\kappa\\mathbf{q}_k\\tag{8}$$$$\\mathbf{r}_{i,l,j}=\\mathbf{n}_{i,l,j}^{T}\\left({}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}-\\mathbf{q}_{i,l,j}\\right).\\tag{9}$$$$\\mathcal{E}_{C}^{*}=\\arg\\min_{\\mathcal{E}_{C}}\\sum_{i}\\sum_{\\mathbf{I}_{l,j}\\in\\mathcal{I}_{i}}\\left(\\mathbf{n}_{i,l,j}^{T}\\left({}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}-\\mathbf{q}_{i,l,j}\\right)\\right)\\tag{10}$$.\nInspecting the residual in (9), we find the ${}^{I_{l,j}}p_i$ is dependent on LiDAR poses ${}^{G}_{L_0}T_{t_j}$. This is due to the reason that LiDARs may have FoV overlap with cameras at different times (as in Fig. 2). Since ${}^{G}_{L_0}T_{t_j}\\in\\mathcal{S}$ has been well estimated from Sec. III-C, we keep them fixed in this step. Moreover, the $n_{i,l,j}$ and $q_{i,l,j}$ are also implicitly dependent on $\\mathcal{E}_C$, since both ni,l,jand qi,l,jare related with nearest neighbor search. The complete derivative of (10) to the variable $\\mathcal{E}_C$ would be too complicated. In this paper, to simplify the optimization problem, we ignore the influence of camera extrinsic on $n_{i,l,j}$ and $q_{i,l,j}$. This strategy works well in practice as detailed in Sec. IV-B.\n检查公式 (9) 中的残差，我们发现 ${}^{I_{l,j}}p_i$ 依赖于激光雷达的姿态 ${}^{G}_{L_0}T_{t_j}$。这是由于激光雷达可能在不同时间与相机存在视场重叠（如图2所示）。因为 ${}^{G}_{L_0}T_{t_j}\\in\\mathcal{S}$ 已经根据第三节C部分很好地估计出来了，在此步骤中我们将它们固定不变。此外，$n_{i,l,j}$ 和 $q_{i,l,j}$ 也隐式地依赖于外参 $\\mathcal{E}_C$，因为两者都与最近邻搜索相关。 对变量 $\\mathcal{E}_C$ 完整求导将会过于复杂。在本文中，为了简化优化问题，我们忽略了相机外参对 $n_{i,l,j}$ 和 $q_{i,l,j}$ 的影响。如第四节B部分详细说明的那样，这一策略在实践中表现良好。\n$$\\delta\\mathbf{x}=-\\left(\\mathbf{J}^{T}\\mathbf{J}+\\mu\\mathbf{I}\\right)^{-1}\\mathbf{J}^{T}\\mathbf{r},\\tag{11}$$$$ \\begin{align*} \\delta{x}=\\begin{bmatrix}\\cdots\\quad{}^{C_1}_{L_0}\\phi^{T}\\quad\\delta{{}^{C_1}_{L_0}t^{T}}\\quad\\cdots\\end{bmatrix}\\in\\mathbb{R}^{6h}\\\\ x=\\begin{bmatrix}\\cdots\\quad{}^{C_1}_{L_0}R\\quad{}^{C_1}_{L_0}t\\quad\\cdots\\end{bmatrix}\\\\ J=\\begin{bmatrix}\\cdots\\quad J^{T}_{p}\\quad\\cdots\\end{bmatrix}^{T},r=\\begin{bmatrix}\\cdots\\quad{r_p}\\quad\\cdots\\end{bmatrix}^{T}, \\end{align*} $$$$ \\begin{align*} \u0026\\mathbf{J}_{i,l,j} =\\mathbf{n}_{i,l,j}^T\\frac{\\partial\\mathbf{f}(\\mathbf{p})}{\\partial\\mathbf{p}}\\frac{\\partial\\boldsymbol{\\pi}(\\mathbf{P})}{\\partial\\mathbf{P}}\\left[-_{L_0}^{C_l}\\mathbf{R}\\left(^{L_0}\\mathbf{p}_i\\right)^{\\wedge}\\quad\\mathbf{I}\\right]\\in\\mathbb{R}^{1\\times6} \\\\ \u0026^{L_0}\\mathbf{p}_i =\\left({}_{L_0}^G\\mathbf{T}_{t_j}\\right)^{-1}{}^G\\mathbf{p}_i. \\end{align*}\\tag{12} $$ $$\\delta\\mathbf{x}=-\\left(\\mathbf{J}^{T}\\mathbf{J}+\\mu\\mathbf{I}\\right)^{-1}\\mathbf{J}^{T}\\mathbf{r},\\tag{11}$$$$ \\begin{align*} \\delta{x}=\\begin{bmatrix}\\cdots\\quad{}^{C_1}_{L_0}\\phi^{T}\\quad\\delta{{}^{C_1}_{L_0}t^{T}}\\quad\\cdots\\end{bmatrix}\\in\\mathbb{R}^{6h}\\\\ x=\\begin{bmatrix}\\cdots\\quad{}^{C_1}_{L_0}R\\quad{}^{C_1}_{L_0}t\\quad\\cdots\\end{bmatrix}\\\\ J=\\begin{bmatrix}\\cdots\\quad J^{T}_{p}\\quad\\cdots\\end{bmatrix}^{T},r=\\begin{bmatrix}\\cdots\\quad{r_p}\\quad\\cdots\\end{bmatrix}^{T}, \\end{align*} $$$$ \\begin{align*} \u0026\\mathbf{J}_{i,l,j} =\\mathbf{n}_{i,l,j}^T\\frac{\\partial\\mathbf{f}(\\mathbf{p})}{\\partial\\mathbf{p}}\\frac{\\partial\\boldsymbol{\\pi}(\\mathbf{P})}{\\partial\\mathbf{P}}\\left[-_{L_0}^{C_l}\\mathbf{R}\\left(^{L_0}\\mathbf{p}_i\\right)^{\\wedge}\\quad\\mathbf{I}\\right]\\in\\mathbb{R}^{1\\times6} \\\\ \u0026^{L_0}\\mathbf{p}_i =\\left({}_{L_0}^G\\mathbf{T}_{t_j}\\right)^{-1}{}^G\\mathbf{p}_i. \\end{align*}\\tag{12} $$理论推导 论文中相机标定部分的内容是比较容易理解的，只需找到匹配的点云边缘点和图像边缘点，将点云边缘点投影到图像上，通过 最小化重投影误差即可对相机外参进行优化，其中最重要的是作者建立边缘线上点云与图像的匹配点的实现思路。至于最后的 误差公式的一阶导数推导，暂不进行说明，因为代码实现中直接使用了ceres的自动求导。 后续有空余时间可以补充！\n建立匹配点的思路为：将所有点云边缘线上全局坐标系下的点云投影到基准雷达下(注意，是所有位姿都投影，而非对应的某 一帧，因为不同图像可能会看到同一个边缘线)，再通过cv::projectPoints()函数直接投到像素坐标系下，遍历每个边缘 点，判断其距离最近的5个图像上的边缘点，如果5个点距离该点都小于一定的值则检索该点距离最近的5个点，拟合点云的方向 向量，图像也是一样的处理，将那5个点拟合方向向量。需要注意的是图像的分辨率是有限的，尤其是在较低分辨率的相机中，多个三维点 可能在投影到二维平面后，落在同一个像素上。因此那些投影之后落在同一个位置的三维点要取平均值。此时所有的三维点都将有其对应的二维点。\n代码详解 提取平面 通过体素化提取空间中的平面 下面代码选自ba.hpp,通过判断协方差矩阵的特征值比值确定平面，与之前的雷达标定部分关于平面的提取是一样的，但是多了一些细节处理，其额外将平面拆分成8份，将每一份的法向量与整体的法向量进行一致性评估。具体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 bool judge_eigen(int layer) { VOX_FACTOR covMat = sig_orig; Eigen::SelfAdjointEigenSolver\u0026lt;Eigen::Matrix3d\u0026gt; saes(covMat.cov()); value_vector = saes.eigenvalues(); center = covMat.v / covMat.N;//平面中心点 direct = saes.eigenvectors().col(0);//平面的法向量 eigen_ratio = saes.eigenvalues()[0] / saes.eigenvalues()[2]; // [0] is the smallest //NOTE:与雷达标定部分检测平面刚好相反，这里是小值比大值。 if (eigen_ratio \u0026gt; eigen_thr) return 0; //NOTE:两个较小的特征值比值如果比较接近，那么说明在剩余两个方向分部比较均匀，是线状点云 if (saes.eigenvalues()[0] / saes.eigenvalues()[1] \u0026gt; 0.1) return 0; // 排除线状点云 double eva0 = saes.eigenvalues()[0]; double sqr_eva0 = sqrt(eva0); //NOTE:选择平面中心点沿着平面法向量的方向延伸一定的距离的点作为边界点 Eigen::Vector3d center_turb = center + 5 * sqr_eva0 * direct; //NOTE:将平面拆分为8个子平面 vector\u0026lt;VOX_FACTOR\u0026gt; covMats(8); for (Eigen::Vector3d ap : vec_orig) { int xyz[3] = {0, 0, 0}; for (int k = 0; k \u0026lt; 3; k++) if (ap(k) \u0026gt; center_turb[k]) xyz[k] = 1; Eigen::Vector3d pvec(ap(0), ap(1), ap(2)); int leafnum = 4 * xyz[0] + 2 * xyz[1] + xyz[2]; covMats[leafnum].push(pvec); } //NOTE:重新计算子平面的法向量，判断与平面法向量的夹角是否足够小cos(θ)，当所有的都满足，则认为该平面是平面，否则不是平面 int num_all = 0, num_qua = 0; for (int i = 0; i \u0026lt; 8; i++) if (covMats[i].N \u0026gt; MIN_PT) { Eigen::SelfAdjointEigenSolver\u0026lt;Eigen::Matrix3d\u0026gt; saes(covMats[i].cov()); Eigen::Vector3d child_direct = saes.eigenvectors().col(0); if (fabs(child_direct.dot(direct)) \u0026gt; 0.98) num_qua++; num_all++; } if (num_qua != num_all) return 0; return 1; } 平面整合 选自calib_camera.hpp，将体素中属于同一平面的点云进行合并，判断条件是两个平面法向量相似度很高，且彼此法向量距离对方的平面中心点距离很近。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * @brief 合并平面 * @param origin_list 原始平面列表 * @param merge_list 合并后的平面列表 */ void mergePlane(std::vector\u0026lt;Plane *\u0026gt; \u0026amp;origin_list, std::vector\u0026lt;Plane *\u0026gt; \u0026amp;merge_list) { for (size_t i = 0; i \u0026lt; origin_list.size(); i++) origin_list[i]-\u0026gt;id = 0; int current_id = 1; for (auto iter = origin_list.end() - 1; iter != origin_list.begin(); iter--) { for (auto iter2 = origin_list.begin(); iter2 != iter; iter2++) { //NOTE:计算当前平面和其他平面之间的法向量的差和法向量的和，以及平面中心到平面的距离， // 如果满足条件则认为两个平面是同一个平面，方向相同，距离接近，非常有可能为同一平面 Eigen::Vector3d normal_diff = (*iter)-\u0026gt;normal - (*iter2)-\u0026gt;normal; Eigen::Vector3d normal_add = (*iter)-\u0026gt;normal + (*iter2)-\u0026gt;normal; double dis1 = fabs((*iter)-\u0026gt;normal(0) * (*iter2)-\u0026gt;center(0) + (*iter)-\u0026gt;normal(1) * (*iter2)-\u0026gt;center(1) + (*iter)-\u0026gt;normal(2) * (*iter2)-\u0026gt;center(2) + (*iter)-\u0026gt;d); double dis2 = fabs((*iter2)-\u0026gt;normal(0) * (*iter)-\u0026gt;center(0) + (*iter2)-\u0026gt;normal(1) * (*iter)-\u0026gt;center(1) + (*iter2)-\u0026gt;normal(2) * (*iter)-\u0026gt;center(2) + (*iter2)-\u0026gt;d); if (normal_diff.norm() \u0026lt; 0.2 || normal_add.norm() \u0026lt; 0.2) if (dis1 \u0026lt; 0.05 \u0026amp;\u0026amp; dis2 \u0026lt; 0.05) { if ((*iter)-\u0026gt;id == 0 \u0026amp;\u0026amp; (*iter2)-\u0026gt;id == 0) { (*iter)-\u0026gt;id = current_id; (*iter2)-\u0026gt;id = current_id; current_id++; } else if ((*iter)-\u0026gt;id == 0 \u0026amp;\u0026amp; (*iter2)-\u0026gt;id != 0) (*iter)-\u0026gt;id = (*iter2)-\u0026gt;id; else if ((*iter)-\u0026gt;id != 0 \u0026amp;\u0026amp; (*iter2)-\u0026gt;id == 0) (*iter2)-\u0026gt;id = (*iter)-\u0026gt;id; } } } ..... } 提取边缘线 提取点云边缘线 $$ \\begin{align*} n_1\\cdot(p-c_1)=0\\tag{1}\\\\ n_2\\cdot(p-c_2)=0\\tag{2}\\\\ d\\cdot(p-c_1)=0\\tag{3} \\end{align*} $$$$ \\begin{align*} A=\\begin{bmatrix} n_1^{T}\\\\d^{T}\\\\n_2^{T} \\end{bmatrix}\\tag{4}\\\\ b=\\begin{bmatrix}n_1\\cdot{c_1}\\quad{d}\\cdot{c_1}\\quad{n_2}\\cdot{c_2}\\end{bmatrix}\\tag{5}\\\\ A\\cdot{x}=b\\tag{6} \\end{align*} $$$$ \\begin{align*} (c_2-O)\\cdot{d}\\times{d}\\tag{7}\\\\ (c_2-0)-(c_2-O)\\cdot{d}\\times{d}\\tag{8} \\end{align*} $$ 式7为$c_2$到交线投影位置与$O$点构成的向量,式8则为$c_2$与直线上一点构成垂直于交线的向量； 代码如下所示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 void projectLine(const Plane *plane1, const Plane *plane2, std::vector\u0026lt;Eigen::Vector3d\u0026gt; \u0026amp;line_point) { float theta = plane1-\u0026gt;normal.dot(plane2-\u0026gt;normal); //夹角要大于一定的值 if (!(theta \u0026gt; theta_max_ \u0026amp;\u0026amp; theta \u0026lt; theta_min_)) return; // std::cout \u0026lt;\u0026lt; \u0026#34;theta:\u0026#34; \u0026lt;\u0026lt; theta \u0026lt;\u0026lt; std::endl; // std::cout \u0026lt;\u0026lt; \u0026#34;theta_max_\u0026#34; \u0026lt;\u0026lt; theta_max_ \u0026lt;\u0026lt; \u0026#34; theta_min_\u0026#34; \u0026lt;\u0026lt; theta_min_ \u0026lt;\u0026lt; std::endl; Eigen::Vector3d c1 = plane1-\u0026gt;center; Eigen::Vector3d c2 = plane2-\u0026gt;center; Eigen::Vector3d n1 = plane1-\u0026gt;normal; Eigen::Vector3d n2 = plane2-\u0026gt;normal; Eigen::Matrix3d A; Eigen::Vector3d d = n1.cross(n2).normalized(); A.row(0) = n1.transpose(); A.row(1) = d.transpose(); A.row(2) = n2.transpose(); //NOTE:描述了三个关系 $n_1\\cdot{(p-c_1)}=0$ 、$n_2\\cdot{(p-c_2)}=0$、$ d\\cdot{(p-c_1)}$ //该点与c1平面内中心点构成的向量与n1垂直，与c2平面中心点构成的向量与n2垂直，与c1平面中心点构成·与两个平面法向量、 //垂直方向的法向量构成的向量垂直，所以该点为平面交线上一点 Eigen::Vector3d b(n1.dot(c1), d.dot(c1), n2.dot(c2)); Eigen::Vector3d O = A.colPivHouseholderQr().solve(b); double c1_to_line = (c1 - O).norm(); //NOTE:注意计算点的时候约束了，该点与c1构成的向量是垂直于d的，但是没约束c2 double c2_to_line = ((c2 - O) - (c2 - O).dot(d) * d).norm(); if (c1_to_line / c2_to_line \u0026gt; 8 || c2_to_line / c1_to_line \u0026gt; 8) return; if (plane1-\u0026gt;points_size \u0026lt; plane2-\u0026gt;points_size) for (auto pt : plane1-\u0026gt;plane_points) { Eigen::Vector3d p = (pt - O).dot(d) * d + O; line_point.push_back(p); } else for (auto pt : plane2-\u0026gt;plane_points) { Eigen::Vector3d p = (pt - O).dot(d) * d + O; line_point.push_back(p); } return; } 进一步处理，计算在体素内所有点中距离平面投影线上的点最近的5个点，将其存放到相应的容器中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 /** * @brief 提取体素地图中平面的边缘点 * @param surf_map */ void estimate_edge(std::unordered_map\u0026lt;VOXEL_LOC, OCTO_TREE_ROOT *\u0026gt; \u0026amp;surf_map) { // ros::Rate loop(500); lidar_edge_clouds = pcl::PointCloud\u0026lt;pcl::PointXYZI\u0026gt;::Ptr(new pcl::PointCloud\u0026lt;pcl::PointXYZI\u0026gt;); for (auto iter = surf_map.begin(); iter != surf_map.end(); iter++) { std::vector\u0026lt;Plane *\u0026gt; plane_list; std::vector\u0026lt;Plane *\u0026gt; merge_plane_list; iter-\u0026gt;second-\u0026gt;get_plane_list(plane_list); if (plane_list.size() \u0026gt; 1) { pcl::KdTreeFLANN\u0026lt;pcl::PointXYZI\u0026gt; kd_tree; pcl::PointCloud\u0026lt;pcl::PointXYZI\u0026gt; input_cloud; //将当前所有体素的点云加入到kd树中，用于快速最临近搜索 for (auto pv : iter-\u0026gt;second-\u0026gt;all_points) { pcl::PointXYZI p; p.x = pv(0); p.y = pv(1); p.z = pv(2); input_cloud.push_back(p); } kd_tree.setInputCloud(input_cloud.makeShared()); mergePlane(plane_list, merge_plane_list); if (merge_plane_list.size() \u0026lt;= 1) continue; #ifdef DEBUG for (auto plane : merge_plane_list) { static int i = 0; pcl::PointCloud\u0026lt;pcl::PointXYZRGB\u0026gt; color_cloud; std::vector\u0026lt;unsigned int\u0026gt; colors; colors.push_back(static_cast\u0026lt;unsigned int\u0026gt;(rand() % 255)); colors.push_back(static_cast\u0026lt;unsigned int\u0026gt;(rand() % 255)); colors.push_back(static_cast\u0026lt;unsigned int\u0026gt;(rand() % 255)); for (auto pv : plane-\u0026gt;plane_points) { pcl::PointXYZRGB pi; pi.x = pv[0]; pi.y = pv[1]; pi.z = pv[2]; pi.r = colors[0]; pi.g = colors[1]; pi.b = colors[2]; color_cloud.points.push_back(pi); } pcl::io::savePCDFile(\u0026#34;merge_plane_\u0026#34; + std::to_string(i++)+\u0026#34;.pcd\u0026#34;, color_cloud); } #endif for (size_t p1_index = 0; p1_index \u0026lt; merge_plane_list.size() - 1; p1_index++) for (size_t p2_index = p1_index + 1; p2_index \u0026lt; merge_plane_list.size(); p2_index++) { std::vector\u0026lt;Eigen::Vector3d\u0026gt; line_point; //计算两个平面之间的交线 projectLine(merge_plane_list[p1_index], merge_plane_list[p2_index], line_point); if (line_point.size() == 0) break; pcl::PointCloud\u0026lt;pcl::PointXYZI\u0026gt; line_cloud; for (size_t j = 0; j \u0026lt; line_point.size(); j++) { pcl::PointXYZI p; p.x = line_point[j][0]; p.y = line_point[j][1]; p.z = line_point[j][2]; int K = 5; // 创建两个向量，分别存放近邻的索引值、近邻的中心距 std::vector\u0026lt;int\u0026gt; pointIdxNKNSearch(K); std::vector\u0026lt;float\u0026gt; pointNKNSquaredDistance(K); if (kd_tree.nearestKSearch(p, K, pointIdxNKNSearch, pointNKNSquaredDistance) == K) { Eigen::Vector3d tmp(input_cloud.points[pointIdxNKNSearch[K - 1]].x, input_cloud.points[pointIdxNKNSearch[K - 1]].y, input_cloud.points[pointIdxNKNSearch[K - 1]].z); // if(pointNKNSquaredDistance[K-1] \u0026lt; 0.01) if ((tmp - line_point[j]).norm() \u0026lt; 0.05) { line_cloud.points.push_back(p); lidar_edge_clouds-\u0026gt;points.push_back(p); } } } } } } } 提取图像边缘线 代码主要是通过opencv的cv::Canny()函数实现，没有太多额外的处理，有以下几点需要关注： 1 2 3 4 5 6 7 8 9 ... //高斯模糊，减小图像中的噪声和细节，保留图像的边缘 cv::GaussianBlur(src_img[a], src_img[a], cv::Size(gaussian_size, gaussian_size), 0, 0); cv::Mat canny_result = cv::Mat::zeros(src_img[a].rows, src_img[a].cols, CV_8UC1); //低于阈值1的像素点会被认为不是边缘； //高于阈值2的像素点会被认为是边缘； //在阈值1和阈值2之间的像素点,若与第2步得到的边缘像素点相邻，则被认为是边缘，否则被认为不是边缘。 cv::Canny(src_img[a], canny_result, canny_threshold, canny_threshold * 3, 3, true); ... 构建匹配对 本文第2章理论推导中对建立匹配对的过程进行了一定的描述，这里不再复述。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 void buildVPnp(const Camera \u0026amp;cam, const Vector6d \u0026amp;extrinsic_params, const int dis_threshold, const bool show_residual, const std::vector\u0026lt;pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr\u0026gt; \u0026amp;cam_edge_clouds_2d, const pcl::PointCloud\u0026lt;pcl::PointXYZI\u0026gt;::Ptr \u0026amp;lidar_edge_clouds_3d, std::vector\u0026lt;VPnPData\u0026gt; \u0026amp;pnp_list) { pnp_list.clear(); cv::Mat camera_matrix = (cv::Mat_\u0026lt;double\u0026gt;(3, 3) \u0026lt;\u0026lt; cam.fx_, cam.s_, cam.cx_, 0.0, cam.fy_, cam.cy_, 0.0, 0.0, 1.0); cv::Mat distortion_coeff = (cv::Mat_\u0026lt;double\u0026gt;(1, 5) \u0026lt;\u0026lt; cam.k1_, cam.k2_, cam.p1_, cam.p2_, cam.k3_); Eigen::AngleAxisd rotation_vector3; rotation_vector3 = Eigen::AngleAxisd(extrinsic_params[0], Eigen::Vector3d::UnitZ()) * Eigen::AngleAxisd(extrinsic_params[1], Eigen::Vector3d::UnitY()) * Eigen::AngleAxisd(extrinsic_params[2], Eigen::Vector3d::UnitX()); Eigen::Quaterniond q_(rotation_vector3); for (size_t a = 0; a \u0026lt; base_poses.size(); a += 1) // for each camera pose { std::vector\u0026lt;std::vector\u0026lt;std::vector\u0026lt;pcl::PointXYZI\u0026gt;\u0026gt;\u0026gt; img_pts_container; for (int y = 0; y \u0026lt; cam.height_; y++) { std::vector\u0026lt;std::vector\u0026lt;pcl::PointXYZI\u0026gt;\u0026gt; row_pts_container; for (int x = 0; x \u0026lt; cam.width_; x++) { std::vector\u0026lt;pcl::PointXYZI\u0026gt; col_pts_container; row_pts_container.push_back(col_pts_container); } img_pts_container.push_back(row_pts_container); } std::vector\u0026lt;cv::Point3f\u0026gt; pts_3d; std::vector\u0026lt;cv::Point2f\u0026gt; pts_2d; cv::Mat r_vec = (cv::Mat_\u0026lt;double\u0026gt;(3, 1) \u0026lt;\u0026lt; rotation_vector3.angle() * rotation_vector3.axis().transpose()[0], rotation_vector3.angle() * rotation_vector3.axis().transpose()[1], rotation_vector3.angle() * rotation_vector3.axis().transpose()[2]); Eigen::Vector3d t_(extrinsic_params[3], extrinsic_params[4], extrinsic_params[5]); cv::Mat t_vec = (cv::Mat_\u0026lt;double\u0026gt;(3, 1) \u0026lt;\u0026lt; t_(0), t_(1), t_(2)); for (size_t i = 0; i \u0026lt; lidar_edge_clouds_3d-\u0026gt;size(); i++) { pcl::PointXYZI point_3d = lidar_edge_clouds_3d-\u0026gt;points[i]; Eigen::Vector3d pt1(point_3d.x, point_3d.y, point_3d.z); Eigen::Vector3d pt2(0, 0, 1); Eigen::Vector3d pt; pt = base_poses[a].q.inverse() * (pt1 - base_poses[a].t);//转回到基准雷达坐标系下 //NOTE:将点转化到相机坐标系下，其与原点构成的向量与相机视野方向向量（0,0,1）夹角很小则说明是在相机视野内的点 if (cos_angle(q_ * pt + t_, pt2) \u0026gt; 0.8) // FoV check pts_3d.emplace_back(cv::Point3f(pt(0), pt(1), pt(2))); } //将雷达点投到图像上 cv::projectPoints(pts_3d, r_vec, t_vec, camera_matrix, distortion_coeff, pts_2d); pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr line_edge_cloud_2d(new pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;); std::vector\u0026lt;int\u0026gt; line_edge_cloud_2d_number; for (size_t i = 0; i \u0026lt; pts_2d.size(); i++) { pcl::PointXYZ p; p.x = pts_2d[i].x; p.y = -pts_2d[i].y; p.z = 0; pcl::PointXYZI pi_3d; pi_3d.x = pts_3d[i].x; pi_3d.y = pts_3d[i].y; pi_3d.z = pts_3d[i].z; pi_3d.intensity = 1; //判断是否在图像视野内 if (p.x \u0026gt; 0 \u0026amp;\u0026amp; p.x \u0026lt; cam.width_ \u0026amp;\u0026amp; pts_2d[i].y \u0026gt; 0 \u0026amp;\u0026amp; pts_2d[i].y \u0026lt; cam.height_) { if (img_pts_container[pts_2d[i].y][pts_2d[i].x].size() == 0) { line_edge_cloud_2d-\u0026gt;points.push_back(p); img_pts_container[pts_2d[i].y][pts_2d[i].x].push_back(pi_3d); } else img_pts_container[pts_2d[i].y][pts_2d[i].x].push_back(pi_3d); } } if (show_residual) if (a == 16) { cv::Mat residual_img = getConnectImg( cam, dis_threshold, cam_edge_clouds_2d[a], line_edge_cloud_2d); std::string img_name = std::to_string(a); cv::imshow(img_name, residual_img); cv::waitKey(10); } pcl::search::KdTree\u0026lt;pcl::PointXYZ\u0026gt;::Ptr kdtree_cam(new pcl::search::KdTree\u0026lt;pcl::PointXYZ\u0026gt;()); pcl::search::KdTree\u0026lt;pcl::PointXYZ\u0026gt;::Ptr kdtree_lidar(new pcl::search::KdTree\u0026lt;pcl::PointXYZ\u0026gt;()); pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr search_cloud = pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr(new pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;); pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr tree_cloud_cam = pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr(new pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;); pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr tree_cloud_lidar = pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;::Ptr(new pcl::PointCloud\u0026lt;pcl::PointXYZ\u0026gt;); kdtree_cam-\u0026gt;setInputCloud(cam_edge_clouds_2d[a]); kdtree_lidar-\u0026gt;setInputCloud(line_edge_cloud_2d); tree_cloud_cam = cam_edge_clouds_2d[a]; tree_cloud_lidar = line_edge_cloud_2d; search_cloud = line_edge_cloud_2d; int K = 5; // 指定近邻个数 // 创建两个向量，分别存放近邻的索引值、近邻的中心距 std::vector\u0026lt;int\u0026gt; pointIdxNKNSearch(K); std::vector\u0026lt;float\u0026gt; pointNKNSquaredDistance(K); std::vector\u0026lt;int\u0026gt; pointIdxNKNSearchLidar(K); std::vector\u0026lt;float\u0026gt; pointNKNSquaredDistanceLidar(K); std::vector\u0026lt;cv::Point2d\u0026gt; lidar_2d_list; std::vector\u0026lt;cv::Point2d\u0026gt; img_2d_list; std::vector\u0026lt;Eigen::Vector2d\u0026gt; camera_direction_list; std::vector\u0026lt;Eigen::Vector2d\u0026gt; lidar_direction_list; std::vector\u0026lt;int\u0026gt; lidar_2d_number; for (size_t i = 0; i \u0026lt; search_cloud-\u0026gt;points.size(); i++) { pcl::PointXYZ searchPoint = search_cloud-\u0026gt;points[i]; //查找点云的临近点，主要目的是为了计算点所在直线的方向 kdtree_lidar-\u0026gt;nearestKSearch(searchPoint, K, pointIdxNKNSearchLidar, pointNKNSquaredDistanceLidar); if (kdtree_cam-\u0026gt;nearestKSearch(searchPoint, K, pointIdxNKNSearch, pointNKNSquaredDistance) \u0026gt; 0) { bool dis_check = true; //如果点云中某个点与图像中最临近的5个点，有一个距离超出阈值，则认为该点与图像中该点距离太远，丢弃 for (int j = 0; j \u0026lt; K; j++) { float distance = sqrt(pow(searchPoint.x - tree_cloud_cam-\u0026gt;points[pointIdxNKNSearch[j]].x, 2) + pow(searchPoint.y - tree_cloud_cam-\u0026gt;points[pointIdxNKNSearch[j]].y, 2)); if (distance \u0026gt; dis_threshold) dis_check = false; } if (dis_check) { cv::Point p_l_2d(search_cloud-\u0026gt;points[i].x, -search_cloud-\u0026gt;points[i].y); cv::Point p_c_2d(tree_cloud_cam-\u0026gt;points[pointIdxNKNSearch[0]].x, -tree_cloud_cam-\u0026gt;points[pointIdxNKNSearch[0]].y); Eigen::Vector2d direction_cam(0, 0); std::vector\u0026lt;Eigen::Vector2d\u0026gt; points_cam; for (size_t i = 0; i \u0026lt; pointIdxNKNSearch.size(); i++) { Eigen::Vector2d p(tree_cloud_cam-\u0026gt;points[pointIdxNKNSearch[i]].x, -tree_cloud_cam-\u0026gt;points[pointIdxNKNSearch[i]].y); points_cam.push_back(p); } //计算点的分布方向，即直线方向，与计算通过协方差的特征值判断平面法向量类似 calcDirection(points_cam, direction_cam); Eigen::Vector2d direction_lidar(0, 0); std::vector\u0026lt;Eigen::Vector2d\u0026gt; points_lidar; for (size_t i = 0; i \u0026lt; pointIdxNKNSearch.size(); i++) { Eigen::Vector2d p(tree_cloud_lidar-\u0026gt;points[pointIdxNKNSearchLidar[i]].x, -tree_cloud_lidar-\u0026gt;points[pointIdxNKNSearchLidar[i]].y); points_lidar.push_back(p); } calcDirection(points_lidar, direction_lidar); if (p_l_2d.x \u0026gt; 0 \u0026amp;\u0026amp; p_l_2d.x \u0026lt; cam.width_ \u0026amp;\u0026amp; p_l_2d.y \u0026gt; 0 \u0026amp;\u0026amp; p_l_2d.y \u0026lt; cam.height_) { lidar_2d_list.push_back(p_l_2d); img_2d_list.push_back(p_c_2d); camera_direction_list.push_back(direction_cam); lidar_direction_list.push_back(direction_lidar); } } } } for (size_t i = 0; i \u0026lt; lidar_2d_list.size(); i++) { int y = lidar_2d_list[i].y; int x = lidar_2d_list[i].x; int pixel_points_size = img_pts_container[y][x].size(); if (pixel_points_size \u0026gt; 0) { VPnPData pnp; pnp.x = 0; pnp.y = 0; pnp.z = 0; pnp.u = img_2d_list[i].x; pnp.v = img_2d_list[i].y; //NOTE:图像的分辨率是有限的，尤其是在较低分辨率的相机中，多个三维点可能在投影到二维平面后，落在同一个像素上。 for (int j = 0; j \u0026lt; pixel_points_size; j++) { pnp.x += img_pts_container[y][x][j].x; pnp.y += img_pts_container[y][x][j].y; pnp.z += img_pts_container[y][x][j].z; } pnp.x = pnp.x / pixel_points_size; pnp.y = pnp.y / pixel_points_size; pnp.z = pnp.z / pixel_points_size; pnp.direction = camera_direction_list[i]; pnp.direction_lidar = lidar_direction_list[i]; pnp.number = 0; float theta = pnp.direction.dot(pnp.direction_lidar); // 判断两个方向夹角是否满足条件 if (theta \u0026gt; direction_theta_min_ || theta \u0026lt; direction_theta_max_) pnp_list.push_back(pnp); } } } } 优化问题 最小化重投影误差 $$\\mathcal{E}_{C}^{*}=\\arg\\min_{\\mathcal{E}_{C}}\\sum_{i}\\sum_{\\mathbf{I}_{l,j}\\in\\mathcal{I}_{i}}\\left(\\mathbf{n}_{i,l,j}^{T}\\left({}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}-\\mathbf{q}_{i,l,j}\\right)\\right)\\tag{1}$$ 上式暂时还没理解,等后面再看！，但是好在代码实现上与问题表达是有差异，代码是优化点到直线上的距离，与BLAM中关于边缘特征问题表述是一样的，具体如下所示：\n$$ \\mathcal{E}_{C}^{*}=\\arg\\min_{\\mathcal{E}_{C}}\\sum_{i}\\sum_{\\mathbf{I}_{l,j}\\in\\mathcal{I}_{i}}\\left((I-\\mathbf{n}_{i,l,j}\\mathbf{n}_{i,l,j}^{T})\\left({}^{\\mathbf{I}_{l,j}}\\mathbf{p}_{i}-\\mathbf{q}_{i,l,j}\\right)\\right)\\tag{2} $$。\n下面代码选自calib_camera.cpp,内容为ceres误差函数的建立：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 class vpnp_calib { public: vpnp_calib(VPnPData p) { pd = p; } template\u0026lt;typename T\u0026gt; bool operator()(const T *_q, const T *_t, T *residuals) const { Eigen::Matrix\u0026lt;T, 3, 3\u0026gt; innerT = inner.cast\u0026lt;T\u0026gt;(); Eigen::Matrix\u0026lt;T, 4, 1\u0026gt; distorT = distor.cast\u0026lt;T\u0026gt;(); Eigen::Quaternion\u0026lt;T\u0026gt; q_incre{_q[3], _q[0], _q[1], _q[2]}; Eigen::Matrix\u0026lt;T, 3, 1\u0026gt; t_incre{_t[0], _t[1], _t[2]}; Eigen::Matrix\u0026lt;T, 3, 1\u0026gt; p_l(T(pd.x), T(pd.y), T(pd.z)); Eigen::Matrix\u0026lt;T, 3, 1\u0026gt; p_c = q_incre.toRotationMatrix() * p_l + t_incre;//将点云转换到相机坐标系下 Eigen::Matrix\u0026lt;T, 3, 1\u0026gt; p_2 = innerT * p_c; T uo = p_2[0] / p_2[2]; T vo = p_2[1] / p_2[2];//转化为像素坐标系下，并进行归一化 const T \u0026amp;fx = innerT.coeffRef(0, 0); const T \u0026amp;cx = innerT.coeffRef(0, 2); const T \u0026amp;fy = innerT.coeffRef(1, 1); const T \u0026amp;cy = innerT.coeffRef(1, 2); T xo = (uo - cx) / fx; T yo = (vo - cy) / fy; T r2 = xo * xo + yo * yo; T r4 = r2 * r2; T distortion = 1.0 + distorT[0] * r2 + distorT[1] * r4; T xd = xo * distortion + (distorT[2] * xo * yo + distorT[2] * xo * yo) + distorT[3] * (r2 + xo * xo + xo * xo); T yd = yo * distortion + distorT[3] * xo * yo + distorT[3] * xo * yo + distorT[2] * (r2 + yo * yo + yo * yo); T ud = fx * xd + cx; T vd = fy * yd + cy;//使用针孔模型添加畸变 if (T(pd.direction(0)) == T(0.0) \u0026amp;\u0026amp; T(pd.direction(1)) == T(0.0)) { residuals[0] = ud - T(pd.u); residuals[1] = vd - T(pd.v); } else { residuals[0] = ud - T(pd.u); residuals[1] = vd - T(pd.v); //NOTE:这里用了BALM中的误差公式，而非MLCC中的公式 //构建向量$(I-nn^{T})({}^{I_{l,j}}p_{i}-q_{i,l,j})$以求点到直线的距离，然后最小化这个距离 Eigen::Matrix\u0026lt;T, 2, 2\u0026gt; I = Eigen::Matrix\u0026lt;float, 2, 2\u0026gt;::Identity().cast\u0026lt;T\u0026gt;(); Eigen::Matrix\u0026lt;T, 2, 1\u0026gt; n = pd.direction.cast\u0026lt;T\u0026gt;(); Eigen::Matrix\u0026lt;T, 1, 2\u0026gt; nt = pd.direction.transpose().cast\u0026lt;T\u0026gt;(); Eigen::Matrix\u0026lt;T, 2, 2\u0026gt; V = n * nt; V = I - V; Eigen::Matrix\u0026lt;T, 2, 1\u0026gt; R = Eigen::Matrix\u0026lt;float, 2, 1\u0026gt;::Zero().cast\u0026lt;T\u0026gt;(); R.coeffRef(0, 0) = residuals[0]; R.coeffRef(1, 0) = residuals[1]; R = V * R; residuals[0] = R.coeffRef(0, 0); residuals[1] = R.coeffRef(1, 0); } return true; } static ceres::CostFunction *Create(VPnPData p) { return (new ceres::AutoDiffCostFunction\u0026lt;vpnp_calib, 2, 4, 3\u0026gt;(new vpnp_calib(p))); } private: VPnPData pd; }; 2.粗标定\n代码中还实现了一个粗标定的方法，工作方式为调整初始参数，判断匹配对的数目是否增加，如果增加，则认为图像和点云配准更加准确，此时对参数进行更新，否则进入下一组值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 void roughCalib(Calibration \u0026amp;calibra, double search_resolution, int max_iter) { float match_dis = 20; Eigen::Vector3d fix_adjust_euler(0, 0, 0); std::cout \u0026lt;\u0026lt; \u0026#34;roughCalib ....\u0026#34; \u0026lt;\u0026lt; std::endl; for (int n = 0; n \u0026lt; 2; n++) {//进行两轮 for (int round = 0; round \u0026lt; 3; round++) {//依次调整三个角度 for (size_t a = 0; a \u0026lt; calibra.cams.size(); a++) {//对所有相机进行优化 Eigen::Matrix3d rot = calibra.cams[a].ext_R; Vector3d transation = calibra.cams[a].ext_t; float min_cost = 1000; for (int iter = 0; iter \u0026lt; max_iter; iter++) { Eigen::Vector3d adjust_euler = fix_adjust_euler; //正负交叉 adjust_euler[round] = fix_adjust_euler[round] + pow(-1, iter) * int(iter / 2) * search_resolution; Eigen::Matrix3d adjust_rotation_matrix; adjust_rotation_matrix = Eigen::AngleAxisd(adjust_euler[0], Eigen::Vector3d::UnitZ()) * Eigen::AngleAxisd(adjust_euler[1], Eigen::Vector3d::UnitY()) * Eigen::AngleAxisd(adjust_euler[2], Eigen::Vector3d::UnitX()); Eigen::Matrix3d test_rot = rot * adjust_rotation_matrix; Eigen::Vector3d test_euler = test_rot.eulerAngles(2, 1, 0); Vector6d test_params; test_params \u0026lt;\u0026lt; test_euler[0], test_euler[1], test_euler[2], transation[0], transation[1], transation[2]; std::vector\u0026lt;VPnPData\u0026gt; pnp_list; //建立匹配对 calibra.buildVPnp(calibra.cams[a], test_params, match_dis, false, calibra.cams[a].rgb_edge_clouds, calibra.lidar_edge_clouds, pnp_list); int edge_size = calibra.lidar_edge_clouds-\u0026gt;size(); int pnp_size = pnp_list.size(); float cost = ((float) (edge_size - pnp_size) / (float) edge_size); #ifdef DEBUG std::cout \u0026lt;\u0026lt; \u0026#34;n \u0026#34; \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34; round \u0026#34; \u0026lt;\u0026lt; round \u0026lt;\u0026lt; \u0026#34; a \u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34; iter \u0026#34; \u0026lt;\u0026lt; iter \u0026lt;\u0026lt; \u0026#34; cost:\u0026#34; \u0026lt;\u0026lt; cost \u0026lt;\u0026lt; std::endl; #endif //NOTE:因为，edge_size是不变的，cost越小说明pnp_list数量多,说明pnp配准越好 if (cost \u0026lt; min_cost) { std::cout \u0026lt;\u0026lt; \u0026#34;cost :\u0026#34; \u0026lt;\u0026lt; cost \u0026lt;\u0026lt; \u0026#34;; edge size : \u0026#34; \u0026lt;\u0026lt; calibra.lidar_edge_clouds-\u0026gt;size() \u0026lt;\u0026lt; \u0026#34;; pnp_list: \u0026#34; \u0026lt;\u0026lt; pnp_list.size() \u0026lt;\u0026lt; std::endl; min_cost = cost; Eigen::Matrix3d rot; rot = Eigen::AngleAxisd(test_params[0], Eigen::Vector3d::UnitZ()) * Eigen::AngleAxisd(test_params[1], Eigen::Vector3d::UnitY()) * Eigen::AngleAxisd(test_params[2], Eigen::Vector3d::UnitX()); //更新参数 calibra.cams[a].update_Rt(rot, transation); calibra.buildVPnp(calibra.cams[a], test_params, match_dis, true, calibra.cams[a].rgb_edge_clouds, calibra.lidar_edge_clouds, pnp_list); } } } } } } 正在更新中\u0026hellip;\n参考文献 [1]《Targetless Extrinsic Calibration of Multiple Small FoV LiDARs and Cameras using Adaptive Voxelization》\n[2]《BALM: Bundle Adjustment for Lidar Mapping》\n","date":"2024-10-09T17:22:01+08:00","image":"https://wzwan-developer.github.io/p/mlcc/02/camera_voxel_hu17897963874834980744.png","permalink":"https://wzwan-developer.github.io/p/mlcc/02/","title":"Chapter 02: LiDAR-Camera Extrinsic Calibration"},{"content":"文章内容 To find the correspondences among different LiDAR scans, we assume the initial base LiDAR trajectory $\\mathcal{S}$, LiDAR extrinsic $\\mathcal{E}_L$, and camera extrinsic $\\mathcal{E}_C$ are available. The initial base LiDAR trajectory $\\mathcal{S}$ could be obtained by an online LiDAR SLAM (e.g., [3]), and the initial extrinsic could be obtained from the CAD design or a rough Hand-Eye calibration [14]. Our previous work [5] extracts edge and plane feature points from each LiDAR scan and matches them to the nearby edge and plane points in the map by a $k$-nearest neighbor search ($k-NN$). This would repeatedly build a $k$-d tree of the global map at each iteration. In this paper, we use a more efficient voxel map proposed in [4] to create correspondences among all LiDAR scans.\n为了找到不同雷达扫描之间的对应关系，我们假设初始的基准雷达轨迹$\\mathcal{S}$、雷达外参$\\mathcal{E}_L$、相机外参$\\mathcal{E}_C$是可用的。初始的基准雷达轨迹$\\mathcal{S}$可以通过实时雷达SLAM获得，而初始的外参可以通过CAD设计或者从粗略的手眼标定中获得。我们的前期工作，从每个雷达扫描中提取边缘和平面特征，并通过最邻域搜索，将他们匹配到地图中的临近边缘和平面。这会在每次迭代中重复构建全局地图的$k$-d树，在本文中，我们使用在文献4中提出的一种更为高效的体素地图来创建所有雷达扫描之间的对应关系。\nThe voxel map is built by cutting the point cloud (registered using the current $\\mathcal{S}$ and $\\mathcal{E}_L$) into small voxels such that all points in a voxel roughly lie on a plane (with some adjustable tolerance). The main problem of the fixed-resolution voxel map is that if the resolution is high, the segmentation would be too time-consuming, while if the resolution is too low, multiple small planes in the environments falling into the same voxel would not be segmented. To best adapt to the environment, we implement an adaptive voxelization process. More specifically, the entire map is first cut into voxels with a pre-set size (usually large, e.g., 4m). Then for each voxel, if the contained points from all LiDAR scans roughly form a plane (by checking the ratio between eigenvalues), it is treated as a planar voxel; otherwise, they will be divided into eight octants, where each will be examined again until the contained points roughly form a plane or the voxel size reaches the pre-set minimum lower bound. Moreover, the adaptive voxelization is performed directly on the LiDAR raw points, so no prior feature points extraction is needed as in [5].\n体素地图通过将点云（使用当前的 $\\mathcal{S}$和 $\\mathcal{E}_L$ 进行配准）切割成小的体素来构建，使得体素内的所有点大致位于同一平面上（具有一定的可调容差）。固定分辨率体素图的主要问题是，如果分辨率太高，分割将会非常耗时；而如果分辨率太低，环境中多个小平面落在同一个体素内时则无法进行分割。为了更好地适应环境，我们实现了自适应体素化过程。 具体来说，整个地图首先被切割成预设大小的体素（通常较大，例如4米）。然后对于每个体素，如果所有LiDAR扫描中包含的点大致形成一个平面（通过检查特征值之间的比率来判断），则将其视为平面体素；否则，这些体素将被分成八个八分之一体素（octants），每个都将再次进行检查，直到包含的点大致形成一个平面，或者体素尺寸达到预设的最小下限。此外，自适应体素化直接在LiDAR的原始点上执行，因此不需要像文献[5]那样预先提取特征点。\nFig. 3 shows a typical result of the adaptive voxelization process in a complicated campus environment. As can be seen, this process is able to segment planes of different sizes, including large planes on the ground, medium planes on the building walls, and tiny planes on tree crowns. Fig. 3: A) LiDAR point cloud segmented with the adaptive voxelization. Points within the same voxel are colored identically. The detailed adaptive voxelization of points in the dashed white rectangle could be viewed in B) colored points and C) original points. The default size for the initial voxelization is 4m, and the minimum voxel size is 0.25m.\n图3展示了一个复杂校园环境中自适应体素化过程的典型结果。如图所示，该过程能够分割出不同大小的平面，包括地面上的大平面、建筑物墙面上的中等平面以及树冠上的小平面。 图3：(A) 使用自适应体素化分割的LiDAR点云。同一体素内的点被赋予相同的颜色。白色虚线矩形区域内的详细自适应体素化效果可以在 (B) 彩色点云和 (C) 原始点云中查看。初始体素化的默认大小为4米，而最小的体素大小为0.25米。\n相关理论 论文中关于自适应体素并未提及到重要信息，但是提到了参考文献4《BALM: Bundle Adjustment for Lidar Mapping》。\n自适应体素化 我们在默认大小的3D空间中重复体素化，如果当前体素中的所有特征点都位于平面，则将当前体素与包含的特征点一起保存在内存中；否则，将当前体素分解为八个八分体，并继续检查每个八分体直到达到最小尺寸。在具体实现过程中有以下细节：\n如果一个体素内包含太多的特征点，则会导致文章《Chapter 01: Multi-LiDAR Extrinsic Calibration》中推导过程章节中二阶闭式导数中的Hessian矩阵维度过高，在这种情况下，我们可以将点进行平均，以实现降采样但不降低映射一致性； 同时，二阶闭式导数中的Hessian矩阵推导过程中提到$\\lambda_m\\ne\\lambda_n$,因此当遇到$\\lambda$的代数多重性大于1的体素需要跳过（忽略）； 只需检查体素所包含的点，是否位于同一平面时允许更大的方差，则能自然地扩展到非平面特征（BALM只提到了平面特征和边缘特征）； 设置了两个条件来停止递归体素化：一个是树的最大深度，另一个是体素的最小点数。 其中，判断体素是否为平面的方法是计算体素内所有的点云的协方差矩阵，判断最大特征值与最小特征值的比值是否大于一定的阈值，如果大于则为平面：\n$$ p_c=\\frac{1}{N}\\sum_{i=1}^{N}p_i $$$$ \\begin{align*} C=\\frac{1}{N}\\sum_{i=1}^{N}\\big(p_i - c\\big)\\big(p_i - c\\big)^T\\\\ =\\frac{1}{N}\\sum_{i=1}^{N}\\big(p_ip_i^T-p_ic^T-cp_i^T+cc^T\\big)\\\\ =\\frac{1}{N}\\sum_{i=1}^{N}p_ip_i^T-\\frac{1}{N}\\sum_{i=1}^{N}p_ic^T -c\\big(\\frac{1}{N}\\sum_{i=1}^{N}p_i\\big)^T+cc^T\\\\ =\\frac{1}{N}\\sum_{i=1}^{N}p_ip_i^T-cc^T-cc^T+cc^T\\\\ =\\frac{1}{N}\\sum_{i=1}^{N}p_ip_i^T-cc^T \\end{align*} $$八叉树数据结构 通过雷达获取的点云数据，具有数据量大、分布不均匀等特点。点云数据主要是表征目标表面的海量点集合，并不具备传统网格数据的集合拓扑信息。所以点云数据处理中最为核心的问题就是建立离散点间的拓扑关系，实现基于邻域关系的快速查找。\n建立空间索引在点云数据处理中已被广泛应用，常见空间索引一般是自顶向下逐级划分空间的各种空间索引结构，比较有代表性的包括 BSP树、 KD树、 KDB树、 R树、 R+树、 CELL树、四叉树和八叉树等索引结构，而在这些结构中KD树和八叉树在3D点云数据组织中应用较为广泛。\n八叉树（Octree）是一种用于描述三维空间的树状数据结构。八叉树的每个节点表示一个正方体的体积元素，每个节点有8个子节点，这八个子节点所表示的体积元素加在一起等于父节点的体积。一般中心点作为节点的分叉中心。八叉树若不为空树的话，树中任一节点的子节点恰好只会是8个或0个，不会是0或8以外的数目。八叉树叶子节点代表了分辨率最高的情况。例如分辨率设成0.01m，那么每个叶子就是一个1cm见方的小方块。\n代码详解 多激光雷达标定的具体实现与论文是有差异的，被拆为三步实现以降低维度，每步都会涉及的自适应体素化，其代码大同小异，本文代码片段节选自第三步骤，具体参考global.hpp和global.cpp。\nOCTO_TREE类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 class OCTO_TREE { public: std::vector\u0026lt;vector_vec3d*\u0026gt; baseOriginPc;//基准雷达的原始点云 std::vector\u0026lt;vector_vec3d*\u0026gt; baseTransPc; std::vector\u0026lt;std::vector\u0026lt;vector_vec3d*\u0026gt;\u0026gt; refOriginPc; // n个参考雷达的原始点云 std::vector\u0026lt;std::vector\u0026lt;vector_vec3d*\u0026gt;\u0026gt; refTransPc; OCTO_TREE* leaves[8]; int win_size, //帧数 ref_size, //参考雷达的个数 points_size, layer; OT_STATE octo_state;//八叉树节点类型 double voxel_center[3]; double quater_length, eigen_ratio;//面特征的阈值 Eigen::Vector3d value_vector; OCTO_TREE(int window_size, double ref_lidar_size, double eigen_limit): win_size(window_size), ref_size(ref_lidar_size), eigen_ratio(eigen_limit) { octo_state = UNKNOWN; layer = 0; for(int i = 0; i \u0026lt; 8; i++) leaves[i] = nullptr; for(int i = 0; i \u0026lt; win_size; i++) { baseOriginPc.emplace_back(new vector_vec3d()); baseTransPc.emplace_back(new vector_vec3d()); } for(int j = 0; j \u0026lt; ref_size; j++) { std::vector\u0026lt;vector_vec3d*\u0026gt; refOriginPc_, refTransPc_; for(int i = 0; i \u0026lt; win_size; i++) { refOriginPc_.emplace_back(new vector_vec3d()); refTransPc_.emplace_back(new vector_vec3d()); } refOriginPc.emplace_back(refOriginPc_); refTransPc.emplace_back(refTransPc_); } // feat_eigen_limit = 10; } ~OCTO_TREE() { for(int i = 0; i \u0026lt; win_size; i++) { delete (baseOriginPc[i]); delete (baseTransPc[i]); } baseOriginPc.clear(); baseTransPc.clear(); for(int i = 0; i \u0026lt; ref_size; i++) { for(int j = 0; j \u0026lt; win_size; j++) { delete refOriginPc[i][j]; delete refTransPc[i][j]; } refOriginPc[i].clear(); refTransPc[i].clear(); } refOriginPc.clear(); refTransPc.clear(); for(int i = 0; i \u0026lt; 8; i++) if(leaves[i] != nullptr) delete leaves[i]; } /** * @brief 对八叉树节点进行分割 **/ void recut() { // 如果当前八叉树节点的状态未知，则进行分割决策 if (octo_state == UNKNOWN) { points_size = 0; for (int i = 0; i \u0026lt; win_size; i++) { points_size += baseOriginPc[i]-\u0026gt;size(); for (int j = 0; j \u0026lt; ref_size; j++) points_size += refOriginPc[j][i]-\u0026gt;size(); } // 两个停止递归体素化的条件之一：如果点的总大小小于最小值，则将当前节点标记为中间节点并返回 if (points_size \u0026lt; MIN_PS) { octo_state = MID_NODE; return; } // 判断是否满足平面条件，如果满足则将当前节点标记为平面节点并返回 if (judge_eigen()) { octo_state = PLANE; return; } else { // 两个停止递归体素化的条件之一： 如果当前层达到限制，则将当前节点标记为中间节点并返回 if (layer == LAYER_LIMIT) { octo_state = MID_NODE; return; } // 遍历窗口内的每个点云，根据点的位置将其分配到相应的子节点 for (int i = 0; i \u0026lt; win_size; i++) { uint pt_size = baseTransPc[i]-\u0026gt;size(); for (size_t j = 0; j \u0026lt; pt_size; j++) { int xyz[3] = {0, 0, 0}; for (size_t k = 0; k \u0026lt; 3; k++) if ((*baseTransPc[i])[j][k] \u0026gt; voxel_center[k]) xyz[k] = 1; int leafnum = 4 * xyz[0] + 2 * xyz[1] + xyz[2]; // 如果当前子节点为空，则创建一个新的八叉树节点，并设置其参数 if (leaves[leafnum] == nullptr) { leaves[leafnum] = new OCTO_TREE(win_size, ref_size, eigen_ratio); leaves[leafnum]-\u0026gt;voxel_center[0] = voxel_center[0] + (2 * xyz[0] - 1) * quater_length; leaves[leafnum]-\u0026gt;voxel_center[1] = voxel_center[1] + (2 * xyz[1] - 1) * quater_length; leaves[leafnum]-\u0026gt;voxel_center[2] = voxel_center[2] + (2 * xyz[2] - 1) * quater_length; leaves[leafnum]-\u0026gt;quater_length = quater_length / 2; leaves[leafnum]-\u0026gt;layer = layer + 1; } leaves[leafnum]-\u0026gt;baseOriginPc[i]-\u0026gt;emplace_back((*baseOriginPc[i])[j]); leaves[leafnum]-\u0026gt;baseTransPc[i]-\u0026gt;emplace_back((*baseTransPc[i])[j]); } for (int k = 0; k \u0026lt; ref_size; k++) { pt_size = refTransPc[k][i]-\u0026gt;size(); for (size_t j = 0; j \u0026lt; pt_size; j++) { int xyz[3] = {0, 0, 0}; for (size_t a = 0; a \u0026lt; 3; a++) if ((*refTransPc[k][i])[j][a] \u0026gt; voxel_center[a]) xyz[a] = 1; int leafnum = 4 * xyz[0] + 2 * xyz[1] + xyz[2]; if (leaves[leafnum] == nullptr) { leaves[leafnum] = new OCTO_TREE(win_size, ref_size, eigen_ratio); leaves[leafnum]-\u0026gt;voxel_center[0] = voxel_center[0] + (2 * xyz[0] - 1) * quater_length; leaves[leafnum]-\u0026gt;voxel_center[1] = voxel_center[1] + (2 * xyz[1] - 1) * quater_length; leaves[leafnum]-\u0026gt;voxel_center[2] = voxel_center[2] + (2 * xyz[2] - 1) * quater_length; leaves[leafnum]-\u0026gt;quater_length = quater_length / 2; leaves[leafnum]-\u0026gt;layer = layer + 1; } leaves[leafnum]-\u0026gt;refOriginPc[k][i]-\u0026gt;emplace_back((*refOriginPc[k][i])[j]); leaves[leafnum]-\u0026gt;refTransPc[k][i]-\u0026gt;emplace_back((*refTransPc[k][i])[j]); } } } } } for (size_t i = 0; i \u0026lt; 8; i++) if (leaves[i] != nullptr) leaves[i]-\u0026gt;recut(); } /** * @brief 计算和判断给定点云数据的协方差矩阵的特征值的比值 是本文2.1节的协方差矩阵计算的具体实现 * @return bool 根据特征值的比值判断返回true或false */ bool judge_eigen() { Eigen::Matrix3d covMat(Eigen::Matrix3d::Zero()); Eigen::Vector3d center(0, 0, 0); uint pt_size; for (int i = 0; i \u0026lt; win_size; i++) { pt_size = baseTransPc[i]-\u0026gt;size(); for (size_t j = 0; j \u0026lt; pt_size; j++) { covMat += (*baseTransPc[i])[j] * (*baseTransPc[i])[j].transpose(); center += (*baseTransPc[i])[j]; } for (int k = 0; k \u0026lt; ref_size; k++) { pt_size = refTransPc[k][i]-\u0026gt;size(); for (size_t j = 0; j \u0026lt; pt_size; j++) { covMat += (*refTransPc[k][i])[j] * (*refTransPc[k][i])[j].transpose(); center += (*refTransPc[k][i])[j]; } } } //计算中心点 center /= points_size; //计算协方差矩阵 covMat = covMat / points_size - center * center.transpose(); /* saes.eigenvalues()[2] is the biggest */ Eigen::SelfAdjointEigenSolver\u0026lt;Eigen::Matrix3d\u0026gt; saes(covMat); value_vector = saes.eigenvalues(); // 判断特征值的比值是否大于给定的阈值，是则返回true，否则返回false if (eigen_ratio \u0026lt; saes.eigenvalues()[2] / saes.eigenvalues()[0]) return true; return false; } /** * @brief 递归去将平面节点传递给LM优化器 **/ void feed_pt(LM_OPTIMIZER \u0026amp;lm_opt) { if (octo_state == PLANE) lm_opt.push_voxel(baseOriginPc, refOriginPc); else for (int i = 0; i \u0026lt; 8; i++) if (leaves[i] != nullptr) leaves[i]-\u0026gt;feed_pt(lm_opt); } }; downsample_voxel体素下采样函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 /** * @brief 基于体素网格对点云进行下采样 * 本文自适应体素化章节提到，如果一个体素内包含太多点， * 则会导致二阶闭式导数中的Hessian矩阵维度过高，在这种 * 情况下可以进行将点进行一下平均，以降低维度 * @param pc 输入和输出的点云数据 * @param voxel_size 体素网格的大小，决定了下采样的精度 * @return */ void downsample_voxel(pcl::PointCloud\u0026lt;PointType\u0026gt;\u0026amp; pc, double voxel_size) { // 检查体素大小是否过小，如果小于0.01则不进行下采样 if (voxel_size \u0026lt; 0.01) return; // 使用哈希表存储每个体素网格中的点，以实现快速查找和去重 std::unordered_map\u0026lt;VOXEL_LOC, M_POINT\u0026gt; feature_map; size_t pt_size = pc.size(); // 遍历每个点，计算其在体素网格中的位置，并将点加入相应的体素网格 for (size_t i = 0; i \u0026lt; pt_size; i++) { PointType \u0026amp;pt_trans = pc[i]; float loc_xyz[3]; // 计算点在每个维度上所在的体素网格索引 for (int j = 0; j \u0026lt; 3; j++) { loc_xyz[j] = pt_trans.data[j] / voxel_size; // 如果点的体素网格索引小于0，则减去1，保证索引非负 if (loc_xyz[j] \u0026lt; 0) loc_xyz[j] -= 1.0; } // 构造体素网格位置的键 VOXEL_LOC position((int64_t)loc_xyz[0], (int64_t)loc_xyz[1], (int64_t)loc_xyz[2]); // 在哈希表中查找当前体素网格位置 auto iter = feature_map.find(position); if (iter != feature_map.end()) { // 如果当前体素网格已存在点，则累加点的坐标，并增加点的计数 iter-\u0026gt;second.xyz[0] += pt_trans.x; iter-\u0026gt;second.xyz[1] += pt_trans.y; iter-\u0026gt;second.xyz[2] += pt_trans.z; iter-\u0026gt;second.count++; } else { // 如果当前体素网格不存在点，则创建新的体素网格点，并加入哈希表 M_POINT anp; anp.xyz[0] = pt_trans.x; anp.xyz[1] = pt_trans.y; anp.xyz[2] = pt_trans.z; anp.count = 1; feature_map[position] = anp; } } // 重新计算下采样后的点云大小，并清空原有数据 pt_size = feature_map.size(); pc.clear(); pc.resize(pt_size); // 遍历哈希表，计算每个体素网格点的平均坐标，并填充到输出点云数据中 size_t i = 0; for (auto iter = feature_map.begin(); iter != feature_map.end(); ++iter) { pc[i].x = iter-\u0026gt;second.xyz[0] / iter-\u0026gt;second.count; pc[i].y = iter-\u0026gt;second.xyz[1] / iter-\u0026gt;second.count; pc[i].z = iter-\u0026gt;second.xyz[2] / iter-\u0026gt;second.count; i++; } } cut_voxel体素裁剪函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 /** * @brief 切割体素函数，用于处理特征点云并构建体素特征映射 * * @param feature_map 特征映射，键为体素位置，值为体素树指针 * @param feature_pts 特征点云数据指针 * @param q 旋转矩阵，表示点云的旋转情况 在本文中来源于初始可用的基准雷达的轨迹$\\mathcal{S}$ * @param t 平移向量，表示点云的平移情况 在本文中来源于初始可用的基准雷达的轨迹$\\mathcal{S}$ * @param f_head 用于特征存储的头部索引 * @param baselidar_sz 基础激光雷达数据的体素尺寸 * @param exlidar_sz 扩展激光雷达数据的体素尺寸 * @param eigen_threshold 特征值阈值，用于体素特征提取 * @param exlidar_n 扩展激光雷达的编号，默认为0 * @param is_base_lidar 标记当前处理的是基础激光雷达数据还是扩展激光雷达数据，默认为true */ void cut_voxel(unordered_map\u0026lt;VOXEL_LOC, OCTO_TREE *\u0026gt; \u0026amp;feature_map, pcl::PointCloud\u0026lt;PointType\u0026gt;::Ptr feature_pts, Eigen::Quaterniond q, Eigen::Vector3d t, int f_head, int baselidar_sz, int exlidar_sz, double eigen_threshold, int exlidar_n = 0, bool is_base_lidar = true) { uint pt_size = feature_pts-\u0026gt;size(); for (uint i = 0; i \u0026lt; pt_size; i++) { PointType \u0026amp;pt = feature_pts-\u0026gt;points[i]; Eigen::Vector3d pt_origin(pt.x, pt.y, pt.z); // 将点进行旋转和平移变换,转化到世界坐标系中 Eigen::Vector3d pt_trans = q * pt_origin + t; // 计算点在体素网格中的位置 float loc_xyz[3]; for (int j = 0; j \u0026lt; 3; j++) { loc_xyz[j] = pt_trans[j] / voxel_size; if (loc_xyz[j] \u0026lt; 0) loc_xyz[j] -= 1.0; } // 构建体素位置键 VOXEL_LOC position((int64_t) loc_xyz[0], (int64_t) loc_xyz[1], (int64_t) loc_xyz[2]); // 检查该体素位置是否已存在于特征映射中 auto iter = feature_map.find(position); if (iter != feature_map.end()) { // 如果存在，则向该体素中添加点数据 if (is_base_lidar) { iter-\u0026gt;second-\u0026gt;baseOriginPc[f_head]-\u0026gt;emplace_back(pt_origin); iter-\u0026gt;second-\u0026gt;baseTransPc[f_head]-\u0026gt;emplace_back(pt_trans); } else { iter-\u0026gt;second-\u0026gt;refOriginPc[exlidar_n][f_head]-\u0026gt;emplace_back(pt_origin); iter-\u0026gt;second-\u0026gt;refTransPc[exlidar_n][f_head]-\u0026gt;emplace_back(pt_trans); } } else { // 如果不存在，则创建新的体素树，并向其中添加点数据 OCTO_TREE *ot = new OCTO_TREE(baselidar_sz, exlidar_sz, eigen_threshold); if (is_base_lidar) { ot-\u0026gt;baseOriginPc[f_head]-\u0026gt;emplace_back(pt_origin); ot-\u0026gt;baseTransPc[f_head]-\u0026gt;emplace_back(pt_trans); } else { ot-\u0026gt;refOriginPc[exlidar_n][f_head]-\u0026gt;emplace_back(pt_origin); ot-\u0026gt;refTransPc[exlidar_n][f_head]-\u0026gt;emplace_back(pt_trans); } // 设置体素树的中心点和长度 ot-\u0026gt;voxel_center[0] = (0.5 + position.x) * voxel_size; ot-\u0026gt;voxel_center[1] = (0.5 + position.y) * voxel_size; ot-\u0026gt;voxel_center[2] = (0.5 + position.z) * voxel_size; ot-\u0026gt;quater_length = voxel_size / 4.0; ot-\u0026gt;layer = 0; // 将新的体素树添加到特征映射中 feature_map[position] = ot; } } } 参考文献 [1]《Targetless Extrinsic Calibration of Multiple Small FoV LiDARs and Cameras using Adaptive Voxelization》\n[2]《BALM: Bundle Adjustment for Lidar Mapping》\n[3]《octree八叉树数据结构原理与实现》\n","date":"2024-09-16T15:55:17+08:00","image":"https://wzwan-developer.github.io/p/mlcc/00/lidar_voxel_hu16969779438898434220.png","permalink":"https://wzwan-developer.github.io/p/mlcc/00/","title":"Chapter 00: Adaptive Voxelization"},{"content":"文章内容 $$\\arg\\min_{{\\mathcal{S},\\mathcal{E}_{L},{n}_{l},{q}_{l}}}\\sum_{l}\\underbrace{{\\left(\\frac{1}{N_{l}}\\sum_{k=1}^{{N_{l}}}\\left({n}_{l}^{T}\\left(^{G}{p}_{k}-{q}_{l}\\right)\\right)^{2}\\right)}}_{{l\\mathrm{-th~factor}}}$$， where $_{}^{G}p_{k}\\in \\mathcal{P}_{l}$, $N_{l}$ is the total number of points in $\\mathcal{P}_{l}$, $n_{l}$ is the normal vector of the plane and $q_{l}$ is a point on this plane. Fig.4 :(a) The $l-th$ factor item relating to $\\mathcal{S}$ and $\\mathcal{E}_{L}$ with $L_{i} \\in \\mathcal{L}$ and $t_{j} \\in \\mathcal{T}$ . (b) The distance from the point $_{}^{G}p_{k}$ to the plane $\\pi$.\n$$\\arg\\min_{{\\mathcal{S},\\mathcal{E}_{L},{n}_{l},{q}_{l}}}\\sum_{l}\\underbrace{{\\left(\\frac{1}{N_{l}}\\sum_{k=1}^{{N_{l}}}\\left({n}_{l}^{T}\\left(^{G}{p}_{k}-{q}_{l}\\right)\\right)^{2}\\right)}}_{{l\\mathrm{-th~factor}}}$$ ，其中 $_{}^{G}p_{k}\\in \\mathcal{P}_{l}$，$N_{l}$ 是 $\\mathcal{P}_{l}$中所有点的总点数, $n_{l}$ 是平面的 法向量， $q_{l}$ 是平面中的一点。 Fig.4 :(a) 第$l$ 个因子项，涉及$\\mathcal{S}$ 和 $\\mathcal{E}_{L}$，其中 $L_{i} \\in \\mathcal{L}$ 且 $t_{j} \\in \\mathcal{T}$ 。 (b)点 $_{}^{G}p_{k}$到平面$\\pi$的距离.\n$$ \\arg\\min_{\\mathcal{S},\\mathcal{E}_{L}}\\sum_{l}^{}\\lambda_{3}(A_{l}) $$$$ A_{l}=\\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \\cdot_{}^{G}p_{k}^{T}-q_{l}^{\\ast}\\cdot {q_{l}^{\\ast}}^{T}},q_{l}^{\\ast} =\\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{_{}^{G}p_{k}} $$$$\\lambda_3({x}\\boxplus\\delta{x})\\approx\\lambda_3({x})+{\\bar{J}}\\delta{x}+\\frac12\\delta{x}^T{\\bar{H}}\\delta{x}$$$${x}=[\\underbrace{\\cdots_{L_{0}}^{G}{R}_{t_{j}}\\quad L_{0}^{G}{t}_{t_{j}}\\cdots}_{\\mathcal{S}}\\underbrace{\\cdots {}_{L_{i}}^{L_{0}}{R}\\quad{}_{L_{i}}^{L_{0}}{t}\\cdots}_{\\mathcal{E}_{L}}]$$$$(\\bar{{H}}+\\mu{I}) \\delta{x}=-\\bar{{J}}^T$$ $$ \\arg\\min_{\\mathcal{S},\\mathcal{E}_{L}}\\sum_{l}^{}\\lambda_{3}(A_{l}) $$$$ A_{l}=\\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \\cdot_{}^{G}p_{k}^{T}-q_{l}^{\\ast}\\cdot {q_{l}^{\\ast}}^{T}},q_{l}^{\\ast} =\\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{_{}^{G}p_{k}}$$$$\\lambda_3({x}\\boxplus\\delta{x})\\approx\\lambda_3({x})+{\\bar{J}}\\delta{x}+\\frac12\\delta{x}^T{\\bar{H}}\\delta{x}$$$${x}=[\\underbrace{\\cdots_{L_{0}}^{G}{R}_{t_{j}}\\quad L_{0}^{G}{t}_{t_{j}}\\cdots}_{\\mathcal{S}}\\underbrace{\\cdots_{L_{i}}^{L_{0}}{R}\\quad {}_{L_{i}}^{L_{0}}{t}\\cdots}_{\\mathcal{E}_{L}}]$$$$(\\bar{{H}}+\\mu{I}) \\delta{x}=-{\\bar{{J}}}^T$$理论推导 损失函数的降维 推导一：BALM论文的思路 $$\\arg\\min_{{\\mathcal{S},\\mathcal{E}_{L},{n}_{l},{q}_{l}}}\\sum_{l}\\underbrace{{\\left(\\frac{1}{N_{l}}\\sum_{k=1}^{{N_{l}}}\\left({n}_{l}^{T}\\left(^{G}{p}_{k}-{q}_{l}\\right)\\right)^{2}\\right)}}_{{l\\mathrm{-th~factor}}}$$$$\\arg\\min_{{\\mathcal{S},\\mathcal{E}_{L}}}\\sum_{l}{\\left(\\min_{n_{l},q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( n_{l}^{T}\\left( {^{G}p_{k}-q_{l}}\\right)\\right)^{2}}} \\right)} $$$$\\begin{align*}\\arg\\min_{n_{l},q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( n_{l}^{T}\\left( {^{G}p_{k}-q_{l}}\\right)\\right)^{2}}} \\\\ = \\arg\\min_{n_{l}}\\left( \\min_{q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( n_{l}^{T}\\left( {^{G}p_{k}-q_{l}}\\right)\\right)^{2}}}\\right)\\\\ =\\arg\\min_{n_{l}}n_{l}^{T}\\left( \\min_{q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}}\\right)^{2}}}\\right)n_{l} \\end{align*}$$$$\\begin{align*}\\arg\\min_{q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}}\\right)^{2}}}\\\\ =\\min_{q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}}\\right)\\left( {^{G}p_{k}-q_{l}}\\right)^{T}}}\\end{align*}$$$$\\begin{align*}\\frac{\\partial}{\\partial{q_{l}}} \\left( {\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}}\\right)\\left( {^{G}p_{k}-q_{l}}\\right)^{T}}}\\right) \\\\ ={\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} {-({^{G}p_{k}-q_{l})}^{T}}-\\left( {^{G}p_{k}-q_{l}}\\right)}}\\\\ = {\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} {-2({^{G}p_{k}-q_{l})}}}}\\\\ =-{\\frac{2}{N_{l}}{\\sum_{k=1}^{N_{l}} {({^{G}p_{k}-q_{l})}}}} \\end{align*}$$$$\\begin{align*}-{\\frac{2}{N_{l}}{\\sum_{k=1}^{N_{l}} {({^{G}p_{k}}-q_{l})}}}=0 \\\\ \\sum_{k=1}^{N_{l}}{({^{G}p_{k}-q_{l}})} =0\\\\ \\sum_{k=1}^{N_{l}}{^{G}p_{k}}-N_{l}q_{l}=0\\\\ N_{l}q_{l}=\\sum_{k=1}^{N_{l}}{^{G}p_{k}}\\\\ q_{l}=\\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{^{G}p_{k}} \\end{align*}$$$$\\begin{align*}\\arg\\min_{n_{l}}n_{l}^{T}\\left( \\min_{q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}}\\right)^{2}}}\\right)n_{l}\\\\ =\\arg\\min_{n_{l}}n_{l}^{T}\\left( {\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}^{\\ast}}\\right)^{2}}}\\right)n_{l}\\end{align*}$$$${\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}^{\\ast}}\\right)^{2}}}\\\\ \\Leftrightarrow \\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \\cdot_{}^{G}p_{k}^{T}-q_{l}^{\\ast}\\cdot {q_{l}^{\\ast}}^{T}} $$$$ A_{l}=\\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{_{}^{G}p_{k} \\cdot_{}^{G}p_{k}^{T}-q_{l}^{\\ast}\\cdot {q_{l}^{\\ast}}^{T}},q_{l}^{\\ast} =\\frac{1}{N_{l}}\\sum_{k=1}^{N_{l}}{_{}^{G}p_{k}}$$$$\\begin{align*}\\arg\\min_{n_{l}}n_{l}^{T}\\left( {\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}^{\\ast}}\\right)^{2}}}\\right)n_{l}\\\\ =\\arg\\min_{n_{l}}n_{l}^{T}A_{l}n_{l}\\end{align*}$$$$\\lambda_{min}(M)\\le \\frac{x^{T}Mx}{x^{T}x}\\le\\lambda_{max}(M),\\forall{x}\\ne0$$$$\\begin{align*}\\ =\\lambda_{min}(A_{l})\\\\arg\\min_{n_{l}}n_{l}^{T}\\left( \\min_{q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( {^{G}p_{k}-q_{l}}\\right)^{2}}}\\right)n_{l}\\\\ =\\lambda_{3}(A_{l})\\end{align*}$$$$\\begin{align*}\\arg\\min_{{\\mathcal{S},\\mathcal{E}_{L}}}\\sum_{l}{\\left(\\min_{n_{l},q_{l}}{\\frac{1}{N_{l}}{\\sum_{k=1}^{N_{l}} \\left( n_{l}^{T}\\left( {^{G}p_{k}-q_{l}}\\right)\\right)^{2}}} \\right)}\\\\ =\\arg\\min_{{\\mathcal{S},\\mathcal{E}_{L}}}\\sum_{l}{\\lambda_{3}(A_{l})}\\end{align*}$$补充内容：由上述图4可知，$n_{l}^{T}({}^{G}p_{k}-q_{l})$表达了点${}^{G}p_{k}$到平面$\\pi$的距离，其推导来源于向量法求点到平面的距离。如下图所示： 推导二：该论文中的推导思路 后续补充！\n二阶闭式导数的推导 首先引入BALM中两个定理，如下所示:\n定理1 $${A}=\\frac1N\\sum_{i=1}^N\\left({p}_i-\\bar{{p}}\\right)\\left({p}_i-\\bar{{p}}\\right)^T,\\bar{{p}}=\\frac{1}{N}\\sum_{i=1}^{N}{p}_{i}$$$$\\frac{\\partial\\lambda_k}{\\partial{p}_i}=\\frac2N({p}_i-\\bar{{p}})^T{u}_k{u}_k^T$$其中,$\\bar{p}$是$N$个点的均值。\n证明如下：假设点$p_i= [x_{i} \\quad y_{i} \\quad z_{i}]^{T}$以及对应的特征向量矩阵$U={[u_{1} \\quad u_{2} \\quad u_{3} ]}^{T}$。进一步定义$p$是$p_{i}$的一个元素，$p$是$x_{i},y_{i},z_{i}$中其中一个。协方差矩阵$A$可以分解为 $\\Lambda=U^{T}AU$,其中:\n$\\Lambda$是对角矩阵，其对角线元素是特征值, $\\lambda_{1},\\lambda_{2},\\lambda_{3}$。 $U$是一个正交矩阵，其列是$A$的特征向量$u_{1},u_{2},u_{3}$。 $$ \\frac{\\partial{}\\Lambda}{\\partial{p}}=\\left( \\frac{\\partial{U}}{\\partial{p}}\\right)^{T}AU+U^{T}\\left(\\frac{\\partial{A}}{\\partial{p}}\\right)U+U^{T}A\\left(\\frac{\\partial{U}}{\\partial{p}}\\right)\\tag{式1} $$$$U^{T}A=\\Lambda{}U^{T},AU=U\\Lambda\\tag{式2}$$$$ \\frac{\\partial{}\\Lambda}{\\partial{p}}=\\left( \\frac{\\partial{U}}{\\partial{p}}\\right)^{T}U\\Lambda+U^{T}\\left(\\frac{\\partial{A}}{\\partial{p}}\\right)U+\\Lambda{}U^{T}\\left(\\frac{\\partial{U}}{\\partial{p}}\\right)\\tag{式3} $$$$ U^{T}U=I\\\\ \\Longrightarrow {U^{T}\\frac{\\partial{U}}{\\partial{p}}+\\left(\\frac{\\partial{U}}{\\partial{p}}\\right)^{T}U=0}\\tag{式4} $$$$ \\left( \\frac{\\partial{U}}{\\partial{p}}\\right)^{T}U\\Lambda+\\Lambda{}U^{T}\\left(\\frac{\\partial{U}}{\\partial{p}}\\right)=0\\tag{式5} $$$$ \\frac{\\partial{}\\Lambda}{\\partial{p}}=U^{T}\\left(\\frac{\\partial{A}}{\\partial{p}}\\right)U\\tag{式6} $$$$ \\frac{\\partial{}\\lambda_{k}}{\\partial{p}}={u_{k}}^{T}\\left(\\frac{\\partial{A}}{\\partial{p}}\\right)u_{k}=\\frac{\\partial{{u_{k}}^{T}Au_{k}}}{\\partial{p}}\\tag{式7} $$$$ \\frac{\\partial{}\\lambda_{k}}{\\partial{p_{i}}}=\\begin{bmatrix} \\frac{\\partial{{u_{k}}^{T}Au_{k}}}{\\partial{x_{i}}}\u0026 \\frac{\\partial{{u_{k}}^{T}Au_{k}}}{\\partial{y_{i}}}\u0026 \\frac{\\partial{{u_{k}}^{T}Au_{k}}}{\\partial{z_{i}}} \\end{bmatrix}=\\frac{\\partial{{u_{k}}^{T}Au_{k}}}{\\partial{p_{i}}}\\tag{式8} $$$$ \\begin{align} \\frac{\\partial{}\\lambda_{k}}{\\partial{p_{j}}}=\\frac1N\\sum_{i=1}^N{\\frac{\\partial{{u_{k}}^{T}\\left({p}_j-\\bar{p}\\right)\\left(p_j-\\bar{p}\\right)^Tu_{k}}}{\\partial{p_{i}}}}\\\\ =\\frac1N\\sum_{j=1}^N{\\frac{\\partial{\\left({p}_j-\\bar{p}\\right)^{T}{u_{k}}{u_{k}}^{T}\\left(p_j-\\bar{p}\\right)}}{\\partial{p_{i}}}}\\\\ =\\frac1N\\sum_{j=1}^N{\\frac{\\partial\\left(\\left({u_{k}}^{T}\\left(p_j-\\bar{p}\\right)\\right)^{T}\\left({u_{k}}^{T}\\left(p_j-\\bar{p}\\right)\\right)\\right)}{\\partial{p_{i}}}}\\\\ =\\frac1N\\sum_{j=1}^N{2{\\left(p_j-\\bar{p}\\right)^{T}u_{k}}\\frac{\\partial{u_{k}}^{T}\\left(p_j-\\bar{p}\\right)}{\\partial{p_{i}}}}\\\\ =\\frac2N\\sum_{j=1}^N{{\\left(p_j-\\bar{p}\\right)^{T}u_{k}}\\frac{\\partial{u_{k}}^{T}\\left(p_j-\\bar{p}\\right)}{\\partial{p_{i}}}}\\\\ =\\frac2N\\sum_{j=1}^N{{\\left(p_j-\\bar{p}\\right)^{T}u_{k}}\\frac{\\partial{u_{k}}^{T}\\left(p_j-\\left(\\frac{1}{N}\\sum_{i=1}^{N}p_{i}\\right)\\right)}{\\partial{p_{i}}}}\\\\ =\\frac2N{{\\left(p_i-\\bar{p}\\right)^{T}u_{k}}{u_{k}}^{T}\\left(I-\\frac{1}{N}I\\right)}+\\\\\\frac2N\\sum_{j=1,j\\ne{i}}^N\\left(p_j-\\bar{p}\\right)^{T}u_{k}{u_{k}}^{T}\\left(-\\frac{1}{N}I\\right)\\\\ =\\frac2N{{\\left(p_i-\\bar{p}\\right)^{T}u_{k}}{u_{k}}^{T}\\left(I-\\frac{1}{N}I\\right)}+\\\\\\frac2Nu_{k}{u_{k}}^{T}\\left(-\\frac{1}{N}I\\right)\\sum_{j=1,j\\ne{i}}^N\\left(p_j-\\bar{p}\\right)^{T}\\\\ =\\frac2N{{\\left(p_i-\\bar{p}\\right)^{T}u_{k}}{u_{k}}^{T}\\left(I-\\frac{1}{N}I\\right)}+\\\\\\frac2Nu_{k}{u_{k}}^{T}\\left(-\\frac{1}{N}I\\right)\\left(\\left(\\sum_{j=1}^{N}(p_{j}-\\bar{p})^{T}\\right)-\\left(p_i-\\bar{p}\\right)^{T}\\right)\\\\ =\\frac2N{{\\left(p_i-\\bar{p}\\right)^{T}u_{k}}{u_{k}}^{T}\\left(I-\\frac{1}{N}I\\right)}+\\\\\\frac2Nu_{k}{u_{k}}^{T}\\left(-\\frac{1}{N}I\\right)\\left(0-\\left(p_i-\\bar{p}\\right)^{T}\\right)\\\\ =\\frac2N{{\\left(p_i-\\bar{p}\\right)^{T}u_{k}}{u_{k}}^{T}} \\end{align}\\tag{式9} $$$$ \\frac{\\partial{p}_j}{\\partial{p}_i}={I},(i=j)\\quad\\frac{\\partial{p}_j}{\\partial{p}_i}={0},(i\\neq j) \\tag{式10} $$定理2 $${A}=\\frac1N\\sum_{i=1}^N\\left({p}_i-\\bar{{p}}\\right)\\left({p}_i-\\bar{{p}}\\right)^T,\\bar{{p}}=\\frac{1}{N}\\sum_{i=1}^{N}{p}_{i}$$$$\\begin{aligned}\\frac{\\partial^{2}\\lambda_{k}}{\\partial{p}_{j}\\partial{p}_{i}}=\\begin{cases}\\frac{2}{N}\\biggl(\\frac{N-1}{N}{u}_{k}{u}_{k}^{T}+{u}_{k}({p}_{i}-\\bar{{p}})^{T}{U}{F}_{k}^{{p}_{j}}\\\\\\\\+{U}{F}_{k}^{{p}_{j}}\\biggl({u}_{k}^{T}({p}_{i}-\\bar{{p}})\\biggr)\\biggr),\\quad i=j\\\\\\\\\\frac{2}{N}\\biggl(-\\frac{1}{N}{u}_{k}{u}_{k}^{T}+{u}_{k}({p}_{i}-\\bar{{p}})^{T}{U}{F}_{k}^{{p}_{j}}\\\\\\\\+{U}{F}_{k}^{{p}_{j}}\\biggl({u}_{k}^{T}({p}_{i}-\\bar{{p}})\\biggr)\\biggr),\\quad i\\neq j\\end{cases}\\end{aligned}$$$${F}_{k}^{{P}_{j}}=\\begin{bmatrix}{F}_{1,k}^{{P}_{j}}\\\\{F}_{2,k}^{{P}_{j}}\\\\{F}_{3,k}^{{P}_{j}}\\end{bmatrix}\\in\\mathbb{R}^{3\\times3},\\quad{U}=\\begin{bmatrix}{u}_{1}\u0026{u}_{2}\u0026{u}_{3}\\end{bmatrix}$$$$\\left.{F}_{m,n}^{{P}_{j}}=\\left\\{\\begin{matrix}\\frac{({p}_{j}-\\bar{{p}})^{T}}{N(\\lambda_{n}-\\lambda_{m})}({u}_{m}{u}_{n}^{T}+{u}_{n}{u}_{m}^{T}),m\\neq n\\\\{0}_{1\\times3}\u0026,m=n\\end{matrix}\\right.\\right.$$ $${A}={U}{\\Lambda}{U}^{T} \\tag{式1}$$$$\\frac{\\partial{A}}{\\partial q}=\\frac{\\partial}{\\partial q}\\left({U}{\\Lambda}{U}^{T}\\right)\\tag{式2}$$$${\\frac{\\partial{A}}{\\partial q}}={\\frac{\\partial{U}}{\\partial q}}{\\Lambda}{U}^{T}+{U}{\\frac{\\partial{\\Lambda}}{\\partial q}}{U}^{T}+{U}{\\Lambda}{\\frac{\\partial{U}^{T}}{\\partial q}} $$$$\\begin{align} \\frac{\\partial{A}}{\\partial q}=\\frac{\\partial{U}}{\\partial q}{\\Lambda}{U}^T+{U}\\frac{\\partial{\\Lambda}}{\\partial q}{U}^T+{U}{\\Lambda}\\left(\\frac{\\partial{U}}{\\partial q}\\right)^T\\\\ \\Longrightarrow {U}^{T}{\\frac{\\partial{A}}{\\partial q}}{U}={U}^{T}{\\frac{\\partial{U}}{\\partial q}}{\\Lambda}+{\\frac{\\partial{\\Lambda}}{\\partial q}}+{\\Lambda}\\left({\\frac{\\partial{U}}{\\partial q}}\\right)^{T}{U} \\end{align}\\tag{式3}$$$$ {U}^{T}{\\frac{\\partial{A}}{\\partial q}}{U}={C}^{q}{\\Lambda}+{\\frac{\\partial{\\Lambda}}{\\partial q}}-{\\Lambda}{C}^{q} \\tag{式4}$$$$ \\begin{align} \\left({U}^T\\frac{\\partial{A}}{\\partial q}{U}\\right)_{m,n}=\\left(\\frac{\\partial\\boldsymbol{\\Lambda}}{\\partial q}\\right)_{m,n}-\\left({\\Lambda}{C}^q-{C}^q{\\Lambda}\\right)_{m,n}\\\\ \\Longrightarrow \\left(\\frac{\\partial\\boldsymbol{\\Lambda}}{\\partial q}\\right)_{m,n}=\\left({U}^T\\frac{\\partial{A}}{\\partial q}{U}\\right)_{m,n}+\\left({\\Lambda}{C}^q-{C}^q{\\Lambda}\\right)_{m,n}\\\\ \\Longrightarrow 0=\\left({U}^T\\frac{\\partial{A}}{\\partial q}{U}\\right)_{m,n}+\\left({\\Lambda}{C}^q-{C}^q{\\Lambda}\\right)_{m,n}\\\\ \\Longrightarrow 0=u_{m}^{T}{\\frac{\\partial{A}}{\\partial{q}}}u_{n}+\\lambda_{m}C_{m,n}^{q}-C_{m,n}^{q}\\lambda_{n}\\\\ \\Longrightarrow C_{m,n}^{q}\\left(\\lambda_{m}-\\lambda_{n}\\right)=-u_{m}^{T}{\\frac{\\partial{A}}{\\partial{q}}}u_{n}\\\\ \\Longrightarrow {C}_{m,n}^q=\\frac{{u}_m^T\\frac{\\partial{A}}{\\partial q}{u}_n}{\\lambda_n-\\lambda_m}\u0026,(\\lambda_{m}\\ne\\lambda_{n}) \\end{align} \\tag{式5}$$$$\\begin{align} {C}_{m,m}^q={u}_m^T\\frac{\\partial{u}_m}{\\partial q}\\\\ \\Longrightarrow {C}_{m,m}^q=0\u0026,(m=n) \\end{align}\\tag{式6}$$$$ \\begin{align} \\frac{\\partial u_{k}}{\\partial{q}}=\\frac{\\partial Ue_{k}}{\\partial q} =UU^{T}\\frac{\\partial U}{\\partial q}e_{k} =UC^{q}e_{k} \\end{align} \\tag{式7} $$$$ C^{q}e_{k}=\\begin{bmatrix} C_{1,k}^{q}\\\\ C_{2,k}^{q}\\\\ C_{3,k}^{q} \\end{bmatrix} \\tag{式8}$$$$ \\begin{align} \\begin{aligned} \\frac{\\partial{u}_k}{\\partial{p}_j}\u0026 =\\begin{bmatrix}\\frac{\\partial{U}{e}_k}{\\partial x_j}\u0026\\frac{\\partial{U}{e}_k}{\\partial y_j}\u0026\\frac{\\partial{U}{e}_k}{\\partial z_j}\\end{bmatrix} \\\\ \u0026=\\begin{bmatrix}{U}{C}^{x_j}{e}_k\u0026{U}{C}^{y_j}{e}_k\u0026{U}{C}^{z_j}{e}_k\\end{bmatrix} \\\\ \u0026={U}\\big[{C}^{x_j}{e}_k\\quad{C}^{y_j}{e}_k\\quad{C}^{z_j}{e}_k\\big] \\\\ \u0026={U}\\begin{bmatrix}{C}_{1,k}^{x_j}\u0026{C}_{1,k}^{y_j}\u0026{C}_{1,k}^{z_j}\\\\{C}_{2,k}^{x_j}\u0026{C}_{2,k}^{y_j}\u0026{C}_{2,k}^{z_j}\\\\{C}_{3,k}^{x_j}\u0026{C}_{3,k}^{y_j}\u0026{C}_{3,k}^{z_j}\\end{bmatrix} \\end{aligned} \\end{align} \\tag{式9} $$$$ \\begin{align*} {F}_{m,n}^{{p}_{j}}= \\begin{bmatrix}{C}_{m,n}^{x_{j}}\u0026{C}_{m,n}^{y_{j}}\u0026{C}_{m,n}^{z_{j}}\\end{bmatrix}\\in\\mathbb{R}^{1\\times3},\\quad m,n\\in\\{1,2,3\\}.\\\\ =\\begin{cases} \\frac{{u}_m^T\\frac{\\partial{A}}{\\partial {p_{j}}}{u}_n}{\\lambda_n-\\lambda_m} , \\quad m\\ne n \\\\ 0,\\quad m=n \\end{cases} \\end{align*} \\tag{式10}$$$$ \\frac{\\partial{u_{k}}}{\\partial{p_{j}}}= U\\begin{bmatrix} F_{1,k}^{p_{j}}\\\\ F_{2,k}^{p_{j}}\\\\ F_{3,k}^{p_{j}} \\end{bmatrix} =UF_{k}^{p_{j}}\\tag{式11}$$$$ \\begin{align*} \\frac{u_{m}^{T} \\frac{\\partial A }{\\partial p_{j}} u_{n}}{\\lambda_n -\\lambda_m}\\\\ =\\frac{1}{\\lambda_n -\\lambda_m}\\cdot u_{m}^{T} \\frac{\\partial A }{\\partial p_{j}} u_{n}\\\\ =\\frac{1}{\\lambda_n -\\lambda_m}\\cdot u_{m}^{T} \\frac{\\partial {\\left({A}=\\frac1N\\sum_{i=1}^N\\left({p}_i-\\bar{{p}}\\right)\\left({p}_i-\\bar{{p}}\\right)^T\\right)} }{\\partial p_{j}} u_{n}\\\\ =\\frac{1}{\\lambda_n -\\lambda_m}\\cdot\\left(\\frac{1}{N}\\sum_{i=1}^{N}\\frac{u_{m}^{T}\\left(p_{i}-\\bar{p}\\right)\\left(p_{i}-\\bar{p}\\right)^{T}u_{n}}{\\partial{p_j}}\\right)\\\\ =\\frac{1}{\\lambda_n -\\lambda_m} \\cdot\\frac{1}{N}\\sum_{i=1}^{N} \\left(\\frac{u_{m}^{T}\\left(p_{i}-\\bar{p}\\right)\\left(p_{i}-\\bar{p}\\right)^{T}u_{n}}{\\partial{\\left(p_{i}-\\bar{p}\\right)}}\\cdot\\frac{\\partial{\\left(p_{i}-\\bar{p}\\right)}}{\\partial{p_j}}\\right)\\\\ =\\frac{1}{\\lambda_n -\\lambda_m} \\cdot\\frac{1}{N}\\sum_{i=1}^{N} \\left(\\left(p_{i}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\cdot\\frac{\\partial{\\left(p_{i}-\\bar{p}\\right)}}{\\partial{p_j}}\\right)\\\\ =\\frac{1}{\\lambda_n -\\lambda_m}\\\\ \\cdot\\frac{1}{N}\\sum_{i=1}^{N} \\left(\\left(p_{i}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\cdot \\frac{\\partial{\\left(p_{i}-\\left(\\frac{1}{N}\\sum_{i=1}^{N}{p}_{i}\\right)\\right)}}{\\partial{p_j}}\\right)\\\\ =\\frac{1}{\\lambda_n -\\lambda_m}\\\\ \\cdot\\frac{1}{N}\\sum_{i=1}^{N} \\left(\\left(p_{i}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\cdot \\frac{\\partial{\\left(p_{i}-\\left(\\frac{1}{N}\\sum_{i=1}^{N}{p}_{i}\\right)\\right)}}{\\partial{p_j}}\\right)\\\\ =\\frac{1}{\\lambda_n -\\lambda_m} \\frac{1}{N}\\left(p_{j}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right) \\cdot \\left(I-\\frac{1}{N}I\\right)\\\\ +\\frac{1}{N}\\sum_{i=1,i\\ne{j}}^{N}{\\left(\\left(p_{i}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\cdot\\left(-\\frac{1}{N}I\\right)\\right)}\\\\ =\\frac{1}{\\lambda_n -\\lambda_m} \\frac{1}{N}\\left(p_{j}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right) \\cdot \\left(I-\\frac{1}{N}I\\right)\\\\ +\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\left(-\\frac{1}{N}I\\right) \\frac{1}{N}\\sum_{i=1,i\\ne{j}}^{N}\\left(p_{i}-\\bar{p}\\right)^{T}\\\\ =\\frac{1}{\\lambda_n -\\lambda_m} \\frac{1}{N}\\left(p_{j}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right) \\cdot\\left(I-\\frac{1}{N}I\\right)\\\\ +\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\left(-\\frac{1}{N}I\\right) \\left(\\left(\\sum_{i=1}^{N}(p_{i}-\\bar{p})^{T}\\right)-\\left(p_j-\\bar{p}\\right)^{T}\\right)\\\\ =\\frac{1}{\\lambda_n -\\lambda_m} \\frac{1}{N}\\left(p_{j}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right) \\cdot\\left(I-\\frac{1}{N}I\\right)\\\\ +\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\left(-\\frac{1}{N}I\\right) \\left(0-\\left(p_j-\\bar{p}\\right)^{T}\\right)\\\\ =\\frac{1}{\\lambda_n -\\lambda_m} \\frac{1}{N}\\left(p_{j}-\\bar{p}\\right)^{T}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right)\\\\ =\\frac{\\left(p_{j}-\\bar{p}\\right)^{T}}{\\left(\\lambda_n -\\lambda_m\\right)N}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right) \\end{align*} \\tag{式12}$$$$ \\frac{\\partial{p}_j}{\\partial{p}_i}={I},(i=j)\\quad\\frac{\\partial{p}_j}{\\partial{p}_i}={0},(i\\neq j) \\tag{式13}$$$$ \\frac{\\partial {a}^\\top{x}{x}^\\top{b}}{\\partial {x}}={x}^\\top\\left({a}{b}^\\top+{b}{a}^\\top\\right) \\tag{式14}$$$$ F_{m,n}^{p_{j}}= \\begin{cases} \\frac{\\left(p_{j}-\\bar{p}\\right)^{T}}{\\left(\\lambda_n -\\lambda_m\\right)N}\\left(u_{m}u_{n}^{T}+u_{n}u_{m}^{T}\\right),\\quad m\\ne n\\\\ 0,\\quad m=n \\end{cases} \\tag{式15}$$$$ \\begin{align*} \\frac{\\partial}{\\partial{p_{j}}}\\left(\\frac{\\partial{\\lambda_k}}{\\partial{p_{i}}}\\right) =\\frac{\\partial{\\frac2N\\left({{\\left(p_i-\\bar{p}\\right)^{T}u_{k}}{u_{k}}^{T}}\\right)^{T}}}{\\partial{p_{j}}}\\\\ =\\frac{2}{N}\\cdot\\frac{\\partial{u_{k}{u_{k}}^{T}\\left(p_i-\\bar{p}\\right)}}{\\partial{p_{j}}}\\\\ =\\frac{2}{N}\\cdot\\left({\\frac{\\partial {u_{k}}}{\\partial{p_j}}u_{k}^{T}\\left(p_i-\\bar{p}\\right)}+u_{k}\\frac{\\partial{u_{k}^{T}\\left(p_i-\\bar{p}\\right)}}{p_j}\\right)\\\\ =\\frac{2}{N}\\cdot\\left(\\frac{\\partial {u_{k}}}{\\partial{p_j}}u_{k}^{T}\\left(p_i-\\bar{p}\\right) +u_{k}u_{k}^{T}\\frac{\\partial{\\left(p_i-\\bar{p}\\right)}}{p_j} +u_{k}\\left(p_i-\\bar{p}\\right)^{T}\\frac{\\partial{u_k}}{p_j}\\right)\\\\ =\\frac{2}{N}\\cdot\\left(UF_{k}^{p_j}u_{k}^{T}\\left(p_i-\\bar{p}\\right) +u_{k}u_{k}^{T}\\frac{\\partial{\\left(p_i-\\bar{p}\\right)}}{p_j} +u_{k}\\left(p_i-\\bar{p}\\right)^{T}UF_{k}^{p_j} \\right)\\\\ =\\begin{cases} \\frac{2}{N}\\cdot\\left(UF_{k}^{p_j}u_{k}^{T}\\left(p_i-\\bar{p}\\right) +u_{k}u_{k}^{T}\\frac{N-1}{N}I +u_{k}\\left(p_i-\\bar{p}\\right)^{T}UF_{k}^{p_j} \\right),\\quad i=j \\\\ \\frac{2}{N}\\cdot\\left(UF_{k}^{p_j}u_{k}^{T}\\left(p_i-\\bar{p}\\right) +u_{k}u_{k}^{T}\\frac{-1}{N}I +u_{k}\\left(p_i-\\bar{p}\\right)^{T}UF_{k}^{p_j} \\right),\\quad i \\ne j \\end{cases} \\end{align*} \\tag{式16} $$ 其中同样涉及到式13。\n推导过程 $$\\arg\\min_{\\mathcal{S},\\mathcal{E}_{L}}\\sum_{l}^{}\\lambda_{3}(A_{l})\\tag{式1}$$$$ ^{G}p=\\begin{bmatrix}{^{G}p_{1}^{T}} \\quad {^{G}p_{2}^{T}} \\quad \\cdots \\quad {^{G}p_{N_{l}}^{T}} \\end{bmatrix}\\in\\mathbb{R} ^{3N_{l}} \\tag{式2} $$$$ \\lambda_{3}\\left(^{G}{p}+\\delta^{G}{p}\\right)\\approx\\lambda_{3}\\left(^{G}{p}\\right)+{J}\\cdot\\delta^{G}{p}+\\frac{1}{2} \\delta^{G}{p}^{T}\\cdot{H}\\cdot\\delta^{G}{p} \\tag{式3} $$$$ \\begin{align*} ^Gp_k={^{G}_{L_i}T}_{t_j}p_k={^{G}_{L_0}T}_{t_j}\\cdot {^{L_{0}}_{L_i}T}\\cdot p_{k}\\\\ ={^{G}_{L_0}R_{t_j}}\\left({^{L_0}_{L_i}R\\cdot {p_k}+{^{L_0}_{L_i}t}}\\right)+{^G_{L_0}t_{t_j}} \\end{align*} \\tag{式4} $$$$ T=(R,t)\\quad ,T \\boxplus\\delta{T}=\\left(R\\exp(\\phi^{\\wedge} ),t+\\delta{t}\\right) \\tag{式5} $$$$ \\begin{align*} {}^{G}{p}_{k}+\\delta^{G}{p}_{k}= {}_{L_{0}}^{G}R_{t_{j}}\\exp\\big({}_{L_{0}}^{G}\\phi_{t_{j}}^{\\wedge}\\big) \\bigg({}_{L_{i}}^{L_{0}}R\\exp\\big({}_{L_{i}}^{L_{0}}\\phi^{\\wedge}\\big)p_{k} +{}_{L_{i}}^{L_{0}}{t}+\\delta_{L_{i}}^{L_{0}}{t}\\bigg)\\\\ +{}_{L_{0}}^{G}{t}_{t_{j}} +\\delta_{L_{0}}^{G}{t}_{t_{j}}\\\\ ={}_{L_{0}}^{G}R_{t_{j}}\\big(I+{}_{L_{0}}^{G}\\phi_{t_{j}}^{\\wedge}\\big) \\bigg({}_{L_{i}}^{L_{0}}R\\big(I+{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}\\big)p_{k} +{}_{L_{i}}^{L_{0}}{t}+\\delta_{L_{i}}^{L_{0}}{t}\\bigg)\\\\ +{}_{L_{0}}^{G}{t}_{t_{j}}+\\delta_{L_{0}}^{G}{t}_{t_{j}}\\\\ ={}_{L_{0}}^{G}{R}_{t_{j}}\\big(I+{}_{L_{0}}^{G}\\phi_{t_{j}}^{\\wedge}\\big) \\bigg({}_{L_{i}}^{L_{0}}Rp_{k}+{}_{L_{i}}^{L_{0}}R{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}p_{k} +{}_{L_{i}}^{L_{0}}{t}+\\delta_{L_{i}}^{L_{0}}{t}\\bigg)\\\\ +{}_{L_{0}}^{G}{t}_{t_{j}}+\\delta_{L_{0}}^{G}{t}_{t_{j}}\\\\ \\approx{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R\\cdot{p_{k}}+{}_{L_{0}}^{G}{t}_{t_{j}}\\big) +{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}p_{k} +\\delta_{L_{i}}^{L_{0}}{t}\\big)\\\\ +{}_{L_{0}}^{G}R_{t_{j}}{}_{L_{0}}^{G}\\phi_{t_{j}}^{\\wedge} \\bigg({}_{L_{i}}^{L_{0}}Rp_{k}+{}_{L_{i}}^{L_{0}}{t}\\bigg)\\\\ +{}_{L_{0}}^{G}{t}_{t_{j}}+\\delta_{L_{0}}^{G}{t}_{t_{j}}\\\\ \\approx{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R\\cdot{p_{k}} +{}_{L_{0}}^{G}{t}_{t_{j}}\\big)+{}_{L_{0}}^{G}{t}_{t_{j}} +{}_{L_{0}}^{G}R_{t_{j}}\\big(I\\cdot{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}p_{k} +\\delta_{L_{i}}^{L_{0}}{t}\\big)\\\\ +{}_{L_{0}}^{G}R_{t_{j}}{}_{L_{0}}^{G}\\phi_{t_{j}}^{\\wedge} \\bigg({}_{L_{i}}^{L_{0}}Rp_{k} +{}_{L_{i}}^{L_{0}}{t}\\bigg)+\\delta_{L_{0}}^{G}{t}_{t_{j}}\\\\ \\approx{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R\\cdot{p_{k}} +{}_{L_{0}}^{G}{t}_{t_{j}}\\big)+{}_{L_{0}}^{G}{t}_{t_{j}}\\\\ -{}_{L_0}^GR_{t_j}\\left(p_k\\right)^{\\wedge}\\cdot_{L_i}^{L_0}\\phi+_{L_0}^GR_{t_j}\\delta_{L_i}^{L_0}t -{}_{L_{0}}^{G}R_{t_{j}}\\bigg({}_{L_{i}}^{L_{0}}Rp_{k} +{}_{L_{i}}^{L_{0}}{t}\\bigg)^{\\wedge}{}_{L_{0}}^{G}\\phi_{t_{j}}+\\delta_{L_{0}}^{G}{t}_{t_{j}} \\end{align*} \\tag{式6} $$$$ \\begin{align*} \\delta^{G}{p}_{k}\\approx-{}_{L_{0}}^{G}R_{t_{j}} \\big({}_{L_{i}}^{L_{0}}{R}{p}_{k}+{}_{L_{i}}^{L_{0}}{t}\\big)^{\\wedge}{}_{L_{0}}^{G}\\phi_{t_{j}} +\\delta_{L_{0}}^{G}{t}_{t_{j}}-\\\\{}_{L_{0}}^{G}R_{t_{j}}\\big({p}_{k}\\big)^{\\wedge}{}_{L_{i}}^{L_{0}}\\phi +{}_{L_{0}}^{G}{R}_{t_{j}}\\delta_{L_{i}}^{L_{0}}{t}\\\\ =D\\cdot \\delta x , \\end{align*} \\tag{式7} $$ 其中$\\delta{x}=\\begin{bmatrix}\\cdots \\quad {^G_{L_0}\\phi_{t_j}^{T}\\quad\\delta_{L_0}^{G}t_{t_j}^T}\\cdots{^{L_{0}}_{L_i}\\phi^{T}\\quad\\delta_{L_i}^{L_0}t^T} \\cdots\\end{bmatrix}^{T} \\ne\\mathbb{R}^{6\\left(m+n-2\\right)}$是优化变量$x=\\begin{bmatrix}\\cdots{_{L_0}^GR_{t_j} }\\quad{_{L_0}^{G}t_{t_j}}\\cdots{_{L_0}^{L_i}R}\\quad{_{L_0}^{L_i}t}\\cdots\\end{bmatrix}$的微小扰动。\n$$\\begin{align*} D =\\begin{bmatrix}\\vdots\u0026\\vdots\\\\\\cdots {D}_{k,p}^{\\mathcal{S}}\u0026\\cdots {D}_{k,q}^{\\varepsilon_{L}}\u0026\\cdots\\\\\\vdots\u0026\\vdots\\end{bmatrix}\\in\\mathbb{R}^{3N_{l}\\times6(m+n-2)} \\\\ \\mathrm{D}_{k,p}^{\\mathcal{S}} \\begin{cases} \\begin{bmatrix}{-{}_{L_{0}}^{G}{R}_{t_{j}}}\\left({}_{L_{i}}^{L_{0}}{R}{p}_{k}+{}_{L_{i}}^{L_{0}}{t}\\right)^{\\wedge}\u0026{I}\\end{bmatrix},\\quad{\\mathrm{if} p=j}\\\\ {0}_{3\\times6},\\quad {else} \\end{cases}\\\\ \\mathrm{D}_{k,q}^{\\mathcal{E}_{L}} \\begin{cases} \\begin{bmatrix}{-{}_{L_{0}}^{G}{R}_{t_{j}}}{}_{L_{i}}^{L_{0}}{R}({p}_{k})^{\\wedge}\u0026{}_{L_{0}}^{G}{R}_{t_{j}}\\end{bmatrix},\\quad{\\mathrm{if~}q=i}\\\\ {0}_{3\\times6},\\quad {else} \\end{cases} \\end{align*} $$$$\\delta^{G}{p}_{k}\\approx{\\color{red}+}{}_{L_{0}}^{G}R_{t_{j}} \\big({}_{L_{i}}^{L_{0}}{R}{p}_{k}+{}_{L_{i}}^{L_{0}}{t}\\big)^{\\wedge}{}_{L_{0}}^{G}\\phi_{t_{j}} +\\delta_{L_{0}}^{G}{t}_{t_{j}}{\\color{red}+}\\\\{}_{L_{\\color{red}i}}^{G}R_{t_{j}}\\big({p}_{k}\\big)^{\\wedge}{}_{L_{i}}^{L_{0}}\\phi +{}_{L_{0}}^{G}{R}_{t_{j}}\\delta_{L_{i}}^{L_{0}}{t}$$$$ \\exp(\\phi^{\\wedge})\\approx I+\\phi^{\\wedge}\\tag{式8} $$$$ \\begin{align*} \\begin{gathered} \\lambda_{3}({x}\\boxplus\\delta{x}) \\approx\\lambda_{3}({x})+{JD}\\delta{x}+\\frac{1}{2} \\delta{x}^{T}{D}^{T}{HD}\\delta{x} \\\\ =\\lambda_{3}({x})+{\\bar{J}}\\delta{x}+\\frac{1}{2}\\delta{x}^{T}{\\bar{H}}\\delta{x}. \\end{gathered} \\end{align*} \\tag{式9} $$ 根据定理1和定理2的结论可知：\n$J$为雅可比矩阵，其中第$i$个元素按照定理1计算； $H$为Hessian矩阵，其中第$i$行，第$j$列元素按照定理2计算。 并可得且LM算法的增量公式为$\\left(\\bar{H}(^{G}p+\\mu I)\\right)\\delta{^Gp^{\\ast}}=-\\bar{J}(^Gp)^T$。\n代码详解 工程实现并非直接按照上文的推算一步完成，而是拆分为三阶段完成,分别为优化主激光雷达位姿、优化每个副雷达到主雷达的外参以及联合优化所有雷达外参以及主雷达里程计。\n一阶段：优化主雷达位姿 第一阶段中先优化主雷达里程计。优化之前的初值可以靠纯激光里程计，或者借助其他传感器（如IMU和轮速）的方式获取，使用这个里程计堆叠主雷达的局部地图，并通过自适应提速化的方式提取面特征，通过八叉树递归的方式计算每一个体素的点面误差，构建局部地图的一致性评价指标；\n整理体素数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 /** * @brief 将体素推入某个结构（如容器）中 * 该函数主要用于处理一组三维点云数据，通过体素化处理后，提取有用信息 * @param origin_pc 原始点云数据的二维向量，每个元素是一个指向三维向量的指针 */ void push_voxel(std::vector\u0026lt;vector_vec3d *\u0026gt; \u0026amp;origin_pc) { uint points_size = 0; for (int i = 0; i \u0026lt; window_size; i++) if (!origin_pc[i]-\u0026gt;empty()) points_size++; if (points_size \u0026lt;= 1) return; // 定义变量以指定使用的过滤器数量 int filternum2use = 4; vector_vec3d *origin_point = new vector_vec3d(); std::vector\u0026lt;int\u0026gt; *window_num = new std::vector\u0026lt;int\u0026gt;(); // 预分配内存以提高性能 window_num-\u0026gt;reserve(filternum2use * window_size); origin_point-\u0026gt;reserve(filternum2use * window_size); // 遍历所有窗口，对非空点云计算中心点，并存储相关信息 for (int i = 0; i \u0026lt; window_size; i++) if (!origin_pc[i]-\u0026gt;empty()) get_center(*origin_pc[i], i, *origin_point, *window_num, filternum2use); origin_points.emplace_back(origin_point); window_nums.emplace_back(window_num); } /** * @brief 计算点云的中心点并添加到结果中 * * @param origin_pc 原始点云数据，每个点是一个三维向量 * @param cur_frame 当前帧数，用于标记窗口编号 * @param origin_point 存储计算得到的中心点，每个点是一个三维向量 * @param window_num 存储每个中心点对应的窗口编号 * @param filternum2use 用于计算中心点的点云数量 */ void get_center(vector_vec3d \u0026amp;origin_pc, int cur_frame, vector_vec3d \u0026amp;origin_point, std::vector\u0026lt;int\u0026gt; \u0026amp;window_num, int filternum2use) { size_t pt_size = origin_pc.size(); if (pt_size \u0026lt;= (size_t) filternum2use) { for (size_t i = 0; i \u0026lt; pt_size; i++) { origin_point.emplace_back(origin_pc[i]); window_num.emplace_back(cur_frame); } return; } Eigen::Vector3d center; double part = 1.0 * pt_size / filternum2use; // 遍历每个过滤点数区间计算中心点 for (int i = 0; i \u0026lt; filternum2use; i++) { // 计算当前区间的起始和结束位置 size_t np = part * i; size_t nn = part * (i + 1); center.setZero(); // 在当前区间内累加点坐标 for (size_t j = np; j \u0026lt; nn; j++) center += origin_pc[j]; // 计算当前区间的中心点 center = center / (nn - np); // 将中心点添加到结果中 origin_point.emplace_back(center); // 标记当前中心点的窗口编号 window_num.emplace_back(cur_frame); } } 计算雅可比矩阵和海森矩阵 由于仅优化轨迹，$D=\\frac{\\delta p}{\\delta T}$不同于2.2.4章节的公式7。具体如下 $$ D=\\begin{bmatrix} -{}^{G}_{L_0}R_{t_j}(p_k)^{\\wedge}\u0026I \\end{bmatrix}\\tag{式1} $$ 由于$\\frac{\\delta \\lambda}{\\delta p}$不变，所以$H$和$J$没有变换将其带入2.2.3章节的式9即可推导出$\\bar{J}$和$\\bar{H}$。 其中关于Hessian矩阵块的更新，以点$P(k,j)$为例推导如下其对$\\bar{H}_{00}$的更新如下： $$ \\begin{align*} \\bar{H}_{0,0}=D_{0,k}^{T}H_{k,j}D_{j,0}\\\\ =\\begin{bmatrix}-{}^{G}_{L_0}R_{t_j}(p_k)^{\\wedge}\u0026I\\end{bmatrix}^{T}H_{k,j}\\begin{bmatrix}-{}^{G}_{L_0}R_{t_j}(p_j)^{\\wedge}\u0026I\\end{bmatrix}\\\\ =\\begin{bmatrix} {}^{G}_{L_0}R_{t_j}(p_k)^{\\wedge} \\\\I\\end{bmatrix}H_{k,j}\\begin{bmatrix}-{}^{G}_{L_0}R_{t_j}(p_j)^{\\wedge}\u0026I\\end{bmatrix}\\\\ =\\begin{bmatrix} {}^{G}_{L_0}R_{t_j}(p_k)^{\\wedge}H_{k,j}\\\\H_{k,j}\\end{bmatrix}\\begin{bmatrix}-{}^{G}_{L_0}R_{t_j}(p_j)^{\\wedge}\u0026I\\end{bmatrix}\\\\ =\\begin{bmatrix} -{}^{G}_{L_0}R_{t_j}(p_k)^{\\wedge}H_{k,j}{}^{G}_{L_0}R_{t_j}(p_j)^{\\wedge}\u0026{}^{G}_{L_0}R_{t_j}(p_k)^{\\wedge}H_{k,j}\\\\ -H_{k,j} {}^{G}_{L_0}R_{t_j}(p_j)^{\\wedge}\u0026 H_{k,j} \\end{bmatrix} \\end{align*}\\tag{式2} $$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 /** * 计算Hessian矩阵、转置的Jacobian矩阵和残差 * * 该函数是优化算法的一部分，用于计算给定姿势、平移和初始Hessian矩阵、 * Jacobian向量以及残差的更新值。它是基于输入数据执行迭代计算的关键步骤。 * * @param poses 姿态向量，表示每个窗口的旋转 * @param ts 平移向量，表示每个窗口的平移 * @param Hess Hessian矩阵，用于二阶优化方法 * @param JacT 转置的Jacobian矩阵，优化过程中的线性逼近 * @param residual 残差，衡量当前优化状态的误差 */ void calculate_HJ(vector_quad \u0026amp;poses, vector_vec3d \u0026amp;ts, Eigen::MatrixXd \u0026amp;Hess, Eigen::VectorXd \u0026amp;JacT, double \u0026amp;residual) { // 初始化Hessian矩阵、转置的Jacobian矩阵和残差 Hess.setZero(); JacT.setZero(); residual = 0; // 创建本地副本以避免重复计算 Eigen::MatrixXd _hess(Hess); Eigen::MatrixXd _jact(JacT); // 获取体素的数量 size_t voxel_size = origin_points.size(); // 遍历每个体素 for (size_t i = 0; i \u0026lt; voxel_size; i++) { // 获取当前体素的原始点和窗口数量 vector_vec3d \u0026amp;origin_pts = *origin_points[i]; std::vector\u0026lt;int\u0026gt; \u0026amp;win_num = *window_nums[i]; size_t pts_size = origin_pts.size(); // 初始化变量 Eigen::Vector3d vec_tran; vector_vec3d pt_trans(pts_size); std::vector\u0026lt;Eigen::Matrix3d\u0026gt; point_xis(pts_size); Eigen::Vector3d centor(Eigen::Vector3d::Zero()); Eigen::Matrix3d covMat(Eigen::Matrix3d::Zero()); // 遍历当前体素的所有点 for (size_t j = 0; j \u0026lt; pts_size; j++) { // 计算变换后的向量 vec_tran = poses[win_num[j]] * origin_pts[j]; // 计算并存储点的变换和反对称矩阵 point_xis[j] = -wedge(vec_tran); pt_trans[j] = vec_tran + ts[win_num[j]]; // 更新中心点和协方差矩阵 centor += pt_trans[j]; covMat += pt_trans[j] * pt_trans[j].transpose(); } // 计算协方差矩阵的平均值 double N = pts_size; covMat = (covMat - centor * centor.transpose() / N) / N; centor = centor / N; // 计算协方差矩阵的特征值和特征向量 Eigen::SelfAdjointEigenSolver\u0026lt;Eigen::Matrix3d\u0026gt; saes(covMat); Eigen::Vector3d eigen_value = saes.eigenvalues(); Eigen::Matrix3d U = saes.eigenvectors(); Eigen::Vector3d u[3]; for (int j = 0; j \u0026lt; 3; j++) u[j] = U.block\u0026lt;3, 1\u0026gt;(0, j); // 更新Jacobian矩阵 //损失函数降维之后优化的目标函数转为$\\arg min_{\\mathcal{S}，\\mathcal{E}_L}\\sum_{l}\\lambda_{3}{(A_l)}$ //其中$\\lambda_3$是矩阵A的最小特征值，u0即为最小特征值 Eigen::Matrix3d ukukT = u[0] * u[0].transpose(); Eigen::Vector3d vec_Jt; for (size_t j = 0; j \u0026lt; pts_size; j++) {//雅可比矩阵J和D的乘积的转置，见推导过程章节的式9 pt_trans[j] = pt_trans[j] - centor; vec_Jt = 2.0 / N * ukukT * pt_trans[j]; _jact.block\u0026lt;3, 1\u0026gt;(6 * win_num[j], 0) -= point_xis[j] * vec_Jt; _jact.block\u0026lt;3, 1\u0026gt;(6 * win_num[j] + 3, 0) += vec_Jt; } // 计算Hessian矩阵的辅助变量 Eigen::Matrix3d Hessian33; Eigen::Matrix3d F; std::vector\u0026lt;Eigen::Matrix3d\u0026gt; F_(3); for (size_t j = 0; j \u0026lt; 3; j++) { if (j == 0) {//定理2：公式10 $F_{m,n}^{p_j}$ n=0,m=0的情况 F_[j].setZero(); continue; } Hessian33 = u[j] * u[0].transpose(); //定理2：公式10 $F_{m,n}^{p_j}$ n=0,m!=0的情况 //注意此辅助函数缺乏$(p_i-\\bar{p})^T$，下面的公式会有补充 F_[j] = 1.0 / N / (eigen_value[0] - eigen_value[j]) * (Hessian33 + Hessian33.transpose()); } // 更新Hessian矩阵 Eigen::Matrix3d h33; size_t rownum, colnum; for (size_t j = 0; j \u0026lt; pts_size; j++) { for (int f = 0; f \u0026lt; 3; f++) //此时是完整的辅助变量F F.block\u0026lt;1, 3\u0026gt;(f, 0) = pt_trans[j].transpose() * F_[f]; F = U * F; //按照定义D的子项为3行6列，位置为k行j列。 colnum = 6 * win_num[j]; for (size_t k = 0; k \u0026lt; pts_size; k++) { //注意$u_{k}^{T}\\cdot{\\left(p_i-\\bar{p}\\right)}$是一个标量，所以可以挪到F前面，与文中公式16推导略有差异 Hessian33 = u[0] * (pt_trans[k]).transpose() * F + u[0].dot(pt_trans[k]) * F; rownum = 6 * win_num[k]; if (k == j) Hessian33 += (N - 1) / N * ukukT; else Hessian33 -= 1.0 / N * ukukT; Hessian33 = 2.0 / N * Hessian33; //到此完整的公式16，下文为$D^{T}HD$，是$\\bar{H}$，见3.1章节的公式2 //[-R(p_k)^{wedge} I]^{T} H_33 [-R(p_j)^{wedge} I] //= [(-R(p_k)^{wedge})^{T} H_33 [-R(p_j)^{wedge} I] // I^{T] //=[R(p_k)^{wedge}H_33 [-R(p_j)^{wedge} I] // I] //=[R(p_k)^{wedge}H_33 [-R(p_j)^{wedge} I] // H_33] //= [-R(p_k)^{wedge} H_33 R(p_j)^{wedge} R(p_k)^{wedge}H_33 // -H_33R(p_j)^{wedge} _hess.block\u0026lt;3, 3\u0026gt;(rownum + 3, colnum + 3) += Hessian33; h33 = Hessian33 * point_xis[j]; _hess.block\u0026lt;3, 3\u0026gt;(rownum + 3, colnum) += h33; _hess.block\u0026lt;3, 3\u0026gt;(rownum, colnum + 3) -= point_xis[k] * Hessian33; _hess.block\u0026lt;3, 3\u0026gt;(rownum, colnum) -= point_xis[k] * h33; } } // 更新残差 residual += eigen_value[0]; Hess += _hess; JacT += _jact; _hess.setZero(); _jact.setZero(); } } 二阶段：优化副雷达到主雷达的外参 将一阶段中优化出的主雷达里程计作为真值，对于每一个副雷达，使用主雷达里程计以及各副雷达到主雷达的外参将各个副雷达的点云投影回世界坐标系构成局部地图，并和一阶段中的地图叠在一起构成新的局部地图。和一阶段相同，对使用自适应体素化方法提取面特征，并对于每一个特征体素递归构建基于点面误差的一致性评价指标。\n$$ \\begin{align*} {}^{G}{p}_{k}+\\delta^{G}{p}_{k}= {}_{L_{0}}^{G}R_{t_{j}} \\bigg({}_{L_{i}}^{L_{0}}R\\exp\\big({}_{L_{i}}^{L_{0}}\\phi^{\\wedge}\\big)p_{k} +{}_{L_{i}}^{L_{0}}{t}+\\delta_{L_{i}}^{L_{0}}{t}\\bigg) +{}_{L_{0}}^{G}{t}_{t_{j}}\\\\ \\approx{}{}_{L_{0}}^{G}R_{t_{j}} \\bigg({}_{L_{i}}^{L_{0}}R\\big(I+{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}\\big)p_{k} +{}_{L_{i}}^{L_{0}}{t}+\\delta_{L_{i}}^{L_{0}}{t}\\bigg) +{}_{L_{0}}^{G}{t}_{t_{j}}\\\\ \\approx{}{}_{L_{0}}^{G}{R}_{t_{j}} \\bigg({}_{L_{i}}^{L_{0}}Rp_{k}+{}_{L_{i}}^{L_{0}}R{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}p_{k} +{}_{L_{i}}^{L_{0}}{t}+\\delta_{L_{i}}^{L_{0}}{t}\\bigg) +{}_{L_{0}}^{G}{t}_{t_{j}}\\\\ \\approx{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R\\cdot{p_{k}}+{}_{L_{0}}^{G}{t}_{t_{j}}\\big) +{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}p_{k} +\\delta_{L_{i}}^{L_{0}}{t}\\big) +{}_{L_{0}}^{G}{t}_{t_{j}}\\\\ \\approx{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R\\cdot{p_{k}}+{}_{L_{0}}^{G}{t}_{t_{j}}\\big) +{}_{L_{0}}^{G}{t}_{t_{j}} +{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R{}_{L_{i}}^{L_{0}}\\phi^{\\wedge}p_{k} +\\delta_{L_{i}}^{L_{0}}{t}\\big)\\\\ \\approx{}_{L_{0}}^{G}R_{t_{j}}\\big({}_{L_{i}}^{L_{0}}R\\cdot{p_{k}}+{}_{L_{0}}^{G}{t}_{t_{j}}\\big) +{}_{L_{0}}^{G}{t}_{t_{j}} +{}_{L_{0}}^{G}R_{t_{j}}\\big(-{}_{L_{i}}^{L_{0}}R{p_k}^{\\wedge}{}_{L_{i}}^{L_{0}}\\phi +\\delta_{L_{i}}^{L_{0}}{t}\\big) \\end{align*} \\tag{式1} $$$$ \\delta^{G}{p}_{k}={}_{L_{0}}^{G}R_{t_{j}}\\big((-{}_{L_{i}}^{L_{0}}R{p_k})^{\\wedge}{}_{L_{i}}^{L_{0}}\\phi +\\delta_{L_{i}}^{L_{0}}{t}\\big)\\tag{式2} $$$$ D=\\frac{\\delta p}{\\delta T}=\\begin{bmatrix} -{}_{L_{0}}^{G}R_{t_{j}}({}_{L_{i}}^{L_{0}}R{p_k})^{\\wedge}\u0026 {}_{L_{0}}^{G}R_{t_{j}} \\end{bmatrix} $$$$ \\begin{align*} \\bar{H}_{0,0}=D_{0,k}^{T}H_{k,j}D_{j,0}\\\\ =\\begin{bmatrix}-{}_{L_{0}}^{G}R_{t_{j}}({}_{L_{i}}^{L_{0}}R{p_k})^{\\wedge}\u0026{}_{L_{0}}^{G}R_{t_{j}}\\end{bmatrix}^{T} H_{k,j} \\begin{bmatrix}-{}_{L_{0}}^{G}R_{t_{j}}({}_{L_{i}}^{L_{0}}R{p_j})^{\\wedge}\u0026{}_{L_{0}}^{G}R_{t_{j}}\\end{bmatrix}\\\\ =\\begin{bmatrix} ({}_{L_{i}}^{L_{0}}R{p_k})^{\\wedge}{}_{L_{0}}^{G}R_{t_{j}}^{T} \\\\{{}_{L_{0}}^{G}R_{t_{j}}}^{T}\\end{bmatrix} H_{k,j} \\begin{bmatrix}-{}_{L_{0}}^{G}R_{t_{j}}({}_{L_{i}}^{L_{0}}R{p_j})^{\\wedge}\u0026{}_{L_{0}}^{G}R_{t_{j}}\\end{bmatrix}\\\\ =\\begin{bmatrix} ({}_{L_{i}}^{L_{0}}R{p_k})^{\\wedge}{}_{L_{0}}^{G}R_{t_{j}}^{T}H_{k,j}\\\\{{}_{L_{0}}^{G}R_{t_{j}}}^{T}H_{k,j}\\end{bmatrix} \\begin{bmatrix}-{}_{L_{0}}^{G}R_{t_{j}}({}_{L_{i}}^{L_{0}}R{p_j})^{\\wedge}\u0026{}_{L_{0}}^{G}R_{t_{j}}\\end{bmatrix}\\\\ =\\begin{bmatrix} -({}_{L_{i}}^{L_{0}}R{p_k})^{\\wedge}{}_{L_{0}}^{G}R_{t_{j}}^{T}H_{k,j}{}_{L_{0}}^{G}R_{t_{j}}({}_{L_{i}}^{L_{0}}R{p_j})^{\\wedge}\u0026({}_{L_{i}}^{L_{0}}R{p_k})^{\\wedge}{}_{L_{0}}^{G}R_{t_{j}}^{T}H_{k,j}{}_{L_{0}}^{G}R_{t_{j}}\\\\ -{{}_{L_{0}}^{G}R_{t_{j}}}^{T}H_{k,j}{}_{L_{0}}^{G}R_{t_{j}}({}_{L_{i}}^{L_{0}}R{p_j})^{\\wedge} \u0026 {{}_{L_{0}}^{G}R_{t_{j}}}^{T}H_{k,j}{}_{L_{0}}^{G}R_{t_{j}} \\end{bmatrix} \\end{align*}\\tag{式3} $$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //节选自第二阶段的calculate_HJ函数 //公式推导见公式3 _hess.block\u0026lt;3, 3\u0026gt;(rownum + 3, colnum + 3) += poses[refwin_num[k]].toRotationMatrix().transpose() * Hessian33 * poses[refwin_num[j]].toRotationMatrix(); _hess.block\u0026lt;3, 3\u0026gt;(rownum + 3, colnum) += poses[refwin_num[k]].toRotationMatrix().transpose() * Hessian33 * poses[refwin_num[j]].toRotationMatrix() * point_xis[j]; _hess.block\u0026lt;3, 3\u0026gt;(rownum, colnum + 3) -= point_xis[k] * poses[refwin_num[k]].toRotationMatrix().transpose() * Hessian33 * poses[refwin_num[j]].toRotationMatrix(); _hess.block\u0026lt;3, 3\u0026gt;(rownum, colnum) -= point_xis[k] * poses[refwin_num[k]].toRotationMatrix().transpose() * Hessian33 * poses[refwin_num[j]].toRotationMatrix() * point_xis[j]; 三阶段：联合优化雷达外参和主激光雷达里程计 使用主雷达里程计以及各副雷达到主雷达的外参将各个副雷达的点云投影回世界坐标系构成局部地图，将所有雷达的局部地图堆叠在一起构成新的局部地图。同样的，对于这个局部地图构建基于点面误差的损失函数。\n$$ \\begin{align*} \\bar{J}^{T}=(JD)^{T}=D^{T}J^{J} \\end{align*}\\tag{式1} $$ 考虑两种情况：分辨为$p=j$和$q=i$。\n$$ \\begin{align*} \\bar{J}^{T}=(JD)^{T}=D^{T}J^{J}\\\\ =[-{}_{L_0}^{G}R_{t_j}({}_{L_i}^{L_0}Rp_k+{}_{L_i}^{L_0}t)^{\\wedge}\\quad I]^{T}\\cdot J^{T}\\\\ =[-({}_{L_0}^{G}R_{t_j}({}_{L_i}^{L_0}Rp_k+{}_{L_i}^{L_0}t))^{\\wedge}\\quad I]^{T}\\cdot J^{T}\\\\ =\\begin{bmatrix} ({}_{L_0}^{G}R_{t_j}({}_{L_i}^{L_0}Rp_k+{}_{L_i}^{L_0}t))^{\\wedge}\\\\ I^{T} \\end{bmatrix}\\cdot{J}^{T} \\end{align*}\\tag{式2} $$$$ \\begin{align*} \\bar{J}^{T}=(JD)^{T}=D^{T}J^{J}\\\\ =[-{}_{L_0}^{G}R_{t_j}{}_{L_i}^{L_0}R(p_k)^{\\wedge}\\quad {}_{L_0}^{G}R_{t_j}]^{T}\\cdot J^{T}\\\\ =\\begin{bmatrix} ({}_{L_i}^{L_0}Rp_k)^{\\wedge}{{}_{L_0}^{G}R_{t_j}}^{T}\\\\ {}_{L_0}^{G}R_{t_j}^{T} \\end{bmatrix}\\cdot{J}^{T} \\end{align*}\\tag{式3} $$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 //以下代码选自第三阶段的计算雅可比和海森矩阵的代码 /** * @brief 计算雅可比矩阵和海森矩阵并进行更新，推导过程见2.2.3章节 * @param poses 基准雷达的轨迹的旋转变量 * @param ts 基准雷达的轨迹的平移变量 * @param refQs 参考雷达的轨迹的旋转变量 * @param refTs 参考雷达的轨迹的旋转变量 * @param head 起始帧（所有体素被拆分为多份，多线程计算） * @param end 结束帧 * @param Hess Hessian矩阵 * @param JacT Jacobian矩阵 * @param residual 残差 */ void calculate_HJ(vector_quad \u0026amp;poses, vector_vec3d \u0026amp;ts, vector_quad \u0026amp;refQs, vector_vec3d \u0026amp;refTs, int head, int end, Eigen::MatrixXd \u0026amp;Hess, Eigen::VectorXd \u0026amp;JacT, double \u0026amp;residual) { Hess.setZero(); JacT.setZero(); residual = 0; Eigen::MatrixXd _jact(JacT); for (int i = head; i \u0026lt; end; i++) { vector_vec3d \u0026amp;baseorigin_pts = *baseOriginPts[i]; std::vector\u0026lt;int\u0026gt; \u0026amp;basewin_num = *baseWinNums[i]; size_t basepts_size = baseorigin_pts.size(); size_t refpts_size_all = 0; std::vector\u0026lt;int\u0026gt; refpts_size, refpts_size_part; refpts_size.reserve(ref_size); refpts_size_part.reserve(ref_size + 1); refpts_size_part.emplace_back(0); //计算所有点的个数 for (int j = 0; j \u0026lt; ref_size; j++) {//ref_size代表参考雷达的个数 vector_vec3d \u0026amp;reforigin_pts = *refOriginPts[j][i]; refpts_size.emplace_back(reforigin_pts.size()); refpts_size_all += reforigin_pts.size(); int temp = 0; for (int k = 0; k \u0026lt;= j; k++) temp += refOriginPts[k][i]-\u0026gt;size(); refpts_size_part.emplace_back(temp); } //计参考雷达+基准雷达点的个数 double N = refpts_size_all + basepts_size; int _N = (int) N; //定义$D$和$H$ Eigen::MatrixXd _H(3 * _N, 3 * _N); _H.setZero(); Eigen::MatrixXd _D(3 * _N, jacob_len); _D.setZero(); Eigen::Vector3d vec_tran; vector_vec3d pt_trans(basepts_size + refpts_size_all); std::vector\u0026lt;Eigen::Matrix3d\u0026gt; point_xis(basepts_size + refpts_size_all); std::vector\u0026lt;Eigen::Matrix3d\u0026gt; point_xic(basepts_size + refpts_size_all); Eigen::Vector3d center(Eigen::Vector3d::Zero()); Eigen::Matrix3d covMat(Eigen::Matrix3d::Zero()); //计算基准雷达的协方差矩阵 for (size_t j = 0; j \u0026lt; basepts_size; j++) { vec_tran = poses[basewin_num[j]] * baseorigin_pts[j]; point_xis[j] = -wedge(vec_tran); pt_trans[j] = vec_tran + ts[basewin_num[j]]; //基准雷达点云转化到世界坐标系下的坐标 center += pt_trans[j]; covMat += pt_trans[j] * pt_trans[j].transpose(); } //计算参考雷达的协方差矩阵 size_t cnt = 0; for (int k = 0; k \u0026lt; ref_size; k++) { vector_vec3d \u0026amp;reforigin_pts = *refOriginPts[k][i]; std::vector\u0026lt;int\u0026gt; \u0026amp;refwin_num = *refWinNums[k][i]; for (size_t j = 0; j \u0026lt; reforigin_pts.size(); j++) { vec_tran = poses[refwin_num[j]] * (refQs[k] * reforigin_pts[j] + refTs[k]); point_xis[cnt + basepts_size] = -wedge(vec_tran); pt_trans[cnt + basepts_size] = vec_tran + ts[refwin_num[j]]; //参考雷达的点云转化到世界坐标系下的坐标 center += pt_trans[cnt + basepts_size]; covMat += pt_trans[cnt + basepts_size] * pt_trans[cnt + basepts_size].transpose(); cnt++; } } // 初始化计数器和点的变换 cnt = 0; for (size_t j = 0; j \u0026lt; basepts_size; j++) point_xic[j] = Eigen::MatrixXd::Zero(3, 3); for (int k = 0; k \u0026lt; ref_size; k++) { vector_vec3d \u0026amp;reforigin_pts = *refOriginPts[k][i]; for (size_t j = 0; j \u0026lt; reforigin_pts.size(); j++) { vec_tran = refQs[k] * reforigin_pts[j]; point_xic[cnt + basepts_size] = -wedge(vec_tran); cnt++; } } // 计算协方差矩阵和中心点 covMat = covMat - center * center.transpose() / N; covMat = covMat / N; center = center / N; // 计算协方差矩阵的特征值和特征向量 Eigen::SelfAdjointEigenSolver\u0026lt;Eigen::Matrix3d\u0026gt; saes(covMat); Eigen::Vector3d eigen_value = saes.eigenvalues(); Eigen::Matrix3d U = saes.eigenvectors(); Eigen::Vector3d u[3]; for (int j = 0; j \u0026lt; 3; j++) u[j] = U.block\u0026lt;3, 1\u0026gt;(0, j); // 更新雅可比矩阵 Eigen::Matrix3d ukukT = u[0] * u[0].transpose(); Eigen::Vector3d vec_Jt; //基准雷达点云的影响 for (size_t j = 0; j \u0026lt; basepts_size; j++) { pt_trans[j] = pt_trans[j] - center; //计算文中的$J$ vec_Jt = 2.0 / N * ukukT * pt_trans[j]; //计算基准雷达轨迹的$\\bar J$ _jact.block\u0026lt;3, 1\u0026gt;(6 * basewin_num[j], 0) -= point_xis[j] * vec_Jt; _jact.block\u0026lt;3, 1\u0026gt;(6 * basewin_num[j] + 3, 0) += vec_Jt; } //参考雷达点云的影响 cnt = 0; for (int k = 0; k \u0026lt; ref_size; k++) { vector_vec3d \u0026amp;reforigin_pts = *refOriginPts[k][i]; std::vector\u0026lt;int\u0026gt; \u0026amp;refwin_num = *refWinNums[k][i]; for (size_t j = 0; j \u0026lt; reforigin_pts.size(); j++) { pt_trans[cnt + basepts_size] = pt_trans[cnt + basepts_size] - center; vec_Jt = 2.0 / N * ukukT * pt_trans[cnt + basepts_size]; //公式中p=j的部分,见文中公式2 _jact.block\u0026lt;3, 1\u0026gt;(6 * refwin_num[j], 0) -= point_xis[cnt + basepts_size] * vec_Jt; _jact.block\u0026lt;3, 1\u0026gt;(6 * refwin_num[j] + 3, 0) += vec_Jt; //公式中q=i的部分,见文中公式3 _jact.block\u0026lt;3, 1\u0026gt;(6 * pose_size + 6 * k, 0) -= point_xic[cnt + basepts_size] * poses[refwin_num[j]].toRotationMatrix().transpose() * vec_Jt; _jact.block\u0026lt;3, 1\u0026gt;(6 * pose_size + 3 + 6 * k, 0) += poses[refwin_num[j]].toRotationMatrix().transpose() * vec_Jt; cnt++; } } assert(cnt == refpts_size_all); // 计算Hessian矩阵 Eigen::Matrix3d Hessian33; Eigen::Matrix3d F; std::vector\u0026lt;Eigen::Matrix3d\u0026gt; F_(3); for (size_t j = 0; j \u0026lt; 3; j++) { if (j == 0) { F_[j].setZero(); continue; } Hessian33 = u[j] * u[0].transpose(); F_[j] = 1.0 / N / (eigen_value[0] - eigen_value[j]) * (Hessian33 + Hessian33.transpose()); } size_t colnum_s; // 计算Hessian矩阵和雅可比矩阵的乘积 for (size_t j = 0; j \u0026lt; N; j++) { for (int f = 0; f \u0026lt; 3; f++) F.block\u0026lt;1, 3\u0026gt;(f, 0) = pt_trans[j].transpose() * F_[f]; F = U * F; for (size_t k = 0; k \u0026lt; N; k++) { Hessian33 = u[0] * (pt_trans[k]).transpose() * F + u[0].dot(pt_trans[k]) * F; if (k == j) Hessian33 += (N - 1) / N * ukukT; else Hessian33 -= 1.0 / N * ukukT; Hessian33 = 2.0 / N * Hessian33; _H.block\u0026lt;3, 3\u0026gt;(3 * k, 3 * j) = Hessian33; } if (j \u0026lt; basepts_size) {//基准雷达轨迹的D colnum_s = 6 * basewin_num[j]; _D.block\u0026lt;3, 3\u0026gt;(3 * j, colnum_s) = point_xis[j]; _D.block\u0026lt;3, 3\u0026gt;(3 * j, colnum_s + 3) = Eigen::MatrixXd::Identity(3, 3); } else { int base_pose; for (int a = 0; a \u0026lt; ref_size; a++) if (j - basepts_size \u0026lt; refpts_size_part[a + 1]) { //注意与前面几个阶段求hessian矩阵有差异，这里仅表达了完整的D,而非\\bar{H}，所以这里不用进行D^{T}HD的求解 std::vector\u0026lt;int\u0026gt; \u0026amp;refwin_num = *refWinNums[a][i]; colnum_s = 6 * refwin_num[j - basepts_size - refpts_size_part[a]]; base_pose = refwin_num[j - basepts_size - refpts_size_part[a]]; _D.block\u0026lt;3, 3\u0026gt;(3 * j, colnum_s) = point_xis[j]; _D.block\u0026lt;3, 3\u0026gt;(3 * j, colnum_s + 3) = Eigen::MatrixXd::Identity(3, 3); colnum_s = 6 * (pose_size + a); _D.block\u0026lt;3, 3\u0026gt;(3 * j, colnum_s) = poses[base_pose] * point_xic[j]; _D.block\u0026lt;3, 3\u0026gt;(3 * j, colnum_s + 3) = poses[base_pose].toRotationMatrix(); break; } } } // 更新残差和Hessian矩阵 residual += eigen_value[0]; Hess += _D.transpose() * _H * _D; JacT += _jact; _jact.setZero(); 参考文献 [1]《Targetless Extrinsic Calibration of Multiple Small FoV LiDARs and Cameras using Adaptive Voxelization》\n[2]《BALM: Bundle Adjustment for Lidar Mapping》\n[3]《BALM论文阅读》——epsilonjohn的博客文章\n[4]《A micro Lie theory for state estimation in robotics》\n[5]《多个LiDAR-Camera无目标跨视角联合标定方法》\n[6]《如何用法向量求点到平面距离_【立体几何】用空间向量求点到面的距离》\n","date":"2024-09-11T09:05:20+08:00","image":"https://wzwan-developer.github.io/p/mlcc/01/dense_map_hu3952636258060127531.jpg","permalink":"https://wzwan-developer.github.io/p/mlcc/01/","title":"Chapter 01: Multi-LiDAR Extrinsic Calibration"},{"content":"概率论中的“矩” 彩票的问题 假设福利彩票，每一注两元钱，且中奖的概率分布如下： 其中，概率的“称”如下所示： 此时我们称量一下中奖500万元： 上述结果表明：不确定的500万元等价于确定的0.5元。此时将所有的中奖概率刻画上去： $$1.5 = 5\\times 10\\% + 100\\times0.5\\% + 5000000\\times0.000001\\% $$ 结果表明一张彩票成本两元，但是期望获得的收益为1.5元，每买一张都会亏损0.5元。\n“矩” 一阶矩 上述我们计算的就是概率的一阶矩，也就是期望（expectation/mean）。 $$ E[X]=\\sum p_{i}x_{i} $$含义如下： 二阶矩 $$ \\Sigma=E[(X-\\mu)^{2}]=\\sum_{i}p_{i}(x_{i}-\\mu)^{2} $$高阶矩 三阶矩称为偏度，四阶矩称为峰度。各有用途但是共同的特点为称量之后才能使用。\n参考链接 [1]如何理解概率论中的“矩”？\n","date":"2024-09-09T11:12:48+08:00","image":"https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/gaussian-normal-distribution-graph_hu15871502155684369944.png","permalink":"https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_03/","title":"如何理解概率论中的“矩”"},{"content":"舒尔补定义 给定任意的矩阵块 $M$ ，如下所示：\n$$M=\\begin{bmatrix} A \u0026 B\\\\ C \u0026D\\\\ \\end{bmatrix}$$ 如果，矩阵块 $D$ 是可逆的，则 $A − B D^{-1} C$称之为 $D$ 关于 $M$的舒尔补。 如果，矩阵块 $A$ 是可逆的，则 $D − CA^{-1} B$称之为 $A$ 关于 $M$的舒尔补。 舒尔补的定理推导 $$\\begin{bmatrix}I \u0026 0\\\\ -CA^{-1} \u0026I\\\\\\end{bmatrix} \\begin{bmatrix}A \u0026 B\\\\ C \u0026 D\\end{bmatrix}=\\begin{bmatrix}A \u0026 B\\\\ 0 \u0026 \\Delta _{A}\\end{bmatrix}$$$$\\begin{bmatrix}A \u0026 B\\\\ C\u0026D\\end{bmatrix} \\begin{bmatrix}I \u0026 -A^{-1}B\\\\ 0\u0026I\\\\\\end{bmatrix}= \\begin{bmatrix}A \u0026 0\\\\ C \u0026 \\Delta _{A}\\end{bmatrix}$$$$\\begin{bmatrix}I \u0026 0\\\\ -CA^{-1} \u0026I\\\\\\end{bmatrix} \\begin{bmatrix}A \u0026 B\\\\ C \u0026 D\\end{bmatrix} \\begin{bmatrix}I \u0026 -A^{-1}B\\\\ 0\u0026I\\\\\\end{bmatrix}= \\begin{bmatrix}A \u0026 0\\\\ 0 \u0026 \\Delta _{A}\\end{bmatrix} $$$$\\begin{bmatrix}I \u0026 0\\\\ CA^{-1} \u0026I\\\\\\end{bmatrix} \\begin{bmatrix}A \u0026 0\\\\ 0\u0026 \\Delta _{A}\\end{bmatrix} \\begin{bmatrix}I \u0026 A^{-1}B\\\\ 0\u0026I\\\\\\end{bmatrix}= \\begin{bmatrix}A \u0026 B\\\\ C \u0026 D\\ \\end{bmatrix} $$用途 快速求矩阵的逆 $$M=\\begin{bmatrix}A \u0026 B\\\\ C\u0026D\\end{bmatrix}=\\begin{bmatrix}I \u0026 0\\\\ CA^{-1} \u0026I\\\\\\end{bmatrix} \\begin{bmatrix}A \u0026 0\\\\ 0\u0026 \\Delta _{A}\\end{bmatrix} \\begin{bmatrix}I \u0026 A^{-1}B\\\\ 0\u0026I\\\\\\end{bmatrix}$$$$M^{-1}=\\begin{bmatrix}A \u0026 B\\\\ C\u0026D\\end{bmatrix}^{-1}=\\begin{bmatrix}I \u0026 0\\\\ CA^{-1} \u0026I\\\\\\end{bmatrix}^{-1}\\begin{bmatrix}A^{-1} \u0026 0\\\\ 0\u0026 \\Delta _{A}^{-1}\\end{bmatrix}\\begin{bmatrix}I \u0026 A^{-1}B\\\\ 0\u0026I\\\\\\end{bmatrix}^{-1}\\\\ =\\begin{bmatrix}I \u0026 0\\\\ -CA^{-1} \u0026I\\\\\\end{bmatrix}\\begin{bmatrix}A^{-1} \u0026 0\\\\ 0\u0026 \\Delta _{A}^{-1}\\end{bmatrix}\\begin{bmatrix}I \u0026 -A^{-1}B\\\\ 0\u0026I\\\\\\end{bmatrix}\\\\=\\begin{bmatrix}A^{-1}+A^{-1}B{\\Delta _A}^{-1}CA^{-1}\u0026-A^{-1}B{\\Delta _A}^{-1}\\\\-{\\Delta _A}^{-1}CA^{-1}\u0026{\\Delta _A}^{-1} \\end{bmatrix} $$舒尔补在信息矩阵求解中的使用 $$\\sum=\\begin{bmatrix}A \u0026 C^{T}\\\\C\u0026D\\end{bmatrix}$$$$\\sum^{-1}=\\begin{bmatrix}A\u0026C^{T}\\\\C\u0026D\\end{bmatrix}^{-1}\\\\=\\begin{bmatrix}A^{-1}+A^{-1}C^{T}{\\Delta _A}^{-1}CA^{-1}\u0026-A^{-1}C^{T}{\\Delta _A}^{-1}\\\\-{\\Delta _A}^{-1}CA^{-1}\u0026{\\Delta _A}^{-1} \\end{bmatrix}\\\\\\stackrel{\\triangle}{=}\\begin{bmatrix}\\Lambda_{aa}\u0026\\Lambda _{ab}\\\\\\Lambda _{ba}\u0026\\Lambda _{bb} \\end{bmatrix}$$ 其中，由上式可推导得$A^{-1}=\\Lambda _{aa}-\\Lambda _{ab}\\Lambda _{bb}^{-1}\\Lambda _{ba}$, 以及$D^{-1}=\\Lambda _{bb}-\\Lambda _{ba}\\Lambda _{aa}^{-1}\\Lambda _{ab}$，它们即为下次优化会使用的先验信息矩阵（边际概率的信息矩阵）。\n通过舒尔补分解多元高斯分布 $$ x=\\begin{bmatrix}a\\\\b\\end{bmatrix} $$$$\\sum=\\begin{bmatrix} A \u0026 C^{T} \\\\C\u0026D \\end{bmatrix}$$$$P(a,b)=P(a)P(b|a)\\propto exp(-\\frac{1}{2} \\begin{bmatrix}a\\\\b\\end{bmatrix}^{T}\\begin{bmatrix}A\u0026C^{T}\\\\C\u0026D\\end{bmatrix}^{-1}\\begin{bmatrix}a\u0026b\\end{bmatrix})$$$$ \\begin{align} P(a,b) \\\\ \\propto exp\\left ( -\\frac{1}{2}\\begin{bmatrix}a\\\\b\\end{bmatrix}^{T}\\begin{bmatrix}A\u0026C^{T}\\\\C\u0026D\\end{bmatrix}^{-1}\\begin{bmatrix}a\u0026b\\end{bmatrix}\\right) \\\\ \\propto exp \\left( -\\frac{1}{2}\\begin{bmatrix}a\\\\b\\end{bmatrix}^{T}\\begin{bmatrix}I \u0026 0\\\\ -CA^{-1} \u0026I\\\\\\end{bmatrix}\\begin{bmatrix}A^{-1} \u0026 0\\\\ 0\u0026 \\Delta _{A}^{-1}\\end{bmatrix}\\begin{bmatrix}I \u0026 -A^{-1}B\\\\ 0\u0026I\\\\\\end{bmatrix}\\begin{bmatrix}a\u0026b\\end{bmatrix})\\right )\\\\ \\propto exp\\left( -\\frac{1}{2}\\begin{bmatrix}a^{T}\u0026(b-CA^{-1}a)^{T}\\end{bmatrix}\\begin{bmatrix}A^{-1}\u00260\\\\0\u0026{\\Delta _A^{-1}}\\end{bmatrix}\\begin{bmatrix}a\\\\b-CA^{-1}a\\end{bmatrix}\\right)\\\\ \\propto exp \\left( -\\frac{1}{2}(a^TA^{-1}a)+(b-CA^{-1}a)^{T} \\Delta _A^{-1}(b-CA^{-1}a) \\right)\\\\ \\propto exp \\left( -\\frac{1}{2}a^{T}A^{-1}a\\right)exp \\left ( -\\frac{1}{2}(b-CA^{-1}a)^{T}\\Delta _A^{-1}(b-CA^{-1}a)\\right)\\\\ \\propto P(a)P(b|a) \\\\\\end{align}$$ 在《机器人学中的状态估计》2.2.3章节\u0026quot;联合概率密度函数，分解与推断\u0026quot;可见相似内容,其实就是高斯推断，套用相关模型$P(a)$是观测（边际概率），$P(b|a)$是后验概率，$P(a|b)$是传感器模型。\n","date":"2024-09-02T23:51:06+08:00","image":"https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_02/gaussian-normal-distribution-graph_hu15871502155684369944.png","permalink":"https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_02/","title":"舒尔补"},{"content":"从优化角度理解边缘化 模型 $$\\begin{bmatrix}H_{mm}\u0026H_{mr}\\\\H_{rm}\u0026H_{rr}\\end{bmatrix}\\begin{bmatrix}X_m\\\\X_r\\end{bmatrix}=\\begin{bmatrix}b_m\\\\b_r\\end{bmatrix} $$ 拆解的目的是通过边缘化将$X_m$从状态量里删除掉，但是要保留它的约束。在划窗模式里，这个$X_m$为要边缘化掉的量。\n过程 $$\\begin{bmatrix}I\u00260\\\\-H_{rm}H_{mm}^{-1}\u0026I\\end{bmatrix}\\begin{bmatrix}H_{mm}\u0026H_{mr}\\\\H_{rm}\u0026H_{rr}\\end{bmatrix}\\begin{bmatrix}X_m\\\\X_r\\end{bmatrix}=\\begin{bmatrix}I\u00260\\\\-H_{rm}H_{mm}^{-1}\u0026I\\end{bmatrix}\\begin{bmatrix}b_m\\\\b_r\\end{bmatrix}$$$$\\begin{bmatrix}H_{mm}\u0026H_{mr}\\\\0\u0026H_{rr}-H_{rm}H_{mm}^{-1}H_{mr}\\end{bmatrix}\\begin{bmatrix}X_m\\\\X_r\\end{bmatrix}=\\begin{bmatrix}b_m\\\\b_r-H_{rm}H_{mm}^{-1}b_m\\end{bmatrix}$$$$(H_{rr}-H_{rm}H_{mm}^{-1}H_{mr})X_r=b_r-H_{rm}H_{mm}^{-1}b_{m}$$ 意义：此时可以不依赖$X_m$求解出$X_r$,若我们只关心$X_r$的值，则可以把$X_m$从模型中删除。\n从滤波角度理解边缘化 模型 $$\\begin{align} x_k=A_{k-1}x_{k-1}+v_k+w_k,\u0026k=1...K\\\\ y_k=C_kx_k+n_k,\u0026k=0...K \\end{align}$$MAP估计角度 $$\\hat{x}=arg\\underset{x}{min} J(x)$$$${\\frac{\\partial J(x)}{\\partial x^{T}}}|_x=-H^{T}W^{-1}(z-H\\hat{x})=0 \\Rightarrow (H^{T}W^{-1}H)\\hat{x}=H^{T}W^{-1}z$$ 注：此时形式以及是接近优化角度的$HX=b$。\n滤波角度 $$ \\{ \\hat {x}_{k-1} ,\\hat{P}_{k-1}\\}$$$$ \\{ \\hat {x}_{k} ,\\hat{P}_{k}\\}$$$$ \\{ \\hat {x}_{k} ,\\hat{P}_{k}\\}$$$$ z=\\begin{bmatrix}\\hat{x}_{k-1}\\\\v_k\\\\y_k\\end{bmatrix},H=\\begin{bmatrix}I\u0026\u0026\\\\-A_{k-1}\u0026I\\\\\u0026\u0026C_{k}\\end{bmatrix},W=\\begin{bmatrix}\\hat {P}_{k-1}\u0026\u0026\\\\\u0026Q_k\u0026\\\\\u0026\u0026R_k\\end{bmatrix}$$$$(H_{k}^{T}W_{k}^{-1}H_{k})\\hat{x}=H_{k}^{T}W_{k}^{-1}z_k$$$$\\hat{x}=\\begin{bmatrix}\\hat{x'}_{k-1}\\\\\\hat{x}_k\\end{bmatrix}$$ 借助本文第一节，目标为从$x$变量中删除$\\hat{x'}_{k-1}$，执行舒尔补可得 ","date":"2024-09-02T00:00:00Z","image":"https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/gaussian-normal-distribution-graph_hu15871502155684369944.png","permalink":"https://wzwan-developer.github.io/p/state_estimation_for_robotics/2_01/","title":"边缘化"}]